{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m1kemp/ecgDiagnosis/blob/main/ColabCode/FullImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Il-hgAcf6yi",
        "outputId": "d5813c96-2ffe-4451-aeeb-ac5038f0474c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracting mit-af-database.zip â†’ data/\n",
            "âœ… Done: mit-af-database.zip\n",
            "Extracting mit-arrhythmia-database.zip â†’ data/\n",
            "âœ… Done: mit-arrhythmia-database.zip\n",
            "Extracting training2017.zip â†’ data/\n",
            "âœ… Done: training2017.zip\n",
            "\n",
            "ğŸ“ Contents of data/:\n",
            "  __MACOSX\n",
            "  training2017\n",
            "  mit-bih-arrhythmia-database-1.0.0\n",
            "  files\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î²Î±ÏƒÎ¹ÎºÏÎ½ Î´Î¹Î±Î´ÏÎ¿Î¼ÏÎ½ (paths)\n",
        "drive_data_dir = Path(\"/content/drive/MyDrive/ECGData/data\")\n",
        "local_data_dir = Path(\"data\")\n",
        "# Î”Î¹Î±ÏƒÏ†Î¬Î»Î¹ÏƒÎ· ÏŒÏ„Î¹ Î¿ Ï„Î¿Ï€Î¹ÎºÏŒÏ‚ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼Î¿Ï Ï…Ï€Î¬ÏÏ‡ÎµÎ¹\n",
        "local_data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Î›Î¯ÏƒÏ„Î± Ï„Ï‰Î½ datasets Ï€ÏÎ¿Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±\n",
        "zips = [\n",
        "    \"mit-af-database.zip\",\n",
        "    \"mit-arrhythmia-database.zip\",\n",
        "    \"training2017.zip\",\n",
        "]\n",
        "\n",
        "def safe_extract(zip_path: Path, dest_dir: Path):\n",
        "    \"\"\"Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î±ÏƒÏ†Î±Î»Î® Î±Ï€Î¿ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ· Î±ÏÏ‡ÎµÎ¯Ï‰Î½ .zip.\"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        zf.extractall(dest_dir)\n",
        "\n",
        "# 3. ÎšÏÏÎ¹Î± Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±: Î•Ï€Î±Î½Î¬Î»Î·ÏˆÎ· ÎºÎ±Î¹ Î±Ï€Î¿ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ·\n",
        "for zip_name in zips:\n",
        "    zip_path = drive_data_dir / zip_name\n",
        "\n",
        "    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÏÏ€Î±ÏÎ¾Î·Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï… Ï€ÏÎ¹Î½ Ï„Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±\n",
        "    if not zip_path.exists():\n",
        "        print(f\"âš ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î¿ Drive: {zip_path}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· Î±Ï€Î¿ÏƒÏ…Î¼Ï€Î¯ÎµÏƒÎ·Ï‚: {zip_path.name} â†’ {local_data_dir}/\")\n",
        "    safe_extract(zip_path, local_data_dir)\n",
        "    print(f\"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {zip_path.name}\")\n",
        "\n",
        "# 4. Î•Ï€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ· Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Ï‰Î½ ÏƒÏ„Î¿Î½ Ï„Î¿Ï€Î¹ÎºÏŒ Ï†Î¬ÎºÎµÎ»Î¿\n",
        "print(\"\\nğŸ“ Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î± Ï„Î¿Ï… data/:\")\n",
        "for item in local_data_dir.iterdir():\n",
        "    print(f\"  {item.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_OUbktMiJUY",
        "outputId": "b4c91a01-c0fa-433d-f6b7-436c01f2214f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting neurokit2\n",
            "  Downloading neurokit2-0.2.12-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Collecting biosppy\n",
            "  Downloading biosppy-2.2.3-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.1)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.6.1)\n",
            "Requirement already satisfied: PyWavelets>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.9.0)\n",
            "Collecting bidict (from biosppy)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from biosppy) (3.14.0)\n",
            "Collecting shortuuid (from biosppy)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from biosppy) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from biosppy) (1.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from biosppy) (4.12.0.88)\n",
            "Collecting mock (from biosppy)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.8.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neurokit2-0.2.12-py2.py3-none-any.whl (708 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m708.4/708.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biosppy-2.2.3-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.0/158.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: shortuuid, mock, bidict, pandas, wfdb, neurokit2, biosppy\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bidict-0.23.1 biosppy-2.2.3 mock-5.2.0 neurokit2-0.2.12 pandas-2.3.2 shortuuid-1.0.13 wfdb-4.3.0\n",
            "Processing 8528 signals...\n",
            "Processing signal 1/8528\n",
            "Processing signal 101/8528\n",
            "Processing signal 201/8528\n",
            "Processing signal 301/8528\n",
            "Processing signal 401/8528\n",
            "Processing signal 501/8528\n",
            "Processing signal 601/8528\n",
            "Processing signal 701/8528\n",
            "Processing signal 801/8528\n",
            "Processing signal 901/8528\n",
            "Processing signal 1001/8528\n",
            "Processing signal 1101/8528\n",
            "Processing signal 1201/8528\n",
            "Processing signal 1301/8528\n",
            "Processing signal 1401/8528\n",
            "Processing signal 1501/8528\n",
            "Processing signal 1601/8528\n",
            "Processing signal 1701/8528\n",
            "Processing signal 1801/8528\n",
            "Processing signal 1901/8528\n",
            "Processing signal 2001/8528\n",
            "Processing signal 2101/8528\n",
            "Processing signal 2201/8528\n",
            "Processing signal 2301/8528\n",
            "Processing signal 2401/8528\n",
            "Processing signal 2501/8528\n",
            "Processing signal 2601/8528\n",
            "Processing signal 2701/8528\n",
            "Processing signal 2801/8528\n",
            "Processing signal 2901/8528\n",
            "Processing signal 3001/8528\n",
            "Processing signal 3101/8528\n",
            "Processing signal 3201/8528\n",
            "Processing signal 3301/8528\n",
            "Processing signal 3401/8528\n",
            "Processing signal 3501/8528\n",
            "Processing signal 3601/8528\n",
            "Processing signal 3701/8528\n",
            "Processing signal 3801/8528\n",
            "Processing signal 3901/8528\n",
            "Processing signal 4001/8528\n",
            "Processing signal 4101/8528\n",
            "Processing signal 4201/8528\n",
            "Processing signal 4301/8528\n",
            "Processing signal 4401/8528\n",
            "Processing signal 4501/8528\n",
            "Processing signal 4601/8528\n",
            "Processing signal 4701/8528\n",
            "Processing signal 4801/8528\n",
            "Processing signal 4901/8528\n",
            "Processing signal 5001/8528\n",
            "Processing signal 5101/8528\n",
            "Processing signal 5201/8528\n",
            "Processing signal 5301/8528\n",
            "Processing signal 5401/8528\n",
            "Processing signal 5501/8528\n",
            "Processing signal 5601/8528\n",
            "Processing signal 5701/8528\n",
            "Processing signal 5801/8528\n",
            "Processing signal 5901/8528\n",
            "Processing signal 6001/8528\n",
            "Processing signal 6101/8528\n",
            "Processing signal 6201/8528\n",
            "Processing signal 6301/8528\n",
            "Processing signal 6401/8528\n",
            "Processing signal 6501/8528\n",
            "Processing signal 6601/8528\n",
            "Processing signal 6701/8528\n",
            "Processing signal 6801/8528\n",
            "Processing signal 6901/8528\n",
            "Processing signal 7001/8528\n",
            "Processing signal 7101/8528\n",
            "Processing signal 7201/8528\n",
            "Processing signal 7301/8528\n",
            "Processing signal 7401/8528\n",
            "Processing signal 7501/8528\n",
            "Processing signal 7601/8528\n",
            "Processing signal 7701/8528\n",
            "Processing signal 7801/8528\n",
            "Processing signal 7901/8528\n",
            "Processing signal 8001/8528\n",
            "Processing signal 8101/8528\n",
            "Processing signal 8201/8528\n",
            "Processing signal 8301/8528\n",
            "Processing signal 8401/8528\n",
            "Processing signal 8501/8528\n",
            "PhysioNet Data Shape: torch.Size([335068, 1250])\n",
            "Label distribution: [190702  33552 102468   8346]\n"
          ]
        }
      ],
      "source": [
        "# Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î·ÎºÏÎ½\n",
        "!pip install wfdb neurokit2 biosppy torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wfdb\n",
        "import scipy.io\n",
        "import scipy.signal\n",
        "import neurokit2 as nk\n",
        "import torch\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "# --- ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Î¸ÎµÏÏÎ½ Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ---\n",
        "TARGET_SAMPLING_RATE = 125  # Hz (Î£Ï„ÏŒÏ‡Î¿Ï‚ ÏƒÏ…Ï‡Î½ÏŒÏ„Î·Ï„Î±Ï‚ Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚)\n",
        "MAX_LEN_PHYSIONET = 10 * TARGET_SAMPLING_RATE  # 10 Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î± (ÎœÎ­Î³Î¹ÏƒÏ„Î¿ Î¼Î®ÎºÎ¿Ï‚)\n",
        "\n",
        "def load_physionet_data(path):\n",
        "    \"\"\"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ PhysioNet 2017 (Î±ÏÏ‡ÎµÎ¯Î± .mat ÎºÎ±Î¹ REFERENCE.csv).\"\"\"\n",
        "    signals, labels = [], []\n",
        "    ref_df = pd.read_csv(os.path.join(path, \"REFERENCE.csv\"), header=None)\n",
        "    ref_dict = dict(zip(ref_df[0], ref_df[1]))\n",
        "    # Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ ÏƒÎµ Î±ÎºÎ­ÏÎ±Î¹Î¿Ï…Ï‚\n",
        "    label_mapping = {\"N\": 0, \"A\": 1, \"O\": 2, \"~\": 3}\n",
        "\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith(\".mat\"):\n",
        "            record_name = file.replace(\".mat\", \"\")\n",
        "            try:\n",
        "                mat_data = scipy.io.loadmat(os.path.join(path, file))\n",
        "                signal = mat_data[\"val\"][0]  # Î•Î¾Î±Î³Ï‰Î³Î® ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ Î—ÎšÎ“\n",
        "                label = ref_dict.get(record_name, None)\n",
        "                if label and label in label_mapping:\n",
        "                    signals.append(signal)\n",
        "                    labels.append(label_mapping[label])\n",
        "            except Exception as e:\n",
        "                print(f\"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {record_name}: {e}\")\n",
        "    return signals, labels\n",
        "\n",
        "def downsample_signal(signal, original_fs, target_fs=125):\n",
        "    \"\"\"Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± (resampling) ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ Î—ÎšÎ“.\"\"\"\n",
        "    if original_fs == target_fs:\n",
        "        return signal\n",
        "    num_samples = int(len(signal) * target_fs / original_fs)\n",
        "    return scipy.signal.resample(signal, num_samples)\n",
        "\n",
        "def normalize_signal(signal):\n",
        "    \"\"\"ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Min-Max Ï„Î¿Ï… ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ (ÎºÎ»Î¯Î¼Î±ÎºÎ± [0, 1]).\"\"\"\n",
        "    signal = np.array(signal, dtype=np.float32)\n",
        "    signal_min, signal_max = np.min(signal), np.max(signal)\n",
        "    signal_range = signal_max - signal_min\n",
        "\n",
        "    # Î‘Ï€Î¿Ï†Ï…Î³Î® Î´Î¹Î±Î¯ÏÎµÏƒÎ·Ï‚ Î¼Îµ Ï„Î¿ Î¼Î·Î´Î­Î½ Î³Î¹Î± ÏƒÎ®Î¼Î±Ï„Î± Î¼Îµ Î¼Î·Î´ÎµÎ½Î¹ÎºÏŒ ÎµÏÏÎ¿Ï‚\n",
        "    if signal_range < 1e-8:\n",
        "        return np.zeros_like(signal)\n",
        "\n",
        "    return (signal - signal_min) / signal_range\n",
        "\n",
        "def detect_r_peaks(signal, sampling_rate=125):\n",
        "    \"\"\"Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· R-peaks (ÎºÎ¿ÏÏ…Ï†ÏÎ½) Î¼Îµ Ï‡ÏÎ®ÏƒÎ· Ï„Î·Ï‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·Ï‚ NeuroKit2.\"\"\"\n",
        "    try:\n",
        "        _, r_peaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate)\n",
        "        return np.array(r_peaks[\"ECG_R_Peaks\"])\n",
        "    except:\n",
        "        # Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ ÏƒÎµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Î±Ï€Î¿Ï„Ï…Ï‡Î¯Î±Ï‚ Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ·Ï‚\n",
        "        return np.array([])\n",
        "\n",
        "def extract_t_episodes(signal, r_peaks):\n",
        "    \"\"\"Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ (Ï‡Ï„ÏÏ€Ï‰Î½) Î¼Îµ ÎºÎ­Î½Ï„ÏÎ¿ Ï„Î± R-peaks.\"\"\"\n",
        "    if len(r_peaks) < 2:\n",
        "        return []\n",
        "\n",
        "    rr_intervals = np.diff(r_peaks)\n",
        "    median_rr = int(np.median(rr_intervals))\n",
        "    episodes = []\n",
        "\n",
        "    for r in r_peaks:\n",
        "        # ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï€Î±ÏÎ±Î¸ÏÏÎ¿Ï… Î³ÏÏÏ‰ Î±Ï€ÏŒ Ï„Î¿ R-peak\n",
        "        start = max(0, r - median_rr // 2)\n",
        "        end = min(len(signal), r + median_rr // 2)\n",
        "        if end - start > 50:  # Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Ï‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ Î¼Î®ÎºÎ¿Ï…Ï‚\n",
        "            episodes.append((start, end))\n",
        "    return episodes\n",
        "\n",
        "def pad_signal(signal, max_len):\n",
        "    \"\"\"Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· padding (Î¼Îµ Î¼Î·Î´ÎµÎ½Î¹ÎºÎ¬) Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒ Î¼Î®ÎºÎ¿Ï‚ ÏƒÎ®Î¼Î±Ï„Î¿Ï‚.\"\"\"\n",
        "    if len(signal) < max_len:\n",
        "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
        "    else:\n",
        "        # Î ÎµÏÎ¹ÎºÎ¿Ï€Î® Î±Î½ Ï…Ï€ÎµÏÎ²Î±Î¯Î½ÎµÎ¹ Ï„Î¿ Î¼Î­Î³Î¹ÏƒÏ„Î¿ Î¼Î®ÎºÎ¿Ï‚\n",
        "        return signal[:max_len]\n",
        "\n",
        "def preprocess_ecg_dataset(dataset_path):\n",
        "    \"\"\"ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î³Î¹Î± Ï„Î¿ dataset.\"\"\"\n",
        "    signals, labels = load_physionet_data(dataset_path)\n",
        "    # Î— Î±ÏÏ‡Î¹ÎºÎ® ÏƒÏ…Ï‡Î½ÏŒÏ„Î·Ï„Î± Ï„Î¿Ï… PhysioNet 2017 ÎµÎ¯Î½Î±Î¹ 300 Hz\n",
        "    original_fs = 300\n",
        "    processed_signals, processed_labels = [], []\n",
        "\n",
        "    print(f\"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± {len(signals)} ÏƒÎ·Î¼Î¬Ï„Ï‰Î½...\")\n",
        "\n",
        "    for i, (signal, label) in enumerate(zip(signals, labels)):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ {i+1}/{len(signals)}\")\n",
        "\n",
        "        # --- Î’Î®Î¼Î±Ï„Î± Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ---\n",
        "\n",
        "        # 1. Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±\n",
        "        signal = downsample_signal(signal, original_fs, TARGET_SAMPLING_RATE)\n",
        "\n",
        "        # 2. ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·\n",
        "        signal = normalize_signal(signal)\n",
        "\n",
        "        # Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· ÏƒÎ·Î¼Î¬Ï„Ï‰Î½ Ï€Î¿Ï… Î±Ï€Î­Ï„Ï…Ï‡Î±Î½ ÏƒÏ„Î·Î½ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· (Ï€.Ï‡. ÏƒÏ„Î±Î¸ÎµÏÎ® Ï„Î¹Î¼Î®)\n",
        "        if np.all(signal == 0):\n",
        "            continue\n",
        "\n",
        "        # 3. Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· R-peaks\n",
        "        r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
        "\n",
        "        if len(r_peaks) < 2:\n",
        "            continue\n",
        "\n",
        "        # 4. Î•Î¾Î±Î³Ï‰Î³Î® Ï‡Ï„ÏÏ€Ï‰Î½ (beats)\n",
        "        t_eps = extract_t_episodes(signal, r_peaks)\n",
        "\n",
        "        for start, end in t_eps:\n",
        "            beat = signal[start:end]\n",
        "            if len(beat) > 0:  # Î”Î¹Î±ÏƒÏ†Î¬Î»Î¹ÏƒÎ· ÏŒÏ„Î¹ Î¿ Ï‡Ï„ÏÏ€Î¿Ï‚ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½ÏŒÏ‚\n",
        "                processed_signals.append(pad_signal(beat, MAX_LEN_PHYSIONET))\n",
        "                processed_labels.append(label)\n",
        "\n",
        "    return np.array(processed_signals), np.array(processed_labels)\n",
        "\n",
        "# --- ÎšÏÏÎ¹Î± Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ---\n",
        "\n",
        "# Î•Ï†Î±ÏÎ¼Î¿Î³Î® Ï„Î·Ï‚ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ÏƒÏ„Î¿ ÏƒÏÎ½Î¿Î»Î¿ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ training2017\n",
        "physionet_data, physionet_labels = preprocess_ecg_dataset(\"data/training2017\")\n",
        "\n",
        "# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Ï‰Î½ numpy arrays ÏƒÎµ PyTorch Tensors\n",
        "X_physionet = torch.tensor(physionet_data, dtype=torch.float32)\n",
        "y_physionet = torch.tensor(physionet_labels, dtype=torch.long)\n",
        "\n",
        "# Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Ï‰Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± Î¼ÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ·\n",
        "with gzip.open(\"pretraining_data.pkl.gz\", \"wb\") as f:\n",
        "    pickle.dump((X_physionet, y_physionet), f)\n",
        "\n",
        "print(f\"Î¤ÎµÎ»Î¹ÎºÏŒ ÏƒÏ‡Î®Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (PhysioNet): {X_physionet.shape}\")\n",
        "print(f\"ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½: {np.bincount(physionet_labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbM9jefcjxRn",
        "outputId": "187b863c-a411-4bcc-944a-124a97c18c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing NNModel.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile NNModel.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 1. Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® Î¼Î¿Î½Î¬Î´Î±: Squeeze-and-Excitation (SE) Block\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\" Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… Squeeze-and-Excitation (SE) block\n",
        "        Î³Î¹Î± Î±Î½Î±Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® Î²Î±ÏÏÏ„Î·Ï„Î±Ï‚ Ï„Ï‰Î½ ÎºÎ±Î½Î±Î»Î¹ÏÎ½. \"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
        "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, _ = x.shape\n",
        "        se = self.global_avg_pool(x).view(batch, channels)\n",
        "        se = F.relu(self.fc1(se))\n",
        "        se = F.sigmoid(self.fc2(se))  # Sigmoid Î³Î¹Î± ÎºÎ»Î¹Î¼Î¬ÎºÏ‰ÏƒÎ· [0, 1]\n",
        "        se = se.view(batch, channels, 1)\n",
        "        return x * se  # Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î²Î±ÏÏÎ½ ÏƒÏ„Î± ÎºÎ±Î½Î¬Î»Î¹Î±\n",
        "\n",
        "# 2. Î’Î±ÏƒÎ¹ÎºÎ® Î´Î¿Î¼Î¹ÎºÎ® Î¼Î¿Î½Î¬Î´Î±: Residual Block (Î¼Îµ SE)\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\" Î¥Ï€Î¿Î»ÎµÎ¹Î¼Î¼Î±Ï„Î¹ÎºÏŒ Î¼Ï€Î»Î¿Îº (Residual Block) Ï€Î¿Ï… ÎµÎ½ÏƒÏ‰Î¼Î±Ï„ÏÎ½ÎµÎ¹ SE\n",
        "        ÎºÎ±Î¹ ÏƒÏ…Î½Ï„ÏŒÎ¼ÎµÏ…ÏƒÎ· (shortcut) Î³Î¹Î± Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· Ï„Î·Ï‚ ÎºÎ»Î¯ÏƒÎ·Ï‚. \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=5):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.se = SEBlock(out_channels)\n",
        "\n",
        "        # Shortcut connection (1x1 conv) Î±Î½ Î±Î»Î»Î¬Î¶Î¿Ï…Î½ Î¿Î¹ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm1d(out_channels)\n",
        "        ) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.se(out)  # Î•Ï†Î±ÏÎ¼Î¿Î³Î® SE\n",
        "        out += residual   # Î ÏÏŒÏƒÎ¸ÎµÏƒÎ· Ï…Ï€Î¿Î»ÎµÎ¹Î¼Î¼Î±Ï„Î¹ÎºÎ®Ï‚ ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚\n",
        "        out = F.relu(out)\n",
        "        out = self.maxpool(out)  # Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚ Ï„Î¿Ï… Î¼Ï€Î»Î¿Îº\n",
        "        return out\n",
        "\n",
        "# 3. ÎšÏÏÎ¹Î¿ ÎœÎ¿Î½Ï„Î­Î»Î¿: Î¥Î²ÏÎ¹Î´Î¹ÎºÎ® Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® CNN-BiLSTM\n",
        "class ECGClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Î¤Î¿ ÎºÏÏÎ¹Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ Î—ÎšÎ“, Ï€Î¿Ï… ÏƒÏ…Î½Î´Ï…Î¬Î¶ÎµÎ¹:\n",
        "    - 1D CNN Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î® Ï„Î¿Ï€Î¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½\n",
        "    - Residual Blocks (Î¼Îµ SE) Î³Î¹Î± Î²Î±Î¸ÏÏ„ÎµÏÎ· ÎµÎ¾Î±Î³Ï‰Î³Î®\n",
        "    - BiLSTM Î³Î¹Î± Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï‡ÏÎ¿Î½Î¹ÎºÏÎ½ ÎµÎ¾Î±ÏÏ„Î®ÏƒÎµÏ‰Î½\n",
        "    - Fully Connected ÎµÏ€Î¯Ï€ÎµÎ´Î± Î³Î¹Î± Ï„Î·Î½ Ï„ÎµÎ»Î¹ÎºÎ® Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ECGClassifier, self).__init__()\n",
        "\n",
        "        # --- Î•Ï€Î¯Ï€ÎµÎ´Î± Î•Î¾Î±Î³Ï‰Î³Î®Ï‚ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ (CNN) ---\n",
        "        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "\n",
        "        # --- Î’Î±Î¸Î¹Î¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ (Residual Blocks) ---\n",
        "        self.resblock1 = ResidualBlock(32, 64)\n",
        "        self.resblock2 = ResidualBlock(64, 96)\n",
        "        self.resblock3 = ResidualBlock(96, 128)\n",
        "        self.resblock4 = ResidualBlock(128, 160)\n",
        "\n",
        "        # --- Î•Ï€Î¯Ï€ÎµÎ´Î± ÎœÎ¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î‘ÎºÎ¿Î»Î¿Ï…Î¸Î¯Î±Ï‚ (BiLSTM) ---\n",
        "        self.lstm = nn.LSTM(160, 64, num_layers=2, bidirectional=True,\n",
        "                            batch_first=True, dropout=0.2)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        # --- Î•Ï€Î¯Ï€ÎµÎ´Î± Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ (Fully Connected) ---\n",
        "        self.fc1 = nn.Linear(128, 64) # 128 = 64 (fwd) + 64 (bwd)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "        # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î²Î±ÏÏÎ½ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        \"\"\"Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î²Î±ÏÏÎ½ (Kaiming/He initialization).\"\"\"\n",
        "        if isinstance(m, nn.Conv1d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm1d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Î•Î¯ÏƒÎ¿Î´Î¿Ï‚ x: [batch_size, 1, signal_length]\n",
        "\n",
        "        # 1. Î‘ÏÏ‡Î¹ÎºÎ¬ CNN\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "\n",
        "        # 2. Residual Blocks\n",
        "        x = self.resblock1(x)\n",
        "        x = self.resblock2(x)\n",
        "        x = self.resblock3(x)\n",
        "        x = self.resblock4(x)\n",
        "        # x: [batch_size, 160, reduced_length]\n",
        "\n",
        "        # 3. Î‘Î½Î±Î´Î¹Î¬Ï„Î±Î¾Î· Î³Î¹Î± BiLSTM\n",
        "        # Î‘Î»Î»Î±Î³Î® Î±Ï€ÏŒ (Batch, Channels, Length) -> (Batch, Length, Channels)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # 4. BiLSTM\n",
        "        x, _ = self.lstm(x)\n",
        "        # Î§ÏÎ®ÏƒÎ· Î¼ÏŒÎ½Î¿ Ï„Î·Ï‚ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î±Ï‚ Ï‡ÏÎ¿Î½Î¹ÎºÎ®Ï‚ ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚ (many-to-one)\n",
        "        x = self.dropout1(x[:, -1, :])\n",
        "\n",
        "        # 5. FC (Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® logits (Î· CrossEntropyLoss ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÎ¹ Ï„Î¿ Softmax)\n",
        "        return x\n",
        "\n",
        "# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ„Î¹Î³Î¼Î¹Î¿Ï„ÏÏ€Î¿Ï… ÎºÎ±Î¹ ÎµÎºÏ„ÏÏ€Ï‰ÏƒÎ· Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚\n",
        "model = ECGClassifier(num_classes=5)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX9LZbhFj3DJ",
        "outputId": "6a12b8b8-849e-4688-ef45-21d5aeeab55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECGClassifier(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (resblock1): ResidualBlock(\n",
            "    (conv1): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "      (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock2): ResidualBlock(\n",
            "    (conv1): Conv1d(64, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=96, out_features=6, bias=True)\n",
            "      (fc2): Linear(in_features=6, out_features=96, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(64, 96, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock3): ResidualBlock(\n",
            "    (conv1): Conv1d(96, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "      (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(96, 128, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock4): ResidualBlock(\n",
            "    (conv1): Conv1d(128, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(160, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=160, out_features=10, bias=True)\n",
            "      (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(128, 160, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (lstm): LSTM(160, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=5, bias=True)\n",
            ")\n",
            "Pretraining data: torch.Size([335068, 1250]), Labels: 335068\n",
            "Label distribution: tensor([190702,  33552, 102468,   8346])\n",
            "Epoch 1, Batch 0, Loss: 1.3894\n",
            "Epoch 1, Batch 100, Loss: 1.4775\n",
            "Epoch 1, Batch 200, Loss: 1.0483\n",
            "Epoch 1, Batch 300, Loss: 1.2779\n",
            "Epoch 1, Batch 400, Loss: 1.1158\n",
            "Epoch 1, Batch 500, Loss: 1.2055\n",
            "Epoch 1, Batch 600, Loss: 1.5900\n",
            "Epoch 1, Batch 700, Loss: 1.2578\n",
            "Epoch 1, Batch 800, Loss: 1.0925\n",
            "Epoch 1, Batch 900, Loss: 1.2171\n",
            "Epoch 1, Batch 1000, Loss: 1.2002\n",
            "Epoch 1, Batch 1100, Loss: 0.8319\n",
            "Epoch 1, Batch 1200, Loss: 1.2033\n",
            "Epoch 1, Batch 1300, Loss: 1.3291\n",
            "Epoch 1, Batch 1400, Loss: 1.0843\n",
            "Epoch 1, Batch 1500, Loss: 1.2437\n",
            "Epoch 1, Batch 1600, Loss: 1.3374\n",
            "Epoch 1, Batch 1700, Loss: 1.3280\n",
            "Epoch 1, Batch 1800, Loss: 1.0868\n",
            "Epoch 1, Batch 1900, Loss: 0.9373\n",
            "Epoch 1, Batch 2000, Loss: 1.2162\n",
            "Epoch 1, Batch 2100, Loss: 1.0818\n",
            "Epoch 1, Batch 2200, Loss: 0.9690\n",
            "Epoch 1, Batch 2300, Loss: 1.0840\n",
            "Epoch 1, Batch 2400, Loss: 1.4978\n",
            "Epoch 1, Batch 2500, Loss: 1.3338\n",
            "Epoch 1, Batch 2600, Loss: 1.0678\n",
            "Epoch 1, Batch 2700, Loss: 1.0276\n",
            "Epoch 1, Batch 2800, Loss: 0.8431\n",
            "Epoch 1, Batch 2900, Loss: 1.1242\n",
            "Epoch 1, Batch 3000, Loss: 0.7199\n",
            "Epoch 1, Batch 3100, Loss: 1.0718\n",
            "Epoch 1, Batch 3200, Loss: 1.0809\n",
            "Epoch 1, Batch 3300, Loss: 1.0922\n",
            "Epoch 1, Batch 3400, Loss: 1.1362\n",
            "Epoch 1, Batch 3500, Loss: 1.3834\n",
            "Epoch 1, Batch 3600, Loss: 0.8417\n",
            "Epoch 1, Batch 3700, Loss: 2.2478\n",
            "Epoch 1, Batch 3800, Loss: 1.1363\n",
            "Epoch 1, Batch 3900, Loss: 0.8771\n",
            "Epoch 1, Batch 4000, Loss: 0.8121\n",
            "Epoch 1, Batch 4100, Loss: 1.5112\n",
            "Epoch 1, Batch 4200, Loss: 0.6320\n",
            "Epoch 1, Batch 4300, Loss: 0.9887\n",
            "Epoch 1, Batch 4400, Loss: 1.1745\n",
            "Epoch 1, Batch 4500, Loss: 0.8653\n",
            "Epoch 1, Batch 4600, Loss: 0.9337\n",
            "Epoch 1, Batch 4700, Loss: 0.9661\n",
            "Epoch 1, Batch 4800, Loss: 1.2086\n",
            "Epoch 1, Batch 4900, Loss: 0.8758\n",
            "Epoch 1, Batch 5000, Loss: 1.0176\n",
            "Epoch 1, Batch 5100, Loss: 1.2871\n",
            "Epoch 1, Batch 5200, Loss: 1.0384\n",
            "Epoch 1, Batch 5300, Loss: 0.9506\n",
            "Epoch 1, Batch 5400, Loss: 1.1765\n",
            "Epoch 1, Batch 5500, Loss: 0.8930\n",
            "Epoch 1, Batch 5600, Loss: 0.8984\n",
            "Epoch 1, Batch 5700, Loss: 0.8180\n",
            "Epoch 1, Batch 5800, Loss: 0.8920\n",
            "Epoch 1, Batch 5900, Loss: 0.8533\n",
            "Epoch 1, Batch 6000, Loss: 0.9541\n",
            "Epoch 1, Batch 6100, Loss: 0.8737\n",
            "Epoch 1, Batch 6200, Loss: 0.9639\n",
            "Epoch 1, Batch 6300, Loss: 1.0324\n",
            "Epoch 1, Batch 6400, Loss: 0.7096\n",
            "Epoch 1, Batch 6500, Loss: 1.2907\n",
            "Epoch 1, Batch 6600, Loss: 1.0900\n",
            "Epoch 1, Batch 6700, Loss: 1.0765\n",
            "Epoch 1, Batch 6800, Loss: 1.0472\n",
            "Epoch 1, Batch 6900, Loss: 0.9312\n",
            "Epoch 1, Batch 7000, Loss: 0.7670\n",
            "Epoch 1, Batch 7100, Loss: 1.0064\n",
            "Epoch 1, Batch 7200, Loss: 0.9021\n",
            "Epoch 1, Batch 7300, Loss: 0.9736\n",
            "Epoch 1, Batch 7400, Loss: 0.7862\n",
            "Epoch 1, Batch 7500, Loss: 0.6785\n",
            "Epoch 1, Batch 7600, Loss: 0.9949\n",
            "Epoch 1, Batch 7700, Loss: 0.8624\n",
            "Epoch 1, Batch 7800, Loss: 1.0568\n",
            "Epoch 1, Batch 7900, Loss: 1.7098\n",
            "Epoch 1, Batch 8000, Loss: 0.8944\n",
            "Epoch 1, Batch 8100, Loss: 1.8548\n",
            "Epoch 1, Batch 8200, Loss: 1.1287\n",
            "Epoch 1, Batch 8300, Loss: 1.0540\n",
            "Epoch 1, Batch 8400, Loss: 0.8419\n",
            "Epoch 1, Batch 8500, Loss: 0.8878\n",
            "Epoch 1, Batch 8600, Loss: 0.7128\n",
            "Epoch 1, Batch 8700, Loss: 0.6826\n",
            "Epoch 1, Batch 8800, Loss: 0.8041\n",
            "Epoch 1, Batch 8900, Loss: 0.9325\n",
            "Epoch 1, Batch 9000, Loss: 1.0823\n",
            "Epoch 1, Batch 9100, Loss: 0.9575\n",
            "Epoch 1, Batch 9200, Loss: 0.9654\n",
            "Epoch 1, Batch 9300, Loss: 0.8360\n",
            "Epoch 1, Batch 9400, Loss: 1.3051\n",
            "Epoch 1, Batch 9500, Loss: 1.3113\n",
            "Epoch 1, Batch 9600, Loss: 0.6741\n",
            "Epoch 1, Batch 9700, Loss: 1.1282\n",
            "Epoch 1, Batch 9800, Loss: 1.2638\n",
            "Epoch 1, Batch 9900, Loss: 1.2406\n",
            "Epoch 1, Batch 10000, Loss: 1.1030\n",
            "Epoch 1, Batch 10100, Loss: 1.2060\n",
            "Epoch 1, Batch 10200, Loss: 0.7675\n",
            "Epoch 1, Batch 10300, Loss: 0.9986\n",
            "Epoch 1, Batch 10400, Loss: 1.6738\n",
            "Epoch 1/10, Avg Loss: 1.0885\n",
            "Epoch 2, Batch 0, Loss: 0.8246\n",
            "Epoch 2, Batch 100, Loss: 0.7864\n",
            "Epoch 2, Batch 200, Loss: 0.8437\n",
            "Epoch 2, Batch 300, Loss: 0.9995\n",
            "Epoch 2, Batch 400, Loss: 0.3837\n",
            "Epoch 2, Batch 500, Loss: 0.9536\n",
            "Epoch 2, Batch 600, Loss: 0.9426\n",
            "Epoch 2, Batch 700, Loss: 1.5582\n",
            "Epoch 2, Batch 800, Loss: 1.2447\n",
            "Epoch 2, Batch 900, Loss: 0.7743\n",
            "Epoch 2, Batch 1000, Loss: 0.7339\n",
            "Epoch 2, Batch 1100, Loss: 0.9878\n",
            "Epoch 2, Batch 1200, Loss: 0.7420\n",
            "Epoch 2, Batch 1300, Loss: 0.7660\n",
            "Epoch 2, Batch 1400, Loss: 1.1706\n",
            "Epoch 2, Batch 1500, Loss: 0.8719\n",
            "Epoch 2, Batch 1600, Loss: 1.0505\n",
            "Epoch 2, Batch 1700, Loss: 0.9044\n",
            "Epoch 2, Batch 1800, Loss: 0.9499\n",
            "Epoch 2, Batch 1900, Loss: 0.6765\n",
            "Epoch 2, Batch 2000, Loss: 0.5084\n",
            "Epoch 2, Batch 2100, Loss: 0.5591\n",
            "Epoch 2, Batch 2200, Loss: 0.8694\n",
            "Epoch 2, Batch 2300, Loss: 0.5441\n",
            "Epoch 2, Batch 2400, Loss: 0.8805\n",
            "Epoch 2, Batch 2500, Loss: 0.7126\n",
            "Epoch 2, Batch 2600, Loss: 0.9294\n",
            "Epoch 2, Batch 2700, Loss: 0.7114\n",
            "Epoch 2, Batch 2800, Loss: 0.7850\n",
            "Epoch 2, Batch 2900, Loss: 1.1114\n",
            "Epoch 2, Batch 3000, Loss: 1.1398\n",
            "Epoch 2, Batch 3100, Loss: 0.7188\n",
            "Epoch 2, Batch 3200, Loss: 0.8314\n",
            "Epoch 2, Batch 3300, Loss: 0.8870\n",
            "Epoch 2, Batch 3400, Loss: 1.5277\n",
            "Epoch 2, Batch 3500, Loss: 0.8934\n",
            "Epoch 2, Batch 3600, Loss: 1.0661\n",
            "Epoch 2, Batch 3700, Loss: 0.7938\n",
            "Epoch 2, Batch 3800, Loss: 0.5833\n",
            "Epoch 2, Batch 3900, Loss: 1.1107\n",
            "Epoch 2, Batch 4000, Loss: 1.0107\n",
            "Epoch 2, Batch 4100, Loss: 0.6413\n",
            "Epoch 2, Batch 4200, Loss: 0.9168\n",
            "Epoch 2, Batch 4300, Loss: 1.1694\n",
            "Epoch 2, Batch 4400, Loss: 0.8561\n",
            "Epoch 2, Batch 4500, Loss: 1.1335\n",
            "Epoch 2, Batch 4600, Loss: 1.3141\n",
            "Epoch 2, Batch 4700, Loss: 0.7496\n",
            "Epoch 2, Batch 4800, Loss: 0.8211\n",
            "Epoch 2, Batch 4900, Loss: 0.8150\n",
            "Epoch 2, Batch 5000, Loss: 1.0343\n",
            "Epoch 2, Batch 5100, Loss: 0.7166\n",
            "Epoch 2, Batch 5200, Loss: 0.5472\n",
            "Epoch 2, Batch 5300, Loss: 0.9398\n",
            "Epoch 2, Batch 5400, Loss: 1.1610\n",
            "Epoch 2, Batch 5500, Loss: 1.1528\n",
            "Epoch 2, Batch 5600, Loss: 0.8398\n",
            "Epoch 2, Batch 5700, Loss: 0.9156\n",
            "Epoch 2, Batch 5800, Loss: 0.8727\n",
            "Epoch 2, Batch 5900, Loss: 1.4884\n",
            "Epoch 2, Batch 6000, Loss: 0.6381\n",
            "Epoch 2, Batch 6100, Loss: 1.6968\n",
            "Epoch 2, Batch 6200, Loss: 0.6325\n",
            "Epoch 2, Batch 6300, Loss: 0.8587\n",
            "Epoch 2, Batch 6400, Loss: 0.4008\n",
            "Epoch 2, Batch 6500, Loss: 1.3971\n",
            "Epoch 2, Batch 6600, Loss: 0.8631\n",
            "Epoch 2, Batch 6700, Loss: 0.9683\n",
            "Epoch 2, Batch 6800, Loss: 0.9048\n",
            "Epoch 2, Batch 6900, Loss: 0.9821\n",
            "Epoch 2, Batch 7000, Loss: 1.2941\n",
            "Epoch 2, Batch 7100, Loss: 0.7097\n",
            "Epoch 2, Batch 7200, Loss: 0.5767\n",
            "Epoch 2, Batch 7300, Loss: 0.7594\n",
            "Epoch 2, Batch 7400, Loss: 0.9489\n",
            "Epoch 2, Batch 7500, Loss: 1.1497\n",
            "Epoch 2, Batch 7600, Loss: 0.7166\n",
            "Epoch 2, Batch 7700, Loss: 3.3084\n",
            "Epoch 2, Batch 7800, Loss: 1.1822\n",
            "Epoch 2, Batch 7900, Loss: 1.0420\n",
            "Epoch 2, Batch 8000, Loss: 0.7039\n",
            "Epoch 2, Batch 8100, Loss: 2.7182\n",
            "Epoch 2, Batch 8200, Loss: 0.8457\n",
            "Epoch 2, Batch 8300, Loss: 1.3614\n",
            "Epoch 2, Batch 8400, Loss: 2.2272\n",
            "Epoch 2, Batch 8500, Loss: 0.8028\n",
            "Epoch 2, Batch 8600, Loss: 1.4905\n",
            "Epoch 2, Batch 8700, Loss: 0.8532\n",
            "Epoch 2, Batch 8800, Loss: 1.2406\n",
            "Epoch 2, Batch 8900, Loss: 0.8082\n",
            "Epoch 2, Batch 9000, Loss: 1.9199\n",
            "Epoch 2, Batch 9100, Loss: 0.6849\n",
            "Epoch 2, Batch 9200, Loss: 0.8395\n",
            "Epoch 2, Batch 9300, Loss: 0.9004\n",
            "Epoch 2, Batch 9400, Loss: 1.2367\n",
            "Epoch 2, Batch 9500, Loss: 0.8870\n",
            "Epoch 2, Batch 9600, Loss: 0.6123\n",
            "Epoch 2, Batch 9700, Loss: 0.8854\n",
            "Epoch 2, Batch 9800, Loss: 0.6695\n",
            "Epoch 2, Batch 9900, Loss: 0.6971\n",
            "Epoch 2, Batch 10000, Loss: 0.9302\n",
            "Epoch 2, Batch 10100, Loss: 0.6376\n",
            "Epoch 2, Batch 10200, Loss: 1.2016\n",
            "Epoch 2, Batch 10300, Loss: 0.8878\n",
            "Epoch 2, Batch 10400, Loss: 0.7515\n",
            "Epoch 2/10, Avg Loss: 0.9530\n",
            "Epoch 3, Batch 0, Loss: 0.7489\n",
            "Epoch 3, Batch 100, Loss: 0.8453\n",
            "Epoch 3, Batch 200, Loss: 1.1077\n",
            "Epoch 3, Batch 300, Loss: 0.6285\n",
            "Epoch 3, Batch 400, Loss: 0.7440\n",
            "Epoch 3, Batch 500, Loss: 1.1821\n",
            "Epoch 3, Batch 600, Loss: 0.9069\n",
            "Epoch 3, Batch 700, Loss: 0.5047\n",
            "Epoch 3, Batch 800, Loss: 0.8748\n",
            "Epoch 3, Batch 900, Loss: 0.8021\n",
            "Epoch 3, Batch 1000, Loss: 0.7879\n",
            "Epoch 3, Batch 1100, Loss: 0.7186\n",
            "Epoch 3, Batch 1200, Loss: 0.9732\n",
            "Epoch 3, Batch 1300, Loss: 2.4768\n",
            "Epoch 3, Batch 1400, Loss: 1.7884\n",
            "Epoch 3, Batch 1500, Loss: 0.8153\n",
            "Epoch 3, Batch 1600, Loss: 0.5118\n",
            "Epoch 3, Batch 1700, Loss: 0.9265\n",
            "Epoch 3, Batch 1800, Loss: 0.6762\n",
            "Epoch 3, Batch 1900, Loss: 0.6153\n",
            "Epoch 3, Batch 2000, Loss: 0.8684\n",
            "Epoch 3, Batch 2100, Loss: 0.9775\n",
            "Epoch 3, Batch 2200, Loss: 0.8889\n",
            "Epoch 3, Batch 2300, Loss: 0.7739\n",
            "Epoch 3, Batch 2400, Loss: 0.5550\n",
            "Epoch 3, Batch 2500, Loss: 1.0386\n",
            "Epoch 3, Batch 2600, Loss: 0.9390\n",
            "Epoch 3, Batch 2700, Loss: 0.8866\n",
            "Epoch 3, Batch 2800, Loss: 1.0228\n",
            "Epoch 3, Batch 2900, Loss: 0.7573\n",
            "Epoch 3, Batch 3000, Loss: 1.3775\n",
            "Epoch 3, Batch 3100, Loss: 0.6701\n",
            "Epoch 3, Batch 3200, Loss: 0.7145\n",
            "Epoch 3, Batch 3300, Loss: 0.7012\n",
            "Epoch 3, Batch 3400, Loss: 1.0941\n",
            "Epoch 3, Batch 3500, Loss: 0.9018\n",
            "Epoch 3, Batch 3600, Loss: 0.8879\n",
            "Epoch 3, Batch 3700, Loss: 0.9351\n",
            "Epoch 3, Batch 3800, Loss: 0.8758\n",
            "Epoch 3, Batch 3900, Loss: 0.7181\n",
            "Epoch 3, Batch 4000, Loss: 0.9789\n",
            "Epoch 3, Batch 4100, Loss: 0.8056\n",
            "Epoch 3, Batch 4200, Loss: 0.7862\n",
            "Epoch 3, Batch 4300, Loss: 0.7111\n",
            "Epoch 3, Batch 4400, Loss: 0.5528\n",
            "Epoch 3, Batch 4500, Loss: 0.6304\n",
            "Epoch 3, Batch 4600, Loss: 1.2820\n",
            "Epoch 3, Batch 4700, Loss: 2.2592\n",
            "Epoch 3, Batch 4800, Loss: 2.1349\n",
            "Epoch 3, Batch 4900, Loss: 1.2688\n",
            "Epoch 3, Batch 5000, Loss: 3.3778\n",
            "Epoch 3, Batch 5100, Loss: 1.1873\n",
            "Epoch 3, Batch 5200, Loss: 0.6423\n",
            "Epoch 3, Batch 5300, Loss: 1.4607\n",
            "Epoch 3, Batch 5400, Loss: 0.4076\n",
            "Epoch 3, Batch 5500, Loss: 1.0836\n",
            "Epoch 3, Batch 5600, Loss: 0.8316\n",
            "Epoch 3, Batch 5700, Loss: 1.0870\n",
            "Epoch 3, Batch 5800, Loss: 1.1500\n",
            "Epoch 3, Batch 5900, Loss: 1.1305\n",
            "Epoch 3, Batch 6000, Loss: 0.8586\n",
            "Epoch 3, Batch 6100, Loss: 0.5447\n",
            "Epoch 3, Batch 6200, Loss: 0.6901\n",
            "Epoch 3, Batch 6300, Loss: 0.6864\n",
            "Epoch 3, Batch 6400, Loss: 1.8049\n",
            "Epoch 3, Batch 6500, Loss: 0.8530\n",
            "Epoch 3, Batch 6600, Loss: 0.7090\n",
            "Epoch 3, Batch 6700, Loss: 1.4837\n",
            "Epoch 3, Batch 6800, Loss: 0.6711\n",
            "Epoch 3, Batch 6900, Loss: 1.2026\n",
            "Epoch 3, Batch 7000, Loss: 1.3506\n",
            "Epoch 3, Batch 7100, Loss: 0.9522\n",
            "Epoch 3, Batch 7200, Loss: 0.7768\n",
            "Epoch 3, Batch 7300, Loss: 1.2478\n",
            "Epoch 3, Batch 7400, Loss: 0.7081\n",
            "Epoch 3, Batch 7500, Loss: 0.5178\n",
            "Epoch 3, Batch 7600, Loss: 0.8026\n",
            "Epoch 3, Batch 7700, Loss: 0.6108\n",
            "Epoch 3, Batch 7800, Loss: 0.7303\n",
            "Epoch 3, Batch 7900, Loss: 0.8357\n",
            "Epoch 3, Batch 8000, Loss: 1.7447\n",
            "Epoch 3, Batch 8100, Loss: 0.5725\n",
            "Epoch 3, Batch 8200, Loss: 0.5835\n",
            "Epoch 3, Batch 8300, Loss: 0.8120\n",
            "Epoch 3, Batch 8400, Loss: 0.6434\n",
            "Epoch 3, Batch 8500, Loss: 3.3465\n",
            "Epoch 3, Batch 8600, Loss: 0.4498\n",
            "Epoch 3, Batch 8700, Loss: 0.7340\n",
            "Epoch 3, Batch 8800, Loss: 0.5259\n",
            "Epoch 3, Batch 8900, Loss: 0.8061\n",
            "Epoch 3, Batch 9000, Loss: 1.0176\n",
            "Epoch 3, Batch 9100, Loss: 1.8812\n",
            "Epoch 3, Batch 9200, Loss: 0.5006\n",
            "Epoch 3, Batch 9300, Loss: 0.8279\n",
            "Epoch 3, Batch 9400, Loss: 1.3011\n",
            "Epoch 3, Batch 9500, Loss: 1.0617\n",
            "Epoch 3, Batch 9600, Loss: 0.7900\n",
            "Epoch 3, Batch 9700, Loss: 0.4961\n",
            "Epoch 3, Batch 9800, Loss: 0.9032\n",
            "Epoch 3, Batch 9900, Loss: 0.6029\n",
            "Epoch 3, Batch 10000, Loss: 0.6581\n",
            "Epoch 3, Batch 10100, Loss: 1.2421\n",
            "Epoch 3, Batch 10200, Loss: 0.6553\n",
            "Epoch 3, Batch 10300, Loss: 0.7762\n",
            "Epoch 3, Batch 10400, Loss: 0.4336\n",
            "Epoch 3/10, Avg Loss: 0.8950\n",
            "Epoch 4, Batch 0, Loss: 0.7139\n",
            "Epoch 4, Batch 100, Loss: 0.6393\n",
            "Epoch 4, Batch 200, Loss: 0.6253\n",
            "Epoch 4, Batch 300, Loss: 0.3953\n",
            "Epoch 4, Batch 400, Loss: 0.7528\n",
            "Epoch 4, Batch 500, Loss: 0.6082\n",
            "Epoch 4, Batch 600, Loss: 0.6350\n",
            "Epoch 4, Batch 700, Loss: 0.4448\n",
            "Epoch 4, Batch 800, Loss: 1.1365\n",
            "Epoch 4, Batch 900, Loss: 0.7644\n",
            "Epoch 4, Batch 1000, Loss: 0.6750\n",
            "Epoch 4, Batch 1100, Loss: 0.4540\n",
            "Epoch 4, Batch 1200, Loss: 1.1093\n",
            "Epoch 4, Batch 1300, Loss: 1.3312\n",
            "Epoch 4, Batch 1400, Loss: 0.5619\n",
            "Epoch 4, Batch 1500, Loss: 0.6936\n",
            "Epoch 4, Batch 1600, Loss: 0.6095\n",
            "Epoch 4, Batch 1700, Loss: 1.0910\n",
            "Epoch 4, Batch 1800, Loss: 0.8953\n",
            "Epoch 4, Batch 1900, Loss: 1.2691\n",
            "Epoch 4, Batch 2000, Loss: 0.6678\n",
            "Epoch 4, Batch 2100, Loss: 0.7529\n",
            "Epoch 4, Batch 2200, Loss: 0.6046\n",
            "Epoch 4, Batch 2300, Loss: 1.0343\n",
            "Epoch 4, Batch 2400, Loss: 0.7092\n",
            "Epoch 4, Batch 2500, Loss: 1.0192\n",
            "Epoch 4, Batch 2600, Loss: 0.7235\n",
            "Epoch 4, Batch 2700, Loss: 1.1548\n",
            "Epoch 4, Batch 2800, Loss: 0.5854\n",
            "Epoch 4, Batch 2900, Loss: 1.0934\n",
            "Epoch 4, Batch 3000, Loss: 0.5594\n",
            "Epoch 4, Batch 3100, Loss: 0.9448\n",
            "Epoch 4, Batch 3200, Loss: 0.7805\n",
            "Epoch 4, Batch 3300, Loss: 0.6238\n",
            "Epoch 4, Batch 3400, Loss: 1.2264\n",
            "Epoch 4, Batch 3500, Loss: 0.7152\n",
            "Epoch 4, Batch 3600, Loss: 0.6672\n",
            "Epoch 4, Batch 3700, Loss: 0.8370\n",
            "Epoch 4, Batch 3800, Loss: 1.4032\n",
            "Epoch 4, Batch 3900, Loss: 0.7882\n",
            "Epoch 4, Batch 4000, Loss: 1.1292\n",
            "Epoch 4, Batch 4100, Loss: 0.8585\n",
            "Epoch 4, Batch 4200, Loss: 0.7296\n",
            "Epoch 4, Batch 4300, Loss: 0.8433\n",
            "Epoch 4, Batch 4400, Loss: 0.7107\n",
            "Epoch 4, Batch 4500, Loss: 1.1672\n",
            "Epoch 4, Batch 4600, Loss: 0.8699\n",
            "Epoch 4, Batch 4700, Loss: 0.8234\n",
            "Epoch 4, Batch 4800, Loss: 0.7450\n",
            "Epoch 4, Batch 4900, Loss: 0.5339\n",
            "Epoch 4, Batch 5000, Loss: 0.4973\n",
            "Epoch 4, Batch 5100, Loss: 0.7589\n",
            "Epoch 4, Batch 5200, Loss: 0.8453\n",
            "Epoch 4, Batch 5300, Loss: 0.4835\n",
            "Epoch 4, Batch 5400, Loss: 0.8007\n",
            "Epoch 4, Batch 5500, Loss: 0.7464\n",
            "Epoch 4, Batch 5600, Loss: 1.0752\n",
            "Epoch 4, Batch 5700, Loss: 0.8431\n",
            "Epoch 4, Batch 5800, Loss: 0.8167\n",
            "Epoch 4, Batch 5900, Loss: 0.6902\n",
            "Epoch 4, Batch 6000, Loss: 1.2476\n",
            "Epoch 4, Batch 6100, Loss: 0.5100\n",
            "Epoch 4, Batch 6200, Loss: 0.9660\n",
            "Epoch 4, Batch 6300, Loss: 0.8420\n",
            "Epoch 4, Batch 6400, Loss: 0.6596\n",
            "Epoch 4, Batch 6500, Loss: 0.7960\n",
            "Epoch 4, Batch 6600, Loss: 0.7849\n",
            "Epoch 4, Batch 6700, Loss: 1.2346\n",
            "Epoch 4, Batch 6800, Loss: 0.6552\n",
            "Epoch 4, Batch 6900, Loss: 0.7334\n",
            "Epoch 4, Batch 7000, Loss: 0.5068\n",
            "Epoch 4, Batch 7100, Loss: 0.8577\n",
            "Epoch 4, Batch 7200, Loss: 0.4281\n",
            "Epoch 4, Batch 7300, Loss: 0.6397\n",
            "Epoch 4, Batch 7400, Loss: 1.4705\n",
            "Epoch 4, Batch 7500, Loss: 0.6152\n",
            "Epoch 4, Batch 7600, Loss: 0.7229\n",
            "Epoch 4, Batch 7700, Loss: 0.8756\n",
            "Epoch 4, Batch 7800, Loss: 1.8260\n",
            "Epoch 4, Batch 7900, Loss: 0.7501\n",
            "Epoch 4, Batch 8000, Loss: 0.8482\n",
            "Epoch 4, Batch 8100, Loss: 1.1645\n",
            "Epoch 4, Batch 8200, Loss: 0.5638\n",
            "Epoch 4, Batch 8300, Loss: 0.8294\n",
            "Epoch 4, Batch 8400, Loss: 0.7694\n",
            "Epoch 4, Batch 8500, Loss: 1.2169\n",
            "Epoch 4, Batch 8600, Loss: 0.6735\n",
            "Epoch 4, Batch 8700, Loss: 0.7557\n",
            "Epoch 4, Batch 8800, Loss: 0.7644\n",
            "Epoch 4, Batch 8900, Loss: 0.8736\n",
            "Epoch 4, Batch 9000, Loss: 1.2153\n",
            "Epoch 4, Batch 9100, Loss: 0.5461\n",
            "Epoch 4, Batch 9200, Loss: 0.5823\n",
            "Epoch 4, Batch 9300, Loss: 1.3158\n",
            "Epoch 4, Batch 9400, Loss: 0.9200\n",
            "Epoch 4, Batch 9500, Loss: 0.6550\n",
            "Epoch 4, Batch 9600, Loss: 0.6338\n",
            "Epoch 4, Batch 9700, Loss: 0.5390\n",
            "Epoch 4, Batch 9800, Loss: 0.8208\n",
            "Epoch 4, Batch 9900, Loss: 0.4679\n",
            "Epoch 4, Batch 10000, Loss: 1.0446\n",
            "Epoch 4, Batch 10100, Loss: 0.7977\n",
            "Epoch 4, Batch 10200, Loss: 0.5958\n",
            "Epoch 4, Batch 10300, Loss: 0.6830\n",
            "Epoch 4, Batch 10400, Loss: 0.8952\n",
            "Epoch 4/10, Avg Loss: 0.8440\n",
            "Epoch 5, Batch 0, Loss: 0.8501\n",
            "Epoch 5, Batch 100, Loss: 0.8426\n",
            "Epoch 5, Batch 200, Loss: 0.8282\n",
            "Epoch 5, Batch 300, Loss: 0.7164\n",
            "Epoch 5, Batch 400, Loss: 0.8902\n",
            "Epoch 5, Batch 500, Loss: 0.7105\n",
            "Epoch 5, Batch 600, Loss: 0.9733\n",
            "Epoch 5, Batch 700, Loss: 0.7015\n",
            "Epoch 5, Batch 800, Loss: 0.3718\n",
            "Epoch 5, Batch 900, Loss: 0.4343\n",
            "Epoch 5, Batch 1000, Loss: 0.8364\n",
            "Epoch 5, Batch 1100, Loss: 0.6490\n",
            "Epoch 5, Batch 1200, Loss: 0.8833\n",
            "Epoch 5, Batch 1300, Loss: 1.0037\n",
            "Epoch 5, Batch 1400, Loss: 0.7573\n",
            "Epoch 5, Batch 1500, Loss: 0.8265\n",
            "Epoch 5, Batch 1600, Loss: 0.9609\n",
            "Epoch 5, Batch 1700, Loss: 1.5328\n",
            "Epoch 5, Batch 1800, Loss: 2.3179\n",
            "Epoch 5, Batch 1900, Loss: 0.3061\n",
            "Epoch 5, Batch 2000, Loss: 0.5282\n",
            "Epoch 5, Batch 2100, Loss: 0.6802\n",
            "Epoch 5, Batch 2200, Loss: 0.5311\n",
            "Epoch 5, Batch 2300, Loss: 1.4750\n",
            "Epoch 5, Batch 2400, Loss: 0.4634\n",
            "Epoch 5, Batch 2500, Loss: 0.4353\n",
            "Epoch 5, Batch 2600, Loss: 0.4053\n",
            "Epoch 5, Batch 2700, Loss: 0.5778\n",
            "Epoch 5, Batch 2800, Loss: 0.4152\n",
            "Epoch 5, Batch 2900, Loss: 0.5887\n",
            "Epoch 5, Batch 3000, Loss: 0.6927\n",
            "Epoch 5, Batch 3100, Loss: 0.5178\n",
            "Epoch 5, Batch 3200, Loss: 0.5958\n",
            "Epoch 5, Batch 3300, Loss: 0.8175\n",
            "Epoch 5, Batch 3400, Loss: 0.7551\n",
            "Epoch 5, Batch 3500, Loss: 0.3813\n",
            "Epoch 5, Batch 3600, Loss: 0.8328\n",
            "Epoch 5, Batch 3700, Loss: 0.8684\n",
            "Epoch 5, Batch 3800, Loss: 0.4907\n",
            "Epoch 5, Batch 3900, Loss: 0.8343\n",
            "Epoch 5, Batch 4000, Loss: 0.3241\n",
            "Epoch 5, Batch 4100, Loss: 0.4276\n",
            "Epoch 5, Batch 4200, Loss: 0.4940\n",
            "Epoch 5, Batch 4300, Loss: 1.1702\n",
            "Epoch 5, Batch 4400, Loss: 0.6811\n",
            "Epoch 5, Batch 4500, Loss: 1.2673\n",
            "Epoch 5, Batch 4600, Loss: 1.1561\n",
            "Epoch 5, Batch 4700, Loss: 0.6703\n",
            "Epoch 5, Batch 4800, Loss: 1.6394\n",
            "Epoch 5, Batch 4900, Loss: 0.6338\n",
            "Epoch 5, Batch 5000, Loss: 2.2264\n",
            "Epoch 5, Batch 5100, Loss: 0.4445\n",
            "Epoch 5, Batch 5200, Loss: 0.7166\n",
            "Epoch 5, Batch 5300, Loss: 1.1108\n",
            "Epoch 5, Batch 5400, Loss: 0.4917\n",
            "Epoch 5, Batch 5500, Loss: 1.2945\n",
            "Epoch 5, Batch 5600, Loss: 1.3439\n",
            "Epoch 5, Batch 5700, Loss: 1.0429\n",
            "Epoch 5, Batch 5800, Loss: 0.5714\n",
            "Epoch 5, Batch 5900, Loss: 0.6645\n",
            "Epoch 5, Batch 6000, Loss: 0.7283\n",
            "Epoch 5, Batch 6100, Loss: 0.5582\n",
            "Epoch 5, Batch 6200, Loss: 0.5571\n",
            "Epoch 5, Batch 6300, Loss: 0.8929\n",
            "Epoch 5, Batch 6400, Loss: 0.8683\n",
            "Epoch 5, Batch 6500, Loss: 0.5251\n",
            "Epoch 5, Batch 6600, Loss: 0.5982\n",
            "Epoch 5, Batch 6700, Loss: 0.7508\n",
            "Epoch 5, Batch 6800, Loss: 1.4077\n",
            "Epoch 5, Batch 6900, Loss: 1.0132\n",
            "Epoch 5, Batch 7000, Loss: 0.5659\n",
            "Epoch 5, Batch 7100, Loss: 1.0979\n",
            "Epoch 5, Batch 7200, Loss: 0.7926\n",
            "Epoch 5, Batch 7300, Loss: 0.8427\n",
            "Epoch 5, Batch 7400, Loss: 0.7251\n",
            "Epoch 5, Batch 7500, Loss: 0.6608\n",
            "Epoch 5, Batch 7600, Loss: 0.5751\n",
            "Epoch 5, Batch 7700, Loss: 0.6344\n",
            "Epoch 5, Batch 7800, Loss: 0.6079\n",
            "Epoch 5, Batch 7900, Loss: 0.7021\n",
            "Epoch 5, Batch 8000, Loss: 0.5527\n",
            "Epoch 5, Batch 8100, Loss: 1.1705\n",
            "Epoch 5, Batch 8200, Loss: 0.8007\n",
            "Epoch 5, Batch 8300, Loss: 0.8696\n",
            "Epoch 5, Batch 8400, Loss: 0.6368\n",
            "Epoch 5, Batch 8500, Loss: 0.7070\n",
            "Epoch 5, Batch 8600, Loss: 0.3503\n",
            "Epoch 5, Batch 8700, Loss: 0.4064\n",
            "Epoch 5, Batch 8800, Loss: 0.6564\n",
            "Epoch 5, Batch 8900, Loss: 0.7782\n",
            "Epoch 5, Batch 9000, Loss: 0.5894\n",
            "Epoch 5, Batch 9100, Loss: 0.4477\n",
            "Epoch 5, Batch 9200, Loss: 0.5587\n",
            "Epoch 5, Batch 9300, Loss: 0.6525\n",
            "Epoch 5, Batch 9400, Loss: 0.8978\n",
            "Epoch 5, Batch 9500, Loss: 0.9808\n",
            "Epoch 5, Batch 9600, Loss: 0.5620\n",
            "Epoch 5, Batch 9700, Loss: 0.5651\n",
            "Epoch 5, Batch 9800, Loss: 0.6581\n",
            "Epoch 5, Batch 9900, Loss: 0.4185\n",
            "Epoch 5, Batch 10000, Loss: 1.2087\n",
            "Epoch 5, Batch 10100, Loss: 0.6856\n",
            "Epoch 5, Batch 10200, Loss: 0.4840\n",
            "Epoch 5, Batch 10300, Loss: 0.5435\n",
            "Epoch 5, Batch 10400, Loss: 0.4248\n",
            "Epoch 5/10, Avg Loss: 0.7980\n",
            "Epoch 6, Batch 0, Loss: 0.6804\n",
            "Epoch 6, Batch 100, Loss: 0.5812\n",
            "Epoch 6, Batch 200, Loss: 0.9257\n",
            "Epoch 6, Batch 300, Loss: 0.4909\n",
            "Epoch 6, Batch 400, Loss: 0.7920\n",
            "Epoch 6, Batch 500, Loss: 0.8284\n",
            "Epoch 6, Batch 600, Loss: 0.5811\n",
            "Epoch 6, Batch 700, Loss: 0.3581\n",
            "Epoch 6, Batch 800, Loss: 0.4973\n",
            "Epoch 6, Batch 900, Loss: 0.8026\n",
            "Epoch 6, Batch 1000, Loss: 0.6716\n",
            "Epoch 6, Batch 1100, Loss: 0.2882\n",
            "Epoch 6, Batch 1200, Loss: 0.9658\n",
            "Epoch 6, Batch 1300, Loss: 0.6357\n",
            "Epoch 6, Batch 1400, Loss: 0.7886\n",
            "Epoch 6, Batch 1500, Loss: 0.9725\n",
            "Epoch 6, Batch 1600, Loss: 0.7378\n",
            "Epoch 6, Batch 1700, Loss: 0.4927\n",
            "Epoch 6, Batch 1800, Loss: 0.6436\n",
            "Epoch 6, Batch 1900, Loss: 0.8391\n",
            "Epoch 6, Batch 2000, Loss: 0.4097\n",
            "Epoch 6, Batch 2100, Loss: 0.7799\n",
            "Epoch 6, Batch 2200, Loss: 0.6496\n",
            "Epoch 6, Batch 2300, Loss: 0.7752\n",
            "Epoch 6, Batch 2400, Loss: 0.6135\n",
            "Epoch 6, Batch 2500, Loss: 0.8411\n",
            "Epoch 6, Batch 2600, Loss: 0.5260\n",
            "Epoch 6, Batch 2700, Loss: 0.6987\n",
            "Epoch 6, Batch 2800, Loss: 0.5727\n",
            "Epoch 6, Batch 2900, Loss: 0.5165\n",
            "Epoch 6, Batch 3000, Loss: 0.4805\n",
            "Epoch 6, Batch 3100, Loss: 0.7852\n",
            "Epoch 6, Batch 3200, Loss: 1.2477\n",
            "Epoch 6, Batch 3300, Loss: 0.8849\n",
            "Epoch 6, Batch 3400, Loss: 0.7756\n",
            "Epoch 6, Batch 3500, Loss: 0.5786\n",
            "Epoch 6, Batch 3600, Loss: 0.7290\n",
            "Epoch 6, Batch 3700, Loss: 0.6802\n",
            "Epoch 6, Batch 3800, Loss: 0.4320\n",
            "Epoch 6, Batch 3900, Loss: 0.7394\n",
            "Epoch 6, Batch 4000, Loss: 0.6757\n",
            "Epoch 6, Batch 4100, Loss: 0.5643\n",
            "Epoch 6, Batch 4200, Loss: 2.7368\n",
            "Epoch 6, Batch 4300, Loss: 0.4635\n",
            "Epoch 6, Batch 4400, Loss: 0.9192\n",
            "Epoch 6, Batch 4500, Loss: 0.8771\n",
            "Epoch 6, Batch 4600, Loss: 0.5127\n",
            "Epoch 6, Batch 4700, Loss: 0.7989\n",
            "Epoch 6, Batch 4800, Loss: 0.8275\n",
            "Epoch 6, Batch 4900, Loss: 0.3439\n",
            "Epoch 6, Batch 5000, Loss: 1.4082\n",
            "Epoch 6, Batch 5100, Loss: 1.5848\n",
            "Epoch 6, Batch 5200, Loss: 0.3821\n",
            "Epoch 6, Batch 5300, Loss: 0.9037\n",
            "Epoch 6, Batch 5400, Loss: 0.5017\n",
            "Epoch 6, Batch 5500, Loss: 0.4486\n",
            "Epoch 6, Batch 5600, Loss: 0.6173\n",
            "Epoch 6, Batch 5700, Loss: 0.6462\n",
            "Epoch 6, Batch 5800, Loss: 0.7353\n",
            "Epoch 6, Batch 5900, Loss: 1.2975\n",
            "Epoch 6, Batch 6000, Loss: 0.4988\n",
            "Epoch 6, Batch 6100, Loss: 0.5249\n",
            "Epoch 6, Batch 6200, Loss: 0.5877\n",
            "Epoch 6, Batch 6300, Loss: 0.8776\n",
            "Epoch 6, Batch 6400, Loss: 0.5637\n",
            "Epoch 6, Batch 6500, Loss: 0.5979\n",
            "Epoch 6, Batch 6600, Loss: 0.7982\n",
            "Epoch 6, Batch 6700, Loss: 0.6942\n",
            "Epoch 6, Batch 6800, Loss: 0.7157\n",
            "Epoch 6, Batch 6900, Loss: 0.5984\n",
            "Epoch 6, Batch 7000, Loss: 0.9156\n",
            "Epoch 6, Batch 7100, Loss: 0.9831\n",
            "Epoch 6, Batch 7200, Loss: 0.8076\n",
            "Epoch 6, Batch 7300, Loss: 0.6128\n",
            "Epoch 6, Batch 7400, Loss: 0.5736\n",
            "Epoch 6, Batch 7500, Loss: 0.3976\n",
            "Epoch 6, Batch 7600, Loss: 0.8875\n",
            "Epoch 6, Batch 7700, Loss: 0.4029\n",
            "Epoch 6, Batch 7800, Loss: 1.0820\n",
            "Epoch 6, Batch 7900, Loss: 0.8153\n",
            "Epoch 6, Batch 8000, Loss: 0.9856\n",
            "Epoch 6, Batch 8100, Loss: 0.3415\n",
            "Epoch 6, Batch 8200, Loss: 1.2719\n",
            "Epoch 6, Batch 8300, Loss: 0.6869\n",
            "Epoch 6, Batch 8400, Loss: 0.3262\n",
            "Epoch 6, Batch 8500, Loss: 1.1552\n",
            "Epoch 6, Batch 8600, Loss: 0.7001\n",
            "Epoch 6, Batch 8700, Loss: 1.0539\n",
            "Epoch 6, Batch 8800, Loss: 0.3792\n",
            "Epoch 6, Batch 8900, Loss: 0.5471\n",
            "Epoch 6, Batch 9000, Loss: 2.1122\n",
            "Epoch 6, Batch 9100, Loss: 1.2406\n",
            "Epoch 6, Batch 9200, Loss: 0.9900\n",
            "Epoch 6, Batch 9300, Loss: 0.7091\n",
            "Epoch 6, Batch 9400, Loss: 0.6947\n",
            "Epoch 6, Batch 9500, Loss: 0.6654\n",
            "Epoch 6, Batch 9600, Loss: 0.3220\n",
            "Epoch 6, Batch 9700, Loss: 0.7011\n",
            "Epoch 6, Batch 9800, Loss: 0.6186\n",
            "Epoch 6, Batch 9900, Loss: 1.0189\n",
            "Epoch 6, Batch 10000, Loss: 0.4438\n",
            "Epoch 6, Batch 10100, Loss: 0.8006\n",
            "Epoch 6, Batch 10200, Loss: 0.5624\n",
            "Epoch 6, Batch 10300, Loss: 0.6822\n",
            "Epoch 6, Batch 10400, Loss: 0.3483\n",
            "Epoch 6/10, Avg Loss: 0.7564\n",
            "Epoch 7, Batch 0, Loss: 0.5166\n",
            "Epoch 7, Batch 100, Loss: 0.7074\n",
            "Epoch 7, Batch 200, Loss: 0.7249\n",
            "Epoch 7, Batch 300, Loss: 0.6234\n",
            "Epoch 7, Batch 400, Loss: 0.7622\n",
            "Epoch 7, Batch 500, Loss: 3.2603\n",
            "Epoch 7, Batch 600, Loss: 1.0676\n",
            "Epoch 7, Batch 700, Loss: 0.4790\n",
            "Epoch 7, Batch 800, Loss: 0.6807\n",
            "Epoch 7, Batch 900, Loss: 0.6950\n",
            "Epoch 7, Batch 1000, Loss: 0.2894\n",
            "Epoch 7, Batch 1100, Loss: 0.2763\n",
            "Epoch 7, Batch 1200, Loss: 0.5608\n",
            "Epoch 7, Batch 1300, Loss: 0.4066\n",
            "Epoch 7, Batch 1400, Loss: 0.2664\n",
            "Epoch 7, Batch 1500, Loss: 0.4776\n",
            "Epoch 7, Batch 1600, Loss: 0.6926\n",
            "Epoch 7, Batch 1700, Loss: 0.4794\n",
            "Epoch 7, Batch 1800, Loss: 0.5998\n",
            "Epoch 7, Batch 1900, Loss: 0.7829\n",
            "Epoch 7, Batch 2000, Loss: 0.3805\n",
            "Epoch 7, Batch 2100, Loss: 0.3641\n",
            "Epoch 7, Batch 2200, Loss: 0.9415\n",
            "Epoch 7, Batch 2300, Loss: 0.5684\n",
            "Epoch 7, Batch 2400, Loss: 1.3382\n",
            "Epoch 7, Batch 2500, Loss: 0.5072\n",
            "Epoch 7, Batch 2600, Loss: 0.8732\n",
            "Epoch 7, Batch 2700, Loss: 0.6130\n",
            "Epoch 7, Batch 2800, Loss: 3.0265\n",
            "Epoch 7, Batch 2900, Loss: 0.4958\n",
            "Epoch 7, Batch 3000, Loss: 0.8811\n",
            "Epoch 7, Batch 3100, Loss: 0.6485\n",
            "Epoch 7, Batch 3200, Loss: 0.4405\n",
            "Epoch 7, Batch 3300, Loss: 0.7993\n",
            "Epoch 7, Batch 3400, Loss: 0.4414\n",
            "Epoch 7, Batch 3500, Loss: 0.5858\n",
            "Epoch 7, Batch 3600, Loss: 0.8218\n",
            "Epoch 7, Batch 3700, Loss: 0.4532\n",
            "Epoch 7, Batch 3800, Loss: 0.7082\n",
            "Epoch 7, Batch 3900, Loss: 0.6066\n",
            "Epoch 7, Batch 4000, Loss: 0.9272\n",
            "Epoch 7, Batch 4100, Loss: 0.8220\n",
            "Epoch 7, Batch 4200, Loss: 0.5585\n",
            "Epoch 7, Batch 4300, Loss: 1.0980\n",
            "Epoch 7, Batch 4400, Loss: 0.5950\n",
            "Epoch 7, Batch 4500, Loss: 0.7632\n",
            "Epoch 7, Batch 4600, Loss: 0.8786\n",
            "Epoch 7, Batch 4700, Loss: 0.4897\n",
            "Epoch 7, Batch 4800, Loss: 0.7614\n",
            "Epoch 7, Batch 4900, Loss: 0.4754\n",
            "Epoch 7, Batch 5000, Loss: 0.5229\n",
            "Epoch 7, Batch 5100, Loss: 0.6679\n",
            "Epoch 7, Batch 5200, Loss: 0.6884\n",
            "Epoch 7, Batch 5300, Loss: 0.7039\n",
            "Epoch 7, Batch 5400, Loss: 0.3876\n",
            "Epoch 7, Batch 5500, Loss: 0.5249\n",
            "Epoch 7, Batch 5600, Loss: 0.7932\n",
            "Epoch 7, Batch 5700, Loss: 0.9780\n",
            "Epoch 7, Batch 5800, Loss: 0.4086\n",
            "Epoch 7, Batch 5900, Loss: 0.8982\n",
            "Epoch 7, Batch 6000, Loss: 1.1539\n",
            "Epoch 7, Batch 6100, Loss: 0.6641\n",
            "Epoch 7, Batch 6200, Loss: 0.6869\n",
            "Epoch 7, Batch 6300, Loss: 1.5547\n",
            "Epoch 7, Batch 6400, Loss: 0.3373\n",
            "Epoch 7, Batch 6500, Loss: 0.4520\n",
            "Epoch 7, Batch 6600, Loss: 0.3824\n",
            "Epoch 7, Batch 6700, Loss: 0.4523\n",
            "Epoch 7, Batch 6800, Loss: 0.5368\n",
            "Epoch 7, Batch 6900, Loss: 0.5539\n",
            "Epoch 7, Batch 7000, Loss: 0.2528\n",
            "Epoch 7, Batch 7100, Loss: 1.1507\n",
            "Epoch 7, Batch 7200, Loss: 0.4250\n",
            "Epoch 7, Batch 7300, Loss: 0.7463\n",
            "Epoch 7, Batch 7400, Loss: 0.3131\n",
            "Epoch 7, Batch 7500, Loss: 1.8076\n",
            "Epoch 7, Batch 7600, Loss: 0.3750\n",
            "Epoch 7, Batch 7700, Loss: 0.5136\n",
            "Epoch 7, Batch 7800, Loss: 0.9823\n",
            "Epoch 7, Batch 7900, Loss: 2.6451\n",
            "Epoch 7, Batch 8000, Loss: 0.6099\n",
            "Epoch 7, Batch 8100, Loss: 0.8005\n",
            "Epoch 7, Batch 8200, Loss: 0.8799\n",
            "Epoch 7, Batch 8300, Loss: 0.5208\n",
            "Epoch 7, Batch 8400, Loss: 0.6976\n",
            "Epoch 7, Batch 8500, Loss: 0.6399\n",
            "Epoch 7, Batch 8600, Loss: 0.6128\n",
            "Epoch 7, Batch 8700, Loss: 0.5370\n",
            "Epoch 7, Batch 8800, Loss: 0.4608\n",
            "Epoch 7, Batch 8900, Loss: 0.5327\n",
            "Epoch 7, Batch 9000, Loss: 0.5737\n",
            "Epoch 7, Batch 9100, Loss: 1.3597\n",
            "Epoch 7, Batch 9200, Loss: 0.6850\n",
            "Epoch 7, Batch 9300, Loss: 0.8544\n",
            "Epoch 7, Batch 9400, Loss: 0.6215\n",
            "Epoch 7, Batch 9500, Loss: 0.5630\n",
            "Epoch 7, Batch 9600, Loss: 0.5698\n",
            "Epoch 7, Batch 9700, Loss: 0.5778\n",
            "Epoch 7, Batch 9800, Loss: 0.7241\n",
            "Epoch 7, Batch 9900, Loss: 0.3733\n",
            "Epoch 7, Batch 10000, Loss: 0.3994\n",
            "Epoch 7, Batch 10100, Loss: 0.5395\n",
            "Epoch 7, Batch 10200, Loss: 1.0672\n",
            "Epoch 7, Batch 10300, Loss: 0.5252\n",
            "Epoch 7, Batch 10400, Loss: 0.3554\n",
            "Epoch 7/10, Avg Loss: 0.7159\n",
            "Epoch 8, Batch 0, Loss: 0.4715\n",
            "Epoch 8, Batch 100, Loss: 0.6202\n",
            "Epoch 8, Batch 200, Loss: 1.3963\n",
            "Epoch 8, Batch 300, Loss: 0.5282\n",
            "Epoch 8, Batch 400, Loss: 0.7596\n",
            "Epoch 8, Batch 500, Loss: 0.5358\n",
            "Epoch 8, Batch 600, Loss: 0.5219\n",
            "Epoch 8, Batch 700, Loss: 0.5590\n",
            "Epoch 8, Batch 800, Loss: 0.7121\n",
            "Epoch 8, Batch 900, Loss: 0.3735\n",
            "Epoch 8, Batch 1000, Loss: 0.9496\n",
            "Epoch 8, Batch 1100, Loss: 0.7301\n",
            "Epoch 8, Batch 1200, Loss: 0.6243\n",
            "Epoch 8, Batch 1300, Loss: 0.7426\n",
            "Epoch 8, Batch 1400, Loss: 0.5613\n",
            "Epoch 8, Batch 1500, Loss: 0.7115\n",
            "Epoch 8, Batch 1600, Loss: 0.6117\n",
            "Epoch 8, Batch 1700, Loss: 0.6164\n",
            "Epoch 8, Batch 1800, Loss: 1.9365\n",
            "Epoch 8, Batch 1900, Loss: 0.4041\n",
            "Epoch 8, Batch 2000, Loss: 0.6656\n",
            "Epoch 8, Batch 2100, Loss: 0.6549\n",
            "Epoch 8, Batch 2200, Loss: 0.4251\n",
            "Epoch 8, Batch 2300, Loss: 1.0933\n",
            "Epoch 8, Batch 2400, Loss: 0.3904\n",
            "Epoch 8, Batch 2500, Loss: 0.4822\n",
            "Epoch 8, Batch 2600, Loss: 0.7464\n",
            "Epoch 8, Batch 2700, Loss: 0.3714\n",
            "Epoch 8, Batch 2800, Loss: 0.3722\n",
            "Epoch 8, Batch 2900, Loss: 0.2975\n",
            "Epoch 8, Batch 3000, Loss: 0.8941\n",
            "Epoch 8, Batch 3100, Loss: 0.4305\n",
            "Epoch 8, Batch 3200, Loss: 0.6595\n",
            "Epoch 8, Batch 3300, Loss: 1.4012\n",
            "Epoch 8, Batch 3400, Loss: 0.3112\n",
            "Epoch 8, Batch 3500, Loss: 0.5289\n",
            "Epoch 8, Batch 3600, Loss: 0.6946\n",
            "Epoch 8, Batch 3700, Loss: 0.7911\n",
            "Epoch 8, Batch 3800, Loss: 1.2008\n",
            "Epoch 8, Batch 3900, Loss: 0.5041\n",
            "Epoch 8, Batch 4000, Loss: 0.4402\n",
            "Epoch 8, Batch 4100, Loss: 0.7801\n",
            "Epoch 8, Batch 4200, Loss: 0.6624\n",
            "Epoch 8, Batch 4300, Loss: 0.5406\n",
            "Epoch 8, Batch 4400, Loss: 0.6071\n",
            "Epoch 8, Batch 4500, Loss: 0.3857\n",
            "Epoch 8, Batch 4600, Loss: 0.3221\n",
            "Epoch 8, Batch 4700, Loss: 0.6776\n",
            "Epoch 8, Batch 4800, Loss: 0.4862\n",
            "Epoch 8, Batch 4900, Loss: 0.4079\n",
            "Epoch 8, Batch 5000, Loss: 0.4403\n",
            "Epoch 8, Batch 5100, Loss: 1.0989\n",
            "Epoch 8, Batch 5200, Loss: 0.3586\n",
            "Epoch 8, Batch 5300, Loss: 0.4410\n",
            "Epoch 8, Batch 5400, Loss: 0.4147\n",
            "Epoch 8, Batch 5500, Loss: 0.8009\n",
            "Epoch 8, Batch 5600, Loss: 0.3916\n",
            "Epoch 8, Batch 5700, Loss: 0.3690\n",
            "Epoch 8, Batch 5800, Loss: 0.5321\n",
            "Epoch 8, Batch 5900, Loss: 0.1788\n",
            "Epoch 8, Batch 6000, Loss: 0.5691\n",
            "Epoch 8, Batch 6100, Loss: 1.4411\n",
            "Epoch 8, Batch 6200, Loss: 0.2786\n",
            "Epoch 8, Batch 6300, Loss: 0.6099\n",
            "Epoch 8, Batch 6400, Loss: 0.3924\n",
            "Epoch 8, Batch 6500, Loss: 0.6753\n",
            "Epoch 8, Batch 6600, Loss: 0.7177\n",
            "Epoch 8, Batch 6700, Loss: 1.2813\n",
            "Epoch 8, Batch 6800, Loss: 0.3661\n",
            "Epoch 8, Batch 6900, Loss: 0.3338\n",
            "Epoch 8, Batch 7000, Loss: 0.6822\n",
            "Epoch 8, Batch 7100, Loss: 0.5245\n",
            "Epoch 8, Batch 7200, Loss: 0.4560\n",
            "Epoch 8, Batch 7300, Loss: 0.8697\n",
            "Epoch 8, Batch 7400, Loss: 0.8418\n",
            "Epoch 8, Batch 7500, Loss: 0.8180\n",
            "Epoch 8, Batch 7600, Loss: 0.6479\n",
            "Epoch 8, Batch 7700, Loss: 0.6525\n",
            "Epoch 8, Batch 7800, Loss: 0.3869\n",
            "Epoch 8, Batch 7900, Loss: 0.4904\n",
            "Epoch 8, Batch 8000, Loss: 0.4091\n",
            "Epoch 8, Batch 8100, Loss: 0.6483\n",
            "Epoch 8, Batch 8200, Loss: 0.6817\n",
            "Epoch 8, Batch 8300, Loss: 0.8009\n",
            "Epoch 8, Batch 8400, Loss: 0.4060\n",
            "Epoch 8, Batch 8500, Loss: 0.5283\n",
            "Epoch 8, Batch 8600, Loss: 0.9690\n",
            "Epoch 8, Batch 8700, Loss: 1.1860\n",
            "Epoch 8, Batch 8800, Loss: 0.3555\n",
            "Epoch 8, Batch 8900, Loss: 0.6334\n",
            "Epoch 8, Batch 9000, Loss: 0.8663\n",
            "Epoch 8, Batch 9100, Loss: 0.8531\n",
            "Epoch 8, Batch 9200, Loss: 1.6488\n",
            "Epoch 8, Batch 9300, Loss: 0.6056\n",
            "Epoch 8, Batch 9400, Loss: 0.5092\n",
            "Epoch 8, Batch 9500, Loss: 0.7738\n",
            "Epoch 8, Batch 9600, Loss: 0.7982\n",
            "Epoch 8, Batch 9700, Loss: 0.3721\n",
            "Epoch 8, Batch 9800, Loss: 0.8706\n",
            "Epoch 8, Batch 9900, Loss: 1.0807\n",
            "Epoch 8, Batch 10000, Loss: 0.4966\n",
            "Epoch 8, Batch 10100, Loss: 1.0495\n",
            "Epoch 8, Batch 10200, Loss: 0.5229\n",
            "Epoch 8, Batch 10300, Loss: 0.4644\n",
            "Epoch 8, Batch 10400, Loss: 0.6982\n",
            "Epoch 8/10, Avg Loss: 0.6726\n",
            "Epoch 9, Batch 0, Loss: 0.4284\n",
            "Epoch 9, Batch 100, Loss: 0.4955\n",
            "Epoch 9, Batch 200, Loss: 0.5086\n",
            "Epoch 9, Batch 300, Loss: 0.6295\n",
            "Epoch 9, Batch 400, Loss: 0.4961\n",
            "Epoch 9, Batch 500, Loss: 0.2577\n",
            "Epoch 9, Batch 600, Loss: 0.4528\n",
            "Epoch 9, Batch 700, Loss: 0.4298\n",
            "Epoch 9, Batch 800, Loss: 0.6706\n",
            "Epoch 9, Batch 900, Loss: 0.4585\n",
            "Epoch 9, Batch 1000, Loss: 1.2860\n",
            "Epoch 9, Batch 1100, Loss: 0.3884\n",
            "Epoch 9, Batch 1200, Loss: 0.5421\n",
            "Epoch 9, Batch 1300, Loss: 0.3198\n",
            "Epoch 9, Batch 1400, Loss: 1.2400\n",
            "Epoch 9, Batch 1500, Loss: 0.4190\n",
            "Epoch 9, Batch 1600, Loss: 0.7080\n",
            "Epoch 9, Batch 1700, Loss: 0.4025\n",
            "Epoch 9, Batch 1800, Loss: 0.5252\n",
            "Epoch 9, Batch 1900, Loss: 0.5974\n",
            "Epoch 9, Batch 2000, Loss: 0.4335\n",
            "Epoch 9, Batch 2100, Loss: 0.4244\n",
            "Epoch 9, Batch 2200, Loss: 0.5266\n",
            "Epoch 9, Batch 2300, Loss: 0.5910\n",
            "Epoch 9, Batch 2400, Loss: 0.8494\n",
            "Epoch 9, Batch 2500, Loss: 0.7093\n",
            "Epoch 9, Batch 2600, Loss: 0.2513\n",
            "Epoch 9, Batch 2700, Loss: 0.3276\n",
            "Epoch 9, Batch 2800, Loss: 0.9746\n",
            "Epoch 9, Batch 2900, Loss: 0.5846\n",
            "Epoch 9, Batch 3000, Loss: 0.7238\n",
            "Epoch 9, Batch 3100, Loss: 0.2901\n",
            "Epoch 9, Batch 3200, Loss: 0.8096\n",
            "Epoch 9, Batch 3300, Loss: 0.6779\n",
            "Epoch 9, Batch 3400, Loss: 0.6266\n",
            "Epoch 9, Batch 3500, Loss: 0.6798\n",
            "Epoch 9, Batch 3600, Loss: 0.7771\n",
            "Epoch 9, Batch 3700, Loss: 0.4336\n",
            "Epoch 9, Batch 3800, Loss: 0.8296\n",
            "Epoch 9, Batch 3900, Loss: 0.5143\n",
            "Epoch 9, Batch 4000, Loss: 0.5843\n",
            "Epoch 9, Batch 4100, Loss: 0.4339\n",
            "Epoch 9, Batch 4200, Loss: 0.4569\n",
            "Epoch 9, Batch 4300, Loss: 1.2764\n",
            "Epoch 9, Batch 4400, Loss: 0.7026\n",
            "Epoch 9, Batch 4500, Loss: 0.4064\n",
            "Epoch 9, Batch 4600, Loss: 0.8003\n",
            "Epoch 9, Batch 4700, Loss: 1.0089\n",
            "Epoch 9, Batch 4800, Loss: 0.6146\n",
            "Epoch 9, Batch 4900, Loss: 0.9000\n",
            "Epoch 9, Batch 5000, Loss: 1.7641\n",
            "Epoch 9, Batch 5100, Loss: 1.1071\n",
            "Epoch 9, Batch 5200, Loss: 1.3979\n",
            "Epoch 9, Batch 5300, Loss: 0.3719\n",
            "Epoch 9, Batch 5400, Loss: 0.9098\n",
            "Epoch 9, Batch 5500, Loss: 0.2978\n",
            "Epoch 9, Batch 5600, Loss: 0.5753\n",
            "Epoch 9, Batch 5700, Loss: 1.4682\n",
            "Epoch 9, Batch 5800, Loss: 0.3892\n",
            "Epoch 9, Batch 5900, Loss: 0.3413\n",
            "Epoch 9, Batch 6000, Loss: 0.4459\n",
            "Epoch 9, Batch 6100, Loss: 0.8396\n",
            "Epoch 9, Batch 6200, Loss: 0.6470\n",
            "Epoch 9, Batch 6300, Loss: 0.5238\n",
            "Epoch 9, Batch 6400, Loss: 0.6522\n",
            "Epoch 9, Batch 6500, Loss: 0.6833\n",
            "Epoch 9, Batch 6600, Loss: 0.3304\n",
            "Epoch 9, Batch 6700, Loss: 0.4565\n",
            "Epoch 9, Batch 6800, Loss: 0.7227\n",
            "Epoch 9, Batch 6900, Loss: 0.3766\n",
            "Epoch 9, Batch 7000, Loss: 0.3727\n",
            "Epoch 9, Batch 7100, Loss: 0.3342\n",
            "Epoch 9, Batch 7200, Loss: 0.4149\n",
            "Epoch 9, Batch 7300, Loss: 0.7986\n",
            "Epoch 9, Batch 7400, Loss: 0.9098\n",
            "Epoch 9, Batch 7500, Loss: 0.5878\n",
            "Epoch 9, Batch 7600, Loss: 0.5483\n",
            "Epoch 9, Batch 7700, Loss: 0.3841\n",
            "Epoch 9, Batch 7800, Loss: 0.5426\n",
            "Epoch 9, Batch 7900, Loss: 0.4051\n",
            "Epoch 9, Batch 8000, Loss: 0.3352\n",
            "Epoch 9, Batch 8100, Loss: 0.3295\n",
            "Epoch 9, Batch 8200, Loss: 0.4634\n",
            "Epoch 9, Batch 8300, Loss: 0.5287\n",
            "Epoch 9, Batch 8400, Loss: 0.6731\n",
            "Epoch 9, Batch 8500, Loss: 0.3603\n",
            "Epoch 9, Batch 8600, Loss: 1.1579\n",
            "Epoch 9, Batch 8700, Loss: 0.4575\n",
            "Epoch 9, Batch 8800, Loss: 0.3552\n",
            "Epoch 9, Batch 8900, Loss: 0.4552\n",
            "Epoch 9, Batch 9000, Loss: 0.6206\n",
            "Epoch 9, Batch 9100, Loss: 0.5416\n",
            "Epoch 9, Batch 9200, Loss: 0.5251\n",
            "Epoch 9, Batch 9300, Loss: 0.4056\n",
            "Epoch 9, Batch 9400, Loss: 0.8830\n",
            "Epoch 9, Batch 9500, Loss: 0.6728\n",
            "Epoch 9, Batch 9600, Loss: 0.5623\n",
            "Epoch 9, Batch 9700, Loss: 0.1783\n",
            "Epoch 9, Batch 9800, Loss: 1.7853\n",
            "Epoch 9, Batch 9900, Loss: 0.4304\n",
            "Epoch 9, Batch 10000, Loss: 0.9733\n",
            "Epoch 9, Batch 10100, Loss: 1.4842\n",
            "Epoch 9, Batch 10200, Loss: 0.9179\n",
            "Epoch 9, Batch 10300, Loss: 0.5683\n",
            "Epoch 9, Batch 10400, Loss: 1.1069\n",
            "Epoch 9/10, Avg Loss: 0.6360\n",
            "Epoch 10, Batch 0, Loss: 0.4149\n",
            "Epoch 10, Batch 100, Loss: 0.3989\n",
            "Epoch 10, Batch 200, Loss: 0.1854\n",
            "Epoch 10, Batch 300, Loss: 1.0928\n",
            "Epoch 10, Batch 400, Loss: 1.5794\n",
            "Epoch 10, Batch 500, Loss: 0.3558\n",
            "Epoch 10, Batch 600, Loss: 0.4165\n",
            "Epoch 10, Batch 700, Loss: 2.5403\n",
            "Epoch 10, Batch 800, Loss: 0.6934\n",
            "Epoch 10, Batch 900, Loss: 0.3639\n",
            "Epoch 10, Batch 1000, Loss: 0.4920\n",
            "Epoch 10, Batch 1100, Loss: 0.2661\n",
            "Epoch 10, Batch 1200, Loss: 0.6500\n",
            "Epoch 10, Batch 1300, Loss: 0.4799\n",
            "Epoch 10, Batch 1400, Loss: 0.3088\n",
            "Epoch 10, Batch 1500, Loss: 0.2279\n",
            "Epoch 10, Batch 1600, Loss: 0.2293\n",
            "Epoch 10, Batch 1700, Loss: 0.2336\n",
            "Epoch 10, Batch 1800, Loss: 0.5389\n",
            "Epoch 10, Batch 1900, Loss: 0.3790\n",
            "Epoch 10, Batch 2000, Loss: 0.4430\n",
            "Epoch 10, Batch 2100, Loss: 0.1580\n",
            "Epoch 10, Batch 2200, Loss: 0.4591\n",
            "Epoch 10, Batch 2300, Loss: 0.7035\n",
            "Epoch 10, Batch 2400, Loss: 0.2770\n",
            "Epoch 10, Batch 2500, Loss: 0.5326\n",
            "Epoch 10, Batch 2600, Loss: 0.3263\n",
            "Epoch 10, Batch 2700, Loss: 0.7550\n",
            "Epoch 10, Batch 2800, Loss: 0.3902\n",
            "Epoch 10, Batch 2900, Loss: 0.6629\n",
            "Epoch 10, Batch 3000, Loss: 0.1149\n",
            "Epoch 10, Batch 3100, Loss: 0.6792\n",
            "Epoch 10, Batch 3200, Loss: 0.1859\n",
            "Epoch 10, Batch 3300, Loss: 0.3711\n",
            "Epoch 10, Batch 3400, Loss: 0.4370\n",
            "Epoch 10, Batch 3500, Loss: 0.4185\n",
            "Epoch 10, Batch 3600, Loss: 0.2983\n",
            "Epoch 10, Batch 3700, Loss: 0.4429\n",
            "Epoch 10, Batch 3800, Loss: 0.0929\n",
            "Epoch 10, Batch 3900, Loss: 0.3225\n",
            "Epoch 10, Batch 4000, Loss: 0.5948\n",
            "Epoch 10, Batch 4100, Loss: 0.3324\n",
            "Epoch 10, Batch 4200, Loss: 0.6607\n",
            "Epoch 10, Batch 4300, Loss: 1.3235\n",
            "Epoch 10, Batch 4400, Loss: 0.7229\n",
            "Epoch 10, Batch 4500, Loss: 0.3289\n",
            "Epoch 10, Batch 4600, Loss: 0.9154\n",
            "Epoch 10, Batch 4700, Loss: 0.9327\n",
            "Epoch 10, Batch 4800, Loss: 0.3969\n",
            "Epoch 10, Batch 4900, Loss: 0.8198\n",
            "Epoch 10, Batch 5000, Loss: 0.5304\n",
            "Epoch 10, Batch 5100, Loss: 0.2695\n",
            "Epoch 10, Batch 5200, Loss: 0.5006\n",
            "Epoch 10, Batch 5300, Loss: 0.5617\n",
            "Epoch 10, Batch 5400, Loss: 0.5098\n",
            "Epoch 10, Batch 5500, Loss: 0.4563\n",
            "Epoch 10, Batch 5600, Loss: 0.5497\n",
            "Epoch 10, Batch 5700, Loss: 0.7186\n",
            "Epoch 10, Batch 5800, Loss: 0.7164\n",
            "Epoch 10, Batch 5900, Loss: 0.3289\n",
            "Epoch 10, Batch 6000, Loss: 0.7854\n",
            "Epoch 10, Batch 6100, Loss: 1.9146\n",
            "Epoch 10, Batch 6200, Loss: 0.5306\n",
            "Epoch 10, Batch 6300, Loss: 0.8931\n",
            "Epoch 10, Batch 6400, Loss: 0.7746\n",
            "Epoch 10, Batch 6500, Loss: 0.2895\n",
            "Epoch 10, Batch 6600, Loss: 1.1487\n",
            "Epoch 10, Batch 6700, Loss: 0.4883\n",
            "Epoch 10, Batch 6800, Loss: 0.7042\n",
            "Epoch 10, Batch 6900, Loss: 0.2588\n",
            "Epoch 10, Batch 7000, Loss: 1.6053\n",
            "Epoch 10, Batch 7100, Loss: 0.4941\n",
            "Epoch 10, Batch 7200, Loss: 0.4517\n",
            "Epoch 10, Batch 7300, Loss: 0.5681\n",
            "Epoch 10, Batch 7400, Loss: 0.3686\n",
            "Epoch 10, Batch 7500, Loss: 0.5750\n",
            "Epoch 10, Batch 7600, Loss: 0.6742\n",
            "Epoch 10, Batch 7700, Loss: 0.3387\n",
            "Epoch 10, Batch 7800, Loss: 0.3592\n",
            "Epoch 10, Batch 7900, Loss: 0.2774\n",
            "Epoch 10, Batch 8000, Loss: 0.3780\n",
            "Epoch 10, Batch 8100, Loss: 0.7327\n",
            "Epoch 10, Batch 8200, Loss: 1.6567\n",
            "Epoch 10, Batch 8300, Loss: 0.2288\n",
            "Epoch 10, Batch 8400, Loss: 0.2651\n",
            "Epoch 10, Batch 8500, Loss: 1.3575\n",
            "Epoch 10, Batch 8600, Loss: 0.4166\n",
            "Epoch 10, Batch 8700, Loss: 0.5023\n",
            "Epoch 10, Batch 8800, Loss: 0.1708\n",
            "Epoch 10, Batch 8900, Loss: 0.9732\n",
            "Epoch 10, Batch 9000, Loss: 0.4276\n",
            "Epoch 10, Batch 9100, Loss: 0.7025\n",
            "Epoch 10, Batch 9200, Loss: 0.1799\n",
            "Epoch 10, Batch 9300, Loss: 0.3568\n",
            "Epoch 10, Batch 9400, Loss: 2.0004\n",
            "Epoch 10, Batch 9500, Loss: 1.0331\n",
            "Epoch 10, Batch 9600, Loss: 0.5162\n",
            "Epoch 10, Batch 9700, Loss: 0.5933\n",
            "Epoch 10, Batch 9800, Loss: 0.4010\n",
            "Epoch 10, Batch 9900, Loss: 0.3683\n",
            "Epoch 10, Batch 10000, Loss: 0.5945\n",
            "Epoch 10, Batch 10100, Loss: 0.4514\n",
            "Epoch 10, Batch 10200, Loss: 0.8604\n",
            "Epoch 10, Batch 10300, Loss: 0.3981\n",
            "Epoch 10, Batch 10400, Loss: 0.3957\n",
            "Epoch 10/10, Avg Loss: 0.5964\n",
            "Pretraining Complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from NNModel import ECGClassifier  # Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Ï„Î·Ï‚ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…\n",
        "import pickle\n",
        "import gzip\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· import Ï€Î¿Ï… Î­Î»ÎµÎ¹Ï€Îµ Î³Î¹Î± Ï„Î¿ np.unique\n",
        "\n",
        "# 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½\n",
        "with gzip.open(\"pretraining_data.pkl.gz\", \"rb\") as f:\n",
        "    X_train, y_train = pickle.load(f)\n",
        "\n",
        "print(f\"Î”ÎµÎ´Î¿Î¼Î­Î½Î± Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚: {X_train.shape}, Î•Ï„Î¹ÎºÎ­Ï„ÎµÏ‚: {len(y_train)}\")\n",
        "print(f\"ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½: {torch.bincount(y_train)}\")\n",
        "\n",
        "# 2. ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ custom Dataset class Î³Î¹Î± Ï„Î¿ PyTorch\n",
        "class ECGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        # Î”Î¹Î±ÏƒÏ†Î¬Î»Î¹ÏƒÎ· ÏŒÏ„Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î­Ï‡Î¿Ï…Î½ Î´Î¹Î¬ÏƒÏ„Î±ÏƒÎ· ÎºÎ±Î½Î±Î»Î¹Î¿Ï (B, C, L)\n",
        "        self.X = X.unsqueeze(1) if X.dim() == 2 else X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# 3. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataLoader\n",
        "batch_size = 32  # ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Ï€Î±ÏÏ„Î¯Î´Î±Ï‚\n",
        "train_dataset = ECGDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "\n",
        "# 4. ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… Î³Î¹Î± Pretraining\n",
        "# (ÎšÎ»Î·ÏÎ¿Î½Î¿Î¼ÎµÎ¯ Î±Ï€ÏŒ Ï„Î¿ ECGClassifier Î±Î»Î»Î¬ Î¿ÏÎ¯Î¶ÎµÎ¹ num_classes=4)\n",
        "class PretrainECGClassifier(ECGClassifier):\n",
        "    def __init__(self):\n",
        "        super(PretrainECGClassifier, self).__init__(num_classes=4)\n",
        "\n",
        "model = PretrainECGClassifier()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 5. Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Loss, Optimizer)\n",
        "\n",
        "# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î²Î±ÏÏÎ½ (weights) Î³Î¹Î± Î±Î½Ï„Î¹Î¼ÎµÏ„ÏÏ€Î¹ÏƒÎ· Î±Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±Ï‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                   classes=np.unique(y_train.numpy()),\n",
        "                                   y=y_train.numpy())\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "# Î§ÏÎ®ÏƒÎ· CrossEntropyLoss Î¼Îµ Ï„Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î­Î½Î± Î²Î¬ÏÎ·\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "# Scheduler Î³Î¹Î± Î´Ï…Î½Î±Î¼Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® Ï„Î¿Ï… learning rate\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "\n",
        "# 6. ÎšÏÏÎ¹Î¿Ï‚ Î’ÏÏŒÏ‡Î¿Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Pretraining Loop)\n",
        "num_epochs = 10\n",
        "best_loss = float('inf')\n",
        "\n",
        "print(\"--- ÎˆÎ½Î±ÏÎ¾Î· Î ÏÎ¿-ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ ---\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Î˜Î­Ï„Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÏƒÎµ ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # ÎœÎ·Î´ÎµÎ½Î¹ÏƒÎ¼ÏŒÏ‚ Ï„Ï‰Î½ gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping (Î±Ï€Î¿Ï†Ï…Î³Î® ÎµÎºÏÎ·Î³Î½Ï…ÏŒÎ¼ÎµÎ½Ï‰Î½ ÎºÎ»Î¯ÏƒÎµÏ‰Î½)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Î²Î±ÏÏÎ½\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Î•Ï€Î¿Ï‡Î® {epoch+1}, Î Î±ÏÏ„Î¯Î´Î± {batch_idx}, Î‘Ï€ÏÎ»ÎµÎ¹Î±: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    scheduler.step(avg_loss)  # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï„Î¿Ï… scheduler\n",
        "\n",
        "    print(f\"Î•Ï€Î¿Ï‡Î® {epoch+1}/{num_epochs}, ÎœÎ­ÏƒÎ· Î‘Ï€ÏÎ»ÎµÎ¹Î±: {avg_loss:.4f}\")\n",
        "\n",
        "    # 7. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        print(f\"ÎÎ­Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏÎ»ÎµÎ¹Î±. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…...\")\n",
        "        with gzip.open(\"pretrained_model_best.pth.gz\", \"wb\") as f:\n",
        "            pickle.dump(model.state_dict(), f)\n",
        "\n",
        "print(\"--- ÎŸÎ»Î¿ÎºÎ»Î®ÏÏ‰ÏƒÎ· Î ÏÎ¿-ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvv_IKAAwII_",
        "outputId": "859508e7-eb52-4a77-d9db-4eb134cb85d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 48 MIT-BIH files...\n",
            "Processing 100 (1/48)\n",
            "  Extracted 2270 valid episodes from 100\n",
            "Processing 101 (2/48)\n",
            "  Extracted 1868 valid episodes from 101\n",
            "Processing 102 (3/48)\n",
            "  Extracted 2187 valid episodes from 102\n",
            "Processing 103 (4/48)\n",
            "  Extracted 2084 valid episodes from 103\n",
            "Processing 104 (5/48)\n",
            "  Extracted 2203 valid episodes from 104\n",
            "Processing 105 (6/48)\n",
            "  Extracted 2570 valid episodes from 105\n",
            "Processing 106 (7/48)\n",
            "  Extracted 2032 valid episodes from 106\n",
            "Processing 107 (8/48)\n",
            "  Extracted 2136 valid episodes from 107\n",
            "Processing 108 (9/48)\n",
            "  Extracted 1770 valid episodes from 108\n",
            "Processing 109 (10/48)\n",
            "  Extracted 2531 valid episodes from 109\n",
            "Processing 111 (11/48)\n",
            "  Extracted 2124 valid episodes from 111\n",
            "Processing 112 (12/48)\n",
            "  Extracted 2539 valid episodes from 112\n",
            "Processing 113 (13/48)\n",
            "  Extracted 1826 valid episodes from 113\n",
            "Processing 114 (14/48)\n",
            "  Extracted 1882 valid episodes from 114\n",
            "Processing 115 (15/48)\n",
            "  Extracted 1953 valid episodes from 115\n",
            "Processing 116 (16/48)\n",
            "  Extracted 2399 valid episodes from 116\n",
            "Processing 117 (17/48)\n",
            "  Extracted 1535 valid episodes from 117\n",
            "Processing 118 (18/48)\n",
            "  Extracted 2278 valid episodes from 118\n",
            "Processing 119 (19/48)\n",
            "  Extracted 1988 valid episodes from 119\n",
            "Processing 121 (20/48)\n",
            "  Extracted 1863 valid episodes from 121\n",
            "Processing 122 (21/48)\n",
            "  Extracted 2475 valid episodes from 122\n",
            "Processing 123 (22/48)\n",
            "  Extracted 1518 valid episodes from 123\n",
            "Processing 124 (23/48)\n",
            "  Extracted 1623 valid episodes from 124\n",
            "Processing 200 (24/48)\n",
            "  Extracted 2608 valid episodes from 200\n",
            "Processing 201 (25/48)\n",
            "  Extracted 1980 valid episodes from 201\n",
            "Processing 202 (26/48)\n",
            "  Extracted 2136 valid episodes from 202\n",
            "Processing 203 (27/48)\n",
            "  Extracted 2821 valid episodes from 203\n",
            "Processing 205 (28/48)\n",
            "  Extracted 2629 valid episodes from 205\n",
            "Processing 207 (29/48)\n",
            "  Extracted 1236 valid episodes from 207\n",
            "Processing 208 (30/48)\n",
            "  Extracted 2948 valid episodes from 208\n",
            "Processing 209 (31/48)\n",
            "  Extracted 3005 valid episodes from 209\n",
            "Processing 210 (32/48)\n",
            "  Extracted 2605 valid episodes from 210\n",
            "Processing 212 (33/48)\n",
            "  Extracted 2748 valid episodes from 212\n",
            "Processing 213 (34/48)\n",
            "  Extracted 3246 valid episodes from 213\n",
            "Processing 214 (35/48)\n",
            "  Extracted 2260 valid episodes from 214\n",
            "Processing 215 (36/48)\n",
            "  Extracted 3357 valid episodes from 215\n",
            "Processing 217 (37/48)\n",
            "  Extracted 2207 valid episodes from 217\n",
            "Processing 219 (38/48)\n",
            "  Extracted 2154 valid episodes from 219\n",
            "Processing 220 (39/48)\n",
            "  Extracted 2047 valid episodes from 220\n",
            "Processing 221 (40/48)\n",
            "  Extracted 2428 valid episodes from 221\n",
            "Processing 222 (41/48)\n",
            "  Extracted 2491 valid episodes from 222\n",
            "Processing 223 (42/48)\n",
            "  Extracted 2605 valid episodes from 223\n",
            "Processing 228 (43/48)\n",
            "  Extracted 2063 valid episodes from 228\n",
            "Processing 230 (44/48)\n",
            "  Extracted 2255 valid episodes from 230\n",
            "Processing 231 (45/48)\n",
            "  Extracted 1917 valid episodes from 231\n",
            "Processing 232 (46/48)\n",
            "  Extracted 1842 valid episodes from 232\n",
            "Processing 233 (47/48)\n",
            "  Extracted 3072 valid episodes from 233\n",
            "Processing 234 (48/48)\n",
            "  Extracted 2753 valid episodes from 234\n",
            "\n",
            "Completed processing 48/48 files\n",
            "Total beats extracted: 109067\n",
            "\n",
            "MIT-BIH Beats Shape: torch.Size([109067, 3750])\n",
            "Unique Labels and Counts: (array([0, 1, 2, 3, 4]), array([89860,  2952,  7003,   799,  8453]))\n",
            "  Normal: 89860 beats (82.4%)\n",
            "  Supraventricular: 2952 beats (2.7%)\n",
            "  Ventricular: 7003 beats (6.4%)\n",
            "  Fusion: 799 beats (0.7%)\n",
            "  Unknown: 8453 beats (7.8%)\n"
          ]
        }
      ],
      "source": [
        "# Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î³Î¹Î± Ï„Î¿ MIT-BIH Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import wfdb\n",
        "import gzip\n",
        "import pickle\n",
        "import neurokit2 as nk\n",
        "from scipy.signal import resample\n",
        "\n",
        "# --- ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Î¸ÎµÏÏÎ½ ---\n",
        "TARGET_SAMPLING_RATE = 125  # Hz\n",
        "MAX_LEN_MITBIH = 30 * TARGET_SAMPLING_RATE  # 30 Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î± (Î¼Î­Î³Î¹ÏƒÏ„Î¿ Î¼Î®ÎºÎ¿Ï‚ Ï‡Ï„ÏÏ€Î¿Ï…)\n",
        "\n",
        "# Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ AAMI ÏƒÎµ 5 ÎºÏÏÎ¹ÎµÏ‚ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚\n",
        "label_mapping = {\n",
        "    # Normal beats (ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Î¯)\n",
        "    'N': 0, 'L': 0, 'R': 0, 'B': 0, '.': 0,\n",
        "    # Supraventricular ectopic beats (Î¥Ï€ÎµÏÎºÎ¿Î¹Î»Î¹Î±ÎºÎ¿Î¯)\n",
        "    'A': 1, 'a': 1, 'J': 1, 'S': 1, 'e': 1, 'j': 1, 'n': 1,\n",
        "    # Ventricular ectopic beats (ÎšÎ¿Î¹Î»Î¹Î±ÎºÎ¿Î¯)\n",
        "    'V': 2, 'r': 2, 'E': 2,\n",
        "    # Fusion beats (Î£ÏÏ„Î·Î¾Î·Ï‚)\n",
        "    'F': 3,\n",
        "    # Unknown/Unclassifiable beats (Î†Î³Î½Ï‰ÏƒÏ„Î¿Î¹/Î‘Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·Ï„Î¿Î¹)\n",
        "    '/': 4, 'Q': 4, 'f': 4, '?': 4\n",
        "}\n",
        "\n",
        "def load_mitbih_record(record_path):\n",
        "    \"\"\"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ ÎºÎ±Î¹ annotations Î±Ï€ÏŒ Î±ÏÏ‡ÎµÎ¯Î± MIT-BIH (WFDB).\"\"\"\n",
        "    try:\n",
        "        record = wfdb.rdrecord(record_path)\n",
        "        annotation = wfdb.rdann(record_path, 'atr')\n",
        "        signal = record.p_signal[:, 0]  # Î§ÏÎ®ÏƒÎ· Î¼ÏŒÎ½Î¿ Ï„Î¿Ï… Ï€ÏÏÏ„Î¿Ï… ÎºÎ±Î½Î±Î»Î¹Î¿Ï (ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ MLII)\n",
        "        return signal, annotation.sample, annotation.symbol\n",
        "    except Exception as e:\n",
        "        print(f\"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ {record_path}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "def downsample_signal(signal, original_fs=360, target_fs=125):\n",
        "    \"\"\"Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ (Î±Ï€ÏŒ 360Hz ÏƒÎµ 125Hz).\"\"\"\n",
        "    if original_fs == target_fs:\n",
        "        return signal\n",
        "    num_samples = int(len(signal) * target_fs / original_fs)\n",
        "    return resample(signal, num_samples)\n",
        "\n",
        "def normalize_signal(signal):\n",
        "    \"\"\"ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Min-Max Ï„Î¿Ï… ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ (ÎºÎ»Î¯Î¼Î±ÎºÎ± [0, 1]).\"\"\"\n",
        "    signal = np.array(signal, dtype=np.float32)\n",
        "    signal_min, signal_max = np.min(signal), np.max(signal)\n",
        "    signal_range = signal_max - signal_min\n",
        "\n",
        "    if signal_range < 1e-8:  # Î‘Ï€Î¿Ï†Ï…Î³Î® Î´Î¹Î±Î¯ÏÎµÏƒÎ·Ï‚ Î¼Îµ Ï„Î¿ Î¼Î·Î´Î­Î½\n",
        "        return np.zeros_like(signal)\n",
        "\n",
        "    return (signal - signal_min) / signal_range\n",
        "\n",
        "def detect_r_peaks(signal, fs=125):\n",
        "    \"\"\"Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· R-peaks Î¼Îµ Ï‡ÏÎ®ÏƒÎ· NeuroKit2.\"\"\"\n",
        "    try:\n",
        "        _, rpeaks = nk.ecg_peaks(signal, sampling_rate=fs)\n",
        "        return rpeaks[\"ECG_R_Peaks\"]\n",
        "    except:\n",
        "        return np.array([])\n",
        "\n",
        "def extract_t_episodes(signal, r_peaks):\n",
        "    \"\"\"Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ ÏƒÎ®Î¼Î±Ï„Î¿Ï‚ (Ï‡Ï„ÏÏ€Ï‰Î½) Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î± R-peaks.\"\"\"\n",
        "    if len(r_peaks) < 2:\n",
        "        return []\n",
        "\n",
        "    rr_intervals = np.diff(r_peaks)\n",
        "    median_rr = int(np.median(rr_intervals))\n",
        "\n",
        "    # ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¿ÏÎ¯Ï‰Î½ Î³Î¹Î± Ï„Î¿ Î¼Î®ÎºÎ¿Ï‚ Ï„Î¿Ï… Ï€Î±ÏÎ±Î¸ÏÏÎ¿Ï…\n",
        "    min_episode_len = max(50, median_rr // 4)\n",
        "    max_episode_len = min(1000, median_rr * 2)\n",
        "\n",
        "    episodes = []\n",
        "    for r in r_peaks:\n",
        "        half_len = median_rr // 2\n",
        "        start = max(0, r - half_len)\n",
        "        end = min(len(signal), r + half_len)\n",
        "\n",
        "        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÎµÎ³ÎºÏ…ÏÏŒÏ„Î·Ï„Î±Ï‚ Î¼Î®ÎºÎ¿Ï…Ï‚ Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚\n",
        "        if (end - start) >= min_episode_len and (end - start) <= max_episode_len:\n",
        "            episodes.append((start, end))\n",
        "\n",
        "    return episodes\n",
        "\n",
        "def assign_labels_to_episodes(episodes, ann_samples, ann_symbols, label_map):\n",
        "    \"\"\"Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ (annotations) ÏƒÏ„Î± ÎµÎ¾Î±Î³ÏŒÎ¼ÎµÎ½Î± Ï„Î¼Î®Î¼Î±Ï„Î± (episodes).\"\"\"\n",
        "    labels = []\n",
        "    ann_samples = np.array(ann_samples)\n",
        "\n",
        "    for start, end in episodes:\n",
        "        center = (start + end) // 2\n",
        "\n",
        "        # Î•ÏÏÎµÏƒÎ· Ï„Î¿Ï… Ï€Î»Î·ÏƒÎ¹Î­ÏƒÏ„ÎµÏÎ¿Ï… annotation ÏƒÏ„Î¿ ÎºÎ­Î½Ï„ÏÎ¿ Ï„Î¿Ï… Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚\n",
        "        distances = np.abs(ann_samples - center)\n",
        "        nearest_idx = np.argmin(distances)\n",
        "\n",
        "        # Î‘Ï€Î¿Î´Î¿Ï‡Î® ÎµÏ„Î¹ÎºÎ­Ï„Î±Ï‚ Î¼ÏŒÎ½Î¿ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î±ÏÎºÎµÏ„Î¬ ÎºÎ¿Î½Ï„Î¬ (Ï€.Ï‡. < 1 Î´ÎµÏ…Ï„.)\n",
        "        if distances[nearest_idx] <= TARGET_SAMPLING_RATE:  # 125 Î´ÎµÎ¯Î³Î¼Î±Ï„Î± = 1s\n",
        "            label = ann_symbols[nearest_idx]\n",
        "            if label in label_map:\n",
        "                labels.append(label_map[label])\n",
        "            else:\n",
        "                labels.append(4)  # Î†Î³Î½Ï‰ÏƒÏ„Î· ÎºÎ»Î¬ÏƒÎ·\n",
        "        else:\n",
        "            labels.append(None)  # Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚ (ÎºÎ±Î¼Î¯Î± ÎµÏ„Î¹ÎºÎ­Ï„Î± ÎºÎ¿Î½Ï„Î¬)\n",
        "\n",
        "    return labels\n",
        "\n",
        "def pad_signal(signal, max_len):\n",
        "    \"\"\"Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· padding (Î¼Îµ Î¼Î·Î´ÎµÎ½Î¹ÎºÎ¬) Î® Ï€ÎµÏÎ¹ÎºÎ¿Ï€Î® Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒ Î¼Î®ÎºÎ¿Ï‚.\"\"\"\n",
        "    if len(signal) < max_len:\n",
        "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
        "    else:\n",
        "        return signal[:max_len]\n",
        "\n",
        "def preprocess_mitbih_dataset(dataset_dir):\n",
        "    \"\"\"ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î³Î¹Î± Ï„Î¿ MIT-BIH dataset.\"\"\"\n",
        "    all_beats, all_labels = [], []\n",
        "    processed_files = 0\n",
        "    total_files = len([f for f in os.listdir(dataset_dir) if f.endswith('.dat')])\n",
        "\n",
        "    print(f\"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± {total_files} Î±ÏÏ‡ÎµÎ¯Ï‰Î½ MIT-BIH...\")\n",
        "\n",
        "    for file in sorted(os.listdir(dataset_dir)):\n",
        "        if file.endswith('.dat'):\n",
        "            record_name = file.replace('.dat', '')\n",
        "            record_path = os.path.join(dataset_dir, record_name)\n",
        "\n",
        "            print(f\"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± {record_name} ({processed_files+1}/{total_files})\")\n",
        "\n",
        "            # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ·\n",
        "            signal, ann_samples, ann_symbols = load_mitbih_record(record_path)\n",
        "            if signal is None:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # 2. Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± (Signal & Annotations)\n",
        "                signal_down = downsample_signal(signal)\n",
        "                ann_samples_down = (np.array(ann_samples) * (TARGET_SAMPLING_RATE / 360)).astype(int)\n",
        "\n",
        "                # 3. ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·\n",
        "                signal_norm = normalize_signal(signal_down)\n",
        "\n",
        "                if np.all(signal_norm == 0):\n",
        "                    print(f\"  Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {record_name}: Î±Ï€Î­Ï„Ï…Ï‡Îµ Î· ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·\")\n",
        "                    continue\n",
        "\n",
        "                # 4. Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· R-peaks (Î±Ï€ÏŒ Ï„Î¿ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î¿ ÏƒÎ®Î¼Î±)\n",
        "                r_peaks = detect_r_peaks(signal_norm, TARGET_SAMPLING_RATE)\n",
        "\n",
        "                if len(r_peaks) < 2:\n",
        "                    print(f\"  Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {record_name}: Î±Î½ÎµÏ€Î±ÏÎºÎ® R-peaks\")\n",
        "                    continue\n",
        "\n",
        "                # 5. Î•Î¾Î±Î³Ï‰Î³Î® Î¤Î¼Î·Î¼Î¬Ï„Ï‰Î½ (Î§Ï„ÏÏ€Ï‰Î½)\n",
        "                t_episodes = extract_t_episodes(signal_norm, r_peaks)\n",
        "\n",
        "                # 6. Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Î•Ï„Î¹ÎºÎµÏ„ÏÎ½ (Î¼Îµ Ï„Î± downsampled annotations)\n",
        "                labels = assign_labels_to_episodes(t_episodes, ann_samples_down, ann_symbols, label_mapping)\n",
        "\n",
        "                # 7. Î£Ï…Î»Î»Î¿Î³Î® Î­Î³ÎºÏ…ÏÏ‰Î½ Ï‡Ï„ÏÏ€Ï‰Î½\n",
        "                valid_episodes = 0\n",
        "                for (start, end), label in zip(t_episodes, labels):\n",
        "                    if label is not None:\n",
        "                        beat = signal_norm[start:end]\n",
        "                        if len(beat) > 0:\n",
        "                            padded = pad_signal(beat, MAX_LEN_MITBIH)\n",
        "                            all_beats.append(padded)\n",
        "                            all_labels.append(label)\n",
        "                            valid_episodes += 1\n",
        "\n",
        "                print(f\"  Î•Î¾Î±Î³Ï‰Î³Î® {valid_episodes} Î­Î³ÎºÏ…ÏÏ‰Î½ Ï‡Ï„ÏÏ€Ï‰Î½ Î±Ï€ÏŒ {record_name}\")\n",
        "                processed_files += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± {record_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"\\nÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± {processed_files}/{total_files} Î±ÏÏ‡ÎµÎ¯Ï‰Î½\")\n",
        "    print(f\"Î£Ï…Î½Î¿Î»Î¹ÎºÎ¿Î¯ Ï‡Ï„ÏÏ€Î¿Î¹ Ï€Î¿Ï… ÎµÎ¾Î®Ï‡Î¸Î·ÏƒÎ±Î½: {len(all_beats)}\")\n",
        "\n",
        "    return np.array(all_beats), np.array(all_labels)\n",
        "\n",
        "# --- ÎšÏÏÎ¹Î± Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ---\n",
        "\n",
        "# Î•Ï†Î±ÏÎ¼Î¿Î³Î® Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚\n",
        "mitbih_signals, mitbih_labels = preprocess_mitbih_dataset(\"data/mit-bih-arrhythmia-database-1.0.0\")\n",
        "\n",
        "# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ PyTorch tensors\n",
        "X_mitbih = torch.tensor(mitbih_signals, dtype=torch.float32)\n",
        "y_mitbih = torch.tensor(mitbih_labels, dtype=torch.long)\n",
        "\n",
        "# Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½\n",
        "with gzip.open(\"mitbih_beats.pkl.gz\", \"wb\") as f:\n",
        "    pickle.dump((X_mitbih, y_mitbih), f)\n",
        "\n",
        "print(f\"\\nÎ¤ÎµÎ»Î¹ÎºÏŒ ÏƒÏ‡Î®Î¼Î± (MIT-BIH Beats): {X_mitbih.shape}\")\n",
        "\n",
        "# Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎºÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½\n",
        "print(\"\\nÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î•Ï„Î¹ÎºÎµÏ„ÏÎ½:\")\n",
        "label_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "unique_labels, counts = np.unique(mitbih_labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    if label < len(label_names):\n",
        "        print(f\"  {label_names[label]} (ÎšÎ»Î¬ÏƒÎ· {label}): {count} Ï‡Ï„ÏÏ€Î¿Î¹ ({count/len(mitbih_labels)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbR2IjQu_e2y",
        "outputId": "f940335a-7259-4dff-f9b7-9b6e383280c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âš ï¸  File not found: /content/drive/MyDrive/ECGData/pretrained_model_best.pth.gz\n",
            "âš ï¸  File not found: /content/drive/MyDrive/ECGData/pretraining_data.pkl.gz\n",
            "âš ï¸  File not found: /content/drive/MyDrive/ECGData/mitbih_beats.pkl.gz\n",
            "\n",
            "ğŸ“ Files in /content/:\n",
            "  âœ… pretrained_model_best.pth.gz (14.1 MB)\n",
            "  âœ… pretraining_data.pkl.gz (112.4 MB)\n",
            "  âœ… mitbih_beats.pkl.gz (37.1 MB)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´Î¹Î±Î´ÏÎ¿Î¼ÏÎ½ ÎºÎ±Î¹ Î±ÏÏ‡ÎµÎ¯Ï‰Î½\n",
        "# Î’Î±ÏƒÎ¹ÎºÏŒÏ‚ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÏƒÏ„Î¿ Drive ÏŒÏ€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î± Ï„Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î±\n",
        "drive_base = \"/content/drive/MyDrive/ECGData\"\n",
        "# Î›Î¯ÏƒÏ„Î± Ï„Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Ï€ÏÎ¿Ï‚ Î¼ÎµÏ„Î±Ï†Î¿ÏÎ¬ ÏƒÏ„Î¿Î½ Ï„Î¿Ï€Î¹ÎºÏŒ Ï‡ÏÏÎ¿ Ï„Î¿Ï… Colab\n",
        "files_to_copy = [\n",
        "    \"pretrained_model_best.pth.gz\", # Î¤Î± Î²Î¬ÏÎ· Ï„Î¿Ï… Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…\n",
        "    \"pretraining_data.pkl.gz\",      # Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (PhysioNet)\n",
        "    \"mitbih_beats.pkl.gz\"           # Î¤Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± (MIT-BIH)\n",
        "]\n",
        "\n",
        "# 3. Î‘Î½Ï„Î¹Î³ÏÎ±Ï†Î® Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î±Ï€ÏŒ Ï„Î¿ Drive ÏƒÏ„Î¿ Colab\n",
        "print(\"--- ÎˆÎ½Î±ÏÎ¾Î· Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î®Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î±Ï€ÏŒ Ï„Î¿ Drive ---\")\n",
        "for file_name in files_to_copy:\n",
        "    source_path = f\"{drive_base}/{file_name}\"\n",
        "\n",
        "    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÏÏ€Î±ÏÎ¾Î·Ï‚ Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÏƒÏ„Î¿ Drive Ï€ÏÎ¹Î½ Ï„Î·Î½ Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î®\n",
        "    if os.path.exists(source_path):\n",
        "        # Î§ÏÎ®ÏƒÎ· !cp Î³Î¹Î± ÎµÎºÏ„Î­Î»ÎµÏƒÎ· ÎµÎ½Ï„Î¿Î»Î®Ï‚ shell (Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î®)\n",
        "        !cp \"{source_path}\" /content/\n",
        "        print(f\"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {file_name}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ \tÎ ÏÎ¿ÏƒÎ¿Ï‡Î®: Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î¿ Drive: {source_path}\")\n",
        "\n",
        "# 4. Î•Ï€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ· ÏÏ€Î±ÏÎ¾Î·Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ ÏƒÏ„Î¿Î½ Ï„Î¿Ï€Î¹ÎºÏŒ Ï‡ÏÏÎ¿ (/content/)\n",
        "print(\"\\nğŸ“ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ ÏƒÏ„Î¿Î½ Ï„Î¿Ï€Î¹ÎºÏŒ Ï†Î¬ÎºÎµÎ»Î¿ /content/:\")\n",
        "for file_name in files_to_copy:\n",
        "    local_path = f\"/content/{file_name}\"\n",
        "    if os.path.exists(local_path):\n",
        "        size_mb = os.path.getsize(local_path) / (1024*1024)\n",
        "        print(f\"  âœ… {file_name} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"  âŒ {file_name} - Î— Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î® Î±Ï€Î­Ï„Ï…Ï‡Îµ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from NNModel import ECGClassifier # Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Ï„Î·Ï‚ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------\n",
        "# 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (MIT-BIH)\n",
        "# --------------------\n",
        "print(\"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ MIT-BIH...\")\n",
        "with gzip.open(\"mitbih_beats.pkl.gz\", \"rb\") as f:\n",
        "    X_mit, y_mit = pickle.load(f)\n",
        "\n",
        "print(f\"Data shape: {X_mit.shape}\")\n",
        "print(f\"Labels shape: {y_mit.shape}\")\n",
        "\n",
        "# Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎºÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½\n",
        "unique_labels, counts = np.unique(y_mit, return_counts=True)\n",
        "print(f\"\\nÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½:\")\n",
        "class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    percentage = (count / len(y_mit)) * 100\n",
        "    print(f\"  ÎšÎ»Î¬ÏƒÎ· {label} ({class_names[label]}): {count} Î´ÎµÎ¯Î³Î¼Î±Ï„Î± ({percentage:.2f}%)\")\n",
        "\n",
        "# Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½: Train-Validation-Test (60/20/20)\n",
        "# Î§ÏÎ®ÏƒÎ· 'stratify' Î³Î¹Î± Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· Ï„Î·Ï‚ Î±Î½Î±Î»Î¿Î³Î¯Î±Ï‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½ ÏƒÏ„Î± ÏƒÏÎ½Î¿Î»Î±\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_mit, y_mit, test_size=0.2, random_state=42, stratify=y_mit\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val  # 0.25 Ï„Î¿Ï… 0.8 = 0.2\n",
        ")\n",
        "\n",
        "print(f\"\\nÎœÎµÎ³Î­Î¸Î· ÏƒÏ…Î½ÏŒÎ»Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:\")\n",
        "print(f\"  Train: {X_train.shape[0]} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±\")\n",
        "print(f\"  Validation: {X_val.shape[0]} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±\")\n",
        "print(f\"  Test: {X_test.shape[0]} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±\")\n",
        "\n",
        "# --------------------\n",
        "# 2. Custom Dataset Class (Î¼Îµ Data Augmentation)\n",
        "# --------------------\n",
        "class ECGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = X.unsqueeze(1) if X.dim() == 2 else X  # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î´Î¹Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚ ÎºÎ±Î½Î±Î»Î¹Î¿Ï (B, C, L)\n",
        "        self.y = y\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx].clone()\n",
        "        y = self.y[idx]\n",
        "\n",
        "        # Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î±Ï€Î»ÏÎ½ Ï„ÎµÏ‡Î½Î¹ÎºÏÎ½ Î±ÏÎ¾Î·ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¿ training set)\n",
        "        if self.augment:\n",
        "            # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î¸Î¿ÏÏÎ²Î¿Ï… (noise)\n",
        "            if np.random.rand() < 0.3:\n",
        "                noise = torch.randn_like(x) * 0.01\n",
        "                x = x + noise\n",
        "\n",
        "            # ÎœÎ¹ÎºÏÎ® Ï‡ÏÎ¿Î½Î¹ÎºÎ® Î¼ÎµÏ„Î±Ï„ÏŒÏ€Î¹ÏƒÎ· (time shift)\n",
        "            if np.random.rand() < 0.3:\n",
        "                shift = np.random.randint(-10, 11)\n",
        "                x = torch.roll(x, shift, dims=-1)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# --------------------\n",
        "# 3. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataLoaders\n",
        "# --------------------\n",
        "batch_size = 128\n",
        "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
        "val_dataset = ECGDataset(X_val, y_val, augment=False)\n",
        "test_dataset = ECGDataset(X_test, y_test, augment=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=2, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
        "                                       shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "# --------------------\n",
        "# 4. Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… (Transfer Learning)\n",
        "# --------------------\n",
        "print(\"\\nÎ‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…...\")\n",
        "model = ECGClassifier(num_classes=5) # 5 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î¿ MIT-BIH\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Î§ÏÎ®ÏƒÎ· ÏƒÏ…ÏƒÎºÎµÏ…Î®Ï‚: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Ï‰Î½ Î²Î±ÏÏÎ½ (Î±Ï€ÏŒ Ï„Î¿ PhysioNet pretraining)\n",
        "try:\n",
        "    with gzip.open(\"pretrained_model_best.pth.gz\", \"rb\") as f:\n",
        "        pretrained_dict = pickle.load(f)\n",
        "\n",
        "    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î±: Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Ï„Î¿Ï… Ï„ÎµÎ»Î¹ÎºÎ¿Ï ÎµÏ€Î¹Ï€Î­Î´Î¿Ï… Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ (fc2)\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
        "                       if not k.startswith('fc2')}\n",
        "\n",
        "    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Ï‰Î½ Î²Î±ÏÏÎ½ (strict=False Î³Î¹Î± Î½Î± Î±Î³Î½Î¿Î·Î¸ÎµÎ¯ Ï„Î¿ fc2 Ï€Î¿Ï… Î»ÎµÎ¯Ï€ÎµÎ¹)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(pretrained_dict, strict=False)\n",
        "    print(f\"Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î²Î¬ÏÎ·. Missing: {len(missing_keys)}, Unexpected: {len(unexpected_keys)}\")\n",
        "\n",
        "    # Î•Ï€Î±Î½Î±-Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… Ï„ÎµÎ»Î¹ÎºÎ¿Ï (FC) ÎµÏ€Î¹Ï€Î­Î´Î¿Ï… Î³Î¹Î± 5 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚\n",
        "    model.fc2 = nn.Linear(model.fc2.in_features, 5).to(device)\n",
        "    nn.init.kaiming_normal_(model.fc2.weight)\n",
        "    nn.init.constant_(model.fc2.bias, 0)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î‘Î´Ï…Î½Î±Î¼Î¯Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Ï‰Î½ Î²Î±ÏÏÎ½: {e}\")\n",
        "    print(\"Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏÏ‡Î® (scratch)...\")\n",
        "\n",
        "# --------------------\n",
        "# 5. Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Loss, Optimizer, Weights)\n",
        "# --------------------\n",
        "# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î²Î±ÏÏÎ½ (class weights) Î³Î¹Î± Ï„Î¿ Î±Î½Î¹ÏƒÏŒÏÏÎ¿Ï€Î¿ dataset\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                   classes=np.unique(y_train.numpy()),\n",
        "                                   y=y_train.numpy())\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Î§ÏÎ®ÏƒÎ· Î²Î±ÏÏÎ½ ÏƒÏ„Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î±Ï€ÏÎ»ÎµÎ¹Î±Ï‚ (CrossEntropyLoss)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "# Scheduler Î³Î¹Î± Î´Ï…Î½Î±Î¼Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® Ï„Î¿Ï… learning rate\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5,\n",
        "                                               factor=0.5)\n",
        "\n",
        "# --------------------\n",
        "# 6. ÎšÏÏÎ¹Î¿Ï‚ Î’ÏÏŒÏ‡Î¿Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Fine-Tuning Loop)\n",
        "# --------------------\n",
        "num_epochs = 50\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "patience = 10 # Î¥Ï€Î¿Î¼Î¿Î½Î® Î³Î¹Î± Ï„Î¿ Early Stopping\n",
        "\n",
        "train_losses, val_losses, val_accs = [], [], [] # Î“Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÎ¿Ï\n",
        "\n",
        "print(f\"\\nÎˆÎ½Î±ÏÎ¾Î· ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (fine-tuning) Î³Î¹Î± {num_epochs} ÎºÏÎºÎ»Î¿Ï…Ï‚...\")\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # --- Î¦Î¬ÏƒÎ· Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Training) ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒÏ„Î·Ï„Î±\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            # --- Î•Î”Î© Î•Î“Î™ÎÎ• Î— Î‘Î›Î›Î‘Î“Î— ---\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, \"\n",
        "                  f\"Loss: {loss.item():.4f}, Acc: {100*correct/total:.2f}%\")\n",
        "\n",
        "    train_acc = 100.0 * correct / total\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # --- Î¦Î¬ÏƒÎ· Î•Ï€Î¹ÎºÏÏÏ‰ÏƒÎ·Ï‚ (Validation) ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad(): # Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï ÎºÎ»Î¯ÏƒÎµÏ‰Î½\n",
        "        for X_val, y_val_batch in val_loader:\n",
        "            X_val, y_val_batch = X_val.to(device), y_val_batch.to(device)\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss += criterion(val_outputs, y_val_batch).item()\n",
        "\n",
        "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
        "            val_total += y_val_batch.size(0)\n",
        "            val_correct += (val_predicted == y_val_batch).sum().item()\n",
        "\n",
        "    val_acc = 100.0 * val_correct / val_total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï„Î¿Ï… scheduler\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # --- Î•Î”Î© Î•Î“Î™ÎÎ• Î— Î‘Î›Î›Î‘Î“Î— ---\n",
        "    print(f\"ÎšÏÎºÎ»Î¿Ï‚ {epoch+1}/{num_epochs}:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # --- ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Early Stopping & Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎšÎ±Î»ÏÏ„ÎµÏÎ¿Ï… ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… ---\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0 # ÎœÎ·Î´ÎµÎ½Î¹ÏƒÎ¼ÏŒÏ‚ Ï…Ï€Î¿Î¼Î¿Î½Î®Ï‚\n",
        "\n",
        "        # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î¼Îµ Ï„Î·Î½ ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÎµÏ€Î¯Î´Î¿ÏƒÎ·\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(f\"  ğŸ’¾ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î½Î­Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿! Val Acc: {val_acc:.2f}%\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Ï„ÎµÏÎ¼Î±Ï„Î¹ÏƒÎ¼ÏŒ (Early Stopping)\n",
        "    if patience_counter >= patience:\n",
        "        # --- Î•Î”Î© Î•Î“Î™ÎÎ• Î— Î‘Î›Î›Î‘Î“Î— ---\n",
        "        print(f\"Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Early Stopping Î¼ÎµÏ„Î¬ Î±Ï€ÏŒ {epoch+1} ÎºÏÎºÎ»Î¿Ï…Ï‚\")\n",
        "        break\n",
        "\n",
        "# --------------------\n",
        "# 7. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎšÎ±Î»ÏÏ„ÎµÏÎ¿Ï… ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… & Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ Drive\n",
        "# --------------------\n",
        "\n",
        "# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î¿Ï… ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Ï€Î¿Ï… Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÎºÎ±Ï„Î¬ Ï„Î· Î´Î¹Î¬ÏÎºÎµÎ¹Î± Ï„Î¿Ï… training\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "print(f\"\\nÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·! ÎšÎ±Î»ÏÏ„ÎµÏÎ· Î±ÎºÏÎ¯Î²ÎµÎ¹Î± (validation): {best_val_acc:.2f}%\")\n",
        "\n",
        "# Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… Ï„ÎµÎ»Î¹ÎºÎ¿Ï (ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï…) Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÏ„Î¿ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "final_model_path = \"/content/drive/MyDrive/ColabData/ECG/ecg_mitbih_finetuned_improved.pth\"\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"Î¤Î¿ Ï„ÎµÎ»Î¹ÎºÏŒ (ÎºÎ±Î»ÏÏ„ÎµÏÎ¿) Î¼Î¿Î½Ï„Î­Î»Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿ Drive: {final_model_path}\")"
      ],
      "metadata": {
        "id": "TqnXx8BVaxaG",
        "outputId": "0ec1cd5c-ae2c-4dfb-e97c-f58eb26f463a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MIT-BIH data...\n",
            "Data shape: torch.Size([109067, 3750])\n",
            "Labels shape: torch.Size([109067])\n",
            "\n",
            "Class distribution:\n",
            "  Class 0 (Normal): 89860 samples (82.39%)\n",
            "  Class 1 (Supraventricular): 2952 samples (2.71%)\n",
            "  Class 2 (Ventricular): 7003 samples (6.42%)\n",
            "  Class 3 (Fusion): 799 samples (0.73%)\n",
            "  Class 4 (Unknown): 8453 samples (7.75%)\n",
            "\n",
            "Data splits:\n",
            "  Train: 65439 samples\n",
            "  Validation: 21814 samples\n",
            "  Test: 21814 samples\n",
            "\n",
            "Initializing model...\n",
            "Using device: cuda\n",
            "Loaded pretrained weights. Missing: 2, Unexpected: 0\n",
            "Class weights: tensor([ 0.2427,  7.3859,  3.1147, 27.3232,  2.5809], device='cuda:0')\n",
            "\n",
            "Starting training for 50 epochs...\n",
            "Epoch 1, Batch 0/511, Loss: 2.5241, Acc: 9.38%\n",
            "Epoch 1, Batch 50/511, Loss: 1.5452, Acc: 35.48%\n",
            "Epoch 1, Batch 100/511, Loss: 1.4639, Acc: 31.95%\n",
            "Epoch 1, Batch 150/511, Loss: 1.2908, Acc: 31.93%\n",
            "Epoch 1, Batch 200/511, Loss: 1.1321, Acc: 34.92%\n",
            "Epoch 1, Batch 250/511, Loss: 1.4973, Acc: 38.02%\n",
            "Epoch 1, Batch 300/511, Loss: 0.8495, Acc: 40.85%\n",
            "Epoch 1, Batch 350/511, Loss: 0.9421, Acc: 43.74%\n",
            "Epoch 1, Batch 400/511, Loss: 0.7078, Acc: 47.39%\n",
            "Epoch 1, Batch 450/511, Loss: 0.4659, Acc: 49.82%\n",
            "Epoch 1, Batch 500/511, Loss: 0.6633, Acc: 51.47%\n",
            "Epoch 1/50:\n",
            "  Train Loss: 1.1300, Train Acc: 51.91%\n",
            "  Val Loss: 0.5798, Val Acc: 89.90%\n",
            "  LR: 0.001000\n",
            "  ğŸ’¾ New best model saved! Val Acc: 89.90%\n",
            "Epoch 2, Batch 0/511, Loss: 0.3690, Acc: 78.12%\n",
            "Epoch 2, Batch 50/511, Loss: 0.5860, Acc: 75.87%\n",
            "Epoch 2, Batch 100/511, Loss: 0.4076, Acc: 75.34%\n",
            "Epoch 2, Batch 150/511, Loss: 0.1450, Acc: 77.11%\n",
            "Epoch 2, Batch 200/511, Loss: 0.2655, Acc: 79.29%\n",
            "Epoch 2, Batch 250/511, Loss: 0.5522, Acc: 80.38%\n",
            "Epoch 2, Batch 300/511, Loss: 0.3420, Acc: 81.55%\n",
            "Epoch 2, Batch 350/511, Loss: 0.5327, Acc: 82.37%\n",
            "Epoch 2, Batch 400/511, Loss: 0.3776, Acc: 83.21%\n",
            "Epoch 2, Batch 450/511, Loss: 0.2928, Acc: 83.70%\n",
            "Epoch 2, Batch 500/511, Loss: 0.3137, Acc: 84.42%\n",
            "Epoch 2/50:\n",
            "  Train Loss: 0.5010, Train Acc: 84.55%\n",
            "  Val Loss: 0.2703, Val Acc: 92.80%\n",
            "  LR: 0.001000\n",
            "  ğŸ’¾ New best model saved! Val Acc: 92.80%\n",
            "Epoch 3, Batch 0/511, Loss: 0.1045, Acc: 95.31%\n",
            "Epoch 3, Batch 50/511, Loss: 0.1876, Acc: 92.65%\n",
            "Epoch 3, Batch 100/511, Loss: 0.2808, Acc: 92.50%\n",
            "Epoch 3, Batch 150/511, Loss: 0.1539, Acc: 92.70%\n",
            "Epoch 3, Batch 200/511, Loss: 0.2030, Acc: 92.79%\n",
            "Epoch 3, Batch 250/511, Loss: 0.2418, Acc: 92.80%\n",
            "Epoch 3, Batch 300/511, Loss: 0.1259, Acc: 92.59%\n",
            "Epoch 3, Batch 350/511, Loss: 1.6067, Acc: 92.46%\n",
            "Epoch 3, Batch 400/511, Loss: 0.1923, Acc: 92.64%\n",
            "Epoch 3, Batch 450/511, Loss: 0.0470, Acc: 92.72%\n",
            "Epoch 3, Batch 500/511, Loss: 0.1779, Acc: 92.75%\n",
            "Epoch 3/50:\n",
            "  Train Loss: 0.3136, Train Acc: 92.74%\n",
            "  Val Loss: 0.2940, Val Acc: 95.68%\n",
            "  LR: 0.001000\n",
            "  ğŸ’¾ New best model saved! Val Acc: 95.68%\n",
            "Epoch 4, Batch 0/511, Loss: 0.2025, Acc: 95.31%\n",
            "Epoch 4, Batch 50/511, Loss: 0.1425, Acc: 94.47%\n",
            "Epoch 4, Batch 100/511, Loss: 1.0774, Acc: 94.38%\n",
            "Epoch 4, Batch 150/511, Loss: 0.2001, Acc: 94.15%\n",
            "Epoch 4, Batch 200/511, Loss: 0.0780, Acc: 94.16%\n",
            "Epoch 4, Batch 250/511, Loss: 0.0645, Acc: 94.22%\n",
            "Epoch 4, Batch 300/511, Loss: 0.2522, Acc: 94.17%\n",
            "Epoch 4, Batch 350/511, Loss: 1.9173, Acc: 94.20%\n",
            "Epoch 4, Batch 400/511, Loss: 0.1146, Acc: 94.31%\n",
            "Epoch 4, Batch 450/511, Loss: 0.5217, Acc: 94.36%\n",
            "Epoch 4, Batch 500/511, Loss: 0.0628, Acc: 94.47%\n",
            "Epoch 4/50:\n",
            "  Train Loss: 0.2868, Train Acc: 94.49%\n",
            "  Val Loss: 0.2089, Val Acc: 96.27%\n",
            "  LR: 0.001000\n",
            "  ğŸ’¾ New best model saved! Val Acc: 96.27%\n",
            "Epoch 5, Batch 0/511, Loss: 0.1125, Acc: 96.88%\n",
            "Epoch 5, Batch 50/511, Loss: 0.2525, Acc: 94.49%\n",
            "Epoch 5, Batch 100/511, Loss: 0.0617, Acc: 94.64%\n",
            "Epoch 5, Batch 150/511, Loss: 0.3526, Acc: 94.79%\n",
            "Epoch 5, Batch 200/511, Loss: 0.2127, Acc: 94.72%\n",
            "Epoch 5, Batch 250/511, Loss: 1.3861, Acc: 94.61%\n",
            "Epoch 5, Batch 300/511, Loss: 0.2857, Acc: 94.79%\n",
            "Epoch 5, Batch 350/511, Loss: 0.0539, Acc: 94.75%\n",
            "Epoch 5, Batch 400/511, Loss: 0.0415, Acc: 94.95%\n",
            "Epoch 5, Batch 450/511, Loss: 0.0808, Acc: 95.00%\n",
            "Epoch 5, Batch 500/511, Loss: 0.0802, Acc: 95.10%\n",
            "Epoch 5/50:\n",
            "  Train Loss: 0.2343, Train Acc: 95.08%\n",
            "  Val Loss: 0.2478, Val Acc: 97.38%\n",
            "  LR: 0.001000\n",
            "  ğŸ’¾ New best model saved! Val Acc: 97.38%\n",
            "Epoch 6, Batch 0/511, Loss: 1.5042, Acc: 94.53%\n",
            "Epoch 6, Batch 50/511, Loss: 0.1214, Acc: 95.62%\n",
            "Epoch 6, Batch 100/511, Loss: 0.0539, Acc: 96.12%\n",
            "Epoch 6, Batch 150/511, Loss: 0.5326, Acc: 95.63%\n",
            "Epoch 6, Batch 200/511, Loss: 0.1367, Acc: 95.39%\n",
            "Epoch 6, Batch 250/511, Loss: 1.3560, Acc: 95.50%\n",
            "Epoch 6, Batch 300/511, Loss: 0.0816, Acc: 95.46%\n",
            "Epoch 6, Batch 350/511, Loss: 0.0765, Acc: 95.48%\n",
            "Epoch 6, Batch 400/511, Loss: 0.0786, Acc: 95.58%\n",
            "Epoch 6, Batch 450/511, Loss: 0.0357, Acc: 95.68%\n",
            "Epoch 6, Batch 500/511, Loss: 0.0234, Acc: 95.72%\n",
            "Epoch 6/50:\n",
            "  Train Loss: 0.2134, Train Acc: 95.72%\n",
            "  Val Loss: 0.1881, Val Acc: 93.54%\n",
            "  LR: 0.001000\n",
            "Epoch 7, Batch 0/511, Loss: 0.0395, Acc: 95.31%\n",
            "Epoch 7, Batch 50/511, Loss: 0.0435, Acc: 94.30%\n",
            "Epoch 7, Batch 100/511, Loss: 0.0758, Acc: 95.00%\n",
            "Epoch 7, Batch 150/511, Loss: 0.0754, Acc: 95.12%\n",
            "Epoch 7, Batch 200/511, Loss: 0.0596, Acc: 95.41%\n",
            "Epoch 7, Batch 250/511, Loss: 0.0215, Acc: 95.56%\n",
            "Epoch 7, Batch 300/511, Loss: 0.1860, Acc: 95.67%\n",
            "Epoch 7, Batch 350/511, Loss: 0.3747, Acc: 95.65%\n",
            "Epoch 7, Batch 400/511, Loss: 0.2949, Acc: 95.50%\n",
            "Epoch 7, Batch 450/511, Loss: 0.1546, Acc: 95.51%\n",
            "Epoch 7, Batch 500/511, Loss: 0.6116, Acc: 95.53%\n",
            "Epoch 7/50:\n",
            "  Train Loss: 0.1965, Train Acc: 95.52%\n",
            "  Val Loss: 0.2709, Val Acc: 79.92%\n",
            "  LR: 0.001000\n",
            "Epoch 8, Batch 0/511, Loss: 0.0857, Acc: 99.22%\n",
            "Epoch 8, Batch 50/511, Loss: 0.0192, Acc: 96.42%\n",
            "Epoch 8, Batch 100/511, Loss: 0.0369, Acc: 96.53%\n",
            "Epoch 8, Batch 150/511, Loss: 0.0719, Acc: 96.53%\n",
            "Epoch 8, Batch 200/511, Loss: 0.0537, Acc: 96.44%\n",
            "Epoch 8, Batch 250/511, Loss: 0.1506, Acc: 96.30%\n",
            "Epoch 8, Batch 300/511, Loss: 0.0643, Acc: 96.25%\n",
            "Epoch 8, Batch 350/511, Loss: 0.1746, Acc: 96.26%\n",
            "Epoch 8, Batch 400/511, Loss: 0.0276, Acc: 96.24%\n",
            "Epoch 8, Batch 450/511, Loss: 0.1080, Acc: 96.30%\n",
            "Epoch 8, Batch 500/511, Loss: 0.0441, Acc: 96.30%\n",
            "Epoch 8/50:\n",
            "  Train Loss: 0.1725, Train Acc: 96.31%\n",
            "  Val Loss: 0.1575, Val Acc: 96.71%\n",
            "  LR: 0.001000\n",
            "Epoch 9, Batch 0/511, Loss: 0.0245, Acc: 96.88%\n",
            "Epoch 9, Batch 50/511, Loss: 0.0595, Acc: 96.25%\n",
            "Epoch 9, Batch 100/511, Loss: 0.2324, Acc: 96.57%\n",
            "Epoch 9, Batch 150/511, Loss: 0.8265, Acc: 96.69%\n",
            "Epoch 9, Batch 200/511, Loss: 0.0618, Acc: 96.76%\n",
            "Epoch 9, Batch 250/511, Loss: 0.1269, Acc: 96.63%\n",
            "Epoch 9, Batch 300/511, Loss: 0.0591, Acc: 96.58%\n",
            "Epoch 9, Batch 350/511, Loss: 0.1601, Acc: 96.50%\n",
            "Epoch 9, Batch 400/511, Loss: 0.0922, Acc: 96.51%\n",
            "Epoch 9, Batch 450/511, Loss: 0.0201, Acc: 96.47%\n",
            "Epoch 9, Batch 500/511, Loss: 0.0305, Acc: 96.43%\n",
            "Epoch 9/50:\n",
            "  Train Loss: 0.1645, Train Acc: 96.43%\n",
            "  Val Loss: 0.1618, Val Acc: 97.35%\n",
            "  LR: 0.001000\n",
            "Epoch 10, Batch 0/511, Loss: 0.0562, Acc: 94.53%\n",
            "Epoch 10, Batch 50/511, Loss: 0.0410, Acc: 97.33%\n",
            "Epoch 10, Batch 100/511, Loss: 0.4780, Acc: 96.90%\n",
            "Epoch 10, Batch 150/511, Loss: 0.1546, Acc: 96.82%\n",
            "Epoch 10, Batch 200/511, Loss: 0.0261, Acc: 96.65%\n",
            "Epoch 10, Batch 250/511, Loss: 0.0409, Acc: 96.50%\n",
            "Epoch 10, Batch 300/511, Loss: 0.0364, Acc: 96.62%\n",
            "Epoch 10, Batch 350/511, Loss: 0.1859, Acc: 96.57%\n",
            "Epoch 10, Batch 400/511, Loss: 0.0266, Acc: 96.56%\n",
            "Epoch 10, Batch 450/511, Loss: 0.1491, Acc: 96.47%\n",
            "Epoch 10, Batch 500/511, Loss: 0.0424, Acc: 96.45%\n",
            "Epoch 10/50:\n",
            "  Train Loss: 0.1572, Train Acc: 96.44%\n",
            "  Val Loss: 0.1810, Val Acc: 97.96%\n",
            "  LR: 0.001000\n",
            "  ğŸ’¾ New best model saved! Val Acc: 97.96%\n",
            "Epoch 11, Batch 0/511, Loss: 0.0190, Acc: 97.66%\n",
            "Epoch 11, Batch 50/511, Loss: 0.0410, Acc: 97.21%\n",
            "Epoch 11, Batch 100/511, Loss: 0.0381, Acc: 97.00%\n",
            "Epoch 11, Batch 150/511, Loss: 0.0121, Acc: 96.72%\n",
            "Epoch 11, Batch 200/511, Loss: 0.0699, Acc: 96.84%\n",
            "Epoch 11, Batch 250/511, Loss: 0.1481, Acc: 96.74%\n",
            "Epoch 11, Batch 300/511, Loss: 0.0656, Acc: 96.71%\n",
            "Epoch 11, Batch 350/511, Loss: 0.0455, Acc: 96.69%\n",
            "Epoch 11, Batch 400/511, Loss: 0.0280, Acc: 96.73%\n",
            "Epoch 11, Batch 450/511, Loss: 0.0809, Acc: 96.82%\n",
            "Epoch 11, Batch 500/511, Loss: 0.1387, Acc: 96.73%\n",
            "Epoch 11/50:\n",
            "  Train Loss: 0.1533, Train Acc: 96.71%\n",
            "  Val Loss: 0.2068, Val Acc: 96.97%\n",
            "  LR: 0.001000\n",
            "Epoch 12, Batch 0/511, Loss: 0.6422, Acc: 97.66%\n",
            "Epoch 12, Batch 50/511, Loss: 0.0285, Acc: 95.88%\n",
            "Epoch 12, Batch 100/511, Loss: 0.0305, Acc: 96.18%\n",
            "Epoch 12, Batch 150/511, Loss: 0.0230, Acc: 96.15%\n",
            "Epoch 12, Batch 200/511, Loss: 0.0216, Acc: 96.37%\n",
            "Epoch 12, Batch 250/511, Loss: 0.0773, Acc: 96.30%\n",
            "Epoch 12, Batch 300/511, Loss: 0.0149, Acc: 96.41%\n",
            "Epoch 12, Batch 350/511, Loss: 0.0185, Acc: 96.48%\n",
            "Epoch 12, Batch 400/511, Loss: 0.0624, Acc: 96.47%\n",
            "Epoch 12, Batch 450/511, Loss: 0.0206, Acc: 96.47%\n",
            "Epoch 12, Batch 500/511, Loss: 0.0234, Acc: 96.50%\n",
            "Epoch 12/50:\n",
            "  Train Loss: 0.1487, Train Acc: 96.51%\n",
            "  Val Loss: 0.1662, Val Acc: 96.80%\n",
            "  LR: 0.001000\n",
            "Epoch 13, Batch 0/511, Loss: 0.3787, Acc: 96.88%\n",
            "Epoch 13, Batch 50/511, Loss: 0.0224, Acc: 96.37%\n",
            "Epoch 13, Batch 100/511, Loss: 0.0141, Acc: 96.69%\n",
            "Epoch 13, Batch 150/511, Loss: 0.0181, Acc: 96.62%\n",
            "Epoch 13, Batch 200/511, Loss: 0.0743, Acc: 96.68%\n",
            "Epoch 13, Batch 250/511, Loss: 0.2762, Acc: 96.82%\n",
            "Epoch 13, Batch 300/511, Loss: 0.0059, Acc: 96.89%\n",
            "Epoch 13, Batch 350/511, Loss: 0.3371, Acc: 96.94%\n",
            "Epoch 13, Batch 400/511, Loss: 0.0629, Acc: 97.03%\n",
            "Epoch 13, Batch 450/511, Loss: 0.0303, Acc: 97.10%\n",
            "Epoch 13, Batch 500/511, Loss: 0.0437, Acc: 97.07%\n",
            "Epoch 13/50:\n",
            "  Train Loss: 0.1350, Train Acc: 97.08%\n",
            "  Val Loss: 0.3590, Val Acc: 91.78%\n",
            "  LR: 0.001000\n",
            "Epoch 14, Batch 0/511, Loss: 0.1333, Acc: 96.09%\n",
            "Epoch 14, Batch 50/511, Loss: 0.0170, Acc: 96.71%\n",
            "Epoch 14, Batch 100/511, Loss: 0.0995, Acc: 96.94%\n",
            "Epoch 14, Batch 150/511, Loss: 0.0134, Acc: 97.11%\n",
            "Epoch 14, Batch 200/511, Loss: 0.0903, Acc: 97.03%\n",
            "Epoch 14, Batch 250/511, Loss: 0.4952, Acc: 97.02%\n",
            "Epoch 14, Batch 300/511, Loss: 0.0555, Acc: 96.95%\n",
            "Epoch 14, Batch 350/511, Loss: 0.0701, Acc: 96.85%\n",
            "Epoch 14, Batch 400/511, Loss: 0.0472, Acc: 96.98%\n",
            "Epoch 14, Batch 450/511, Loss: 0.1010, Acc: 97.02%\n",
            "Epoch 14, Batch 500/511, Loss: 0.0619, Acc: 97.03%\n",
            "Epoch 14/50:\n",
            "  Train Loss: 0.1375, Train Acc: 97.04%\n",
            "  Val Loss: 0.1875, Val Acc: 97.85%\n",
            "  LR: 0.000500\n",
            "Epoch 15, Batch 0/511, Loss: 0.0226, Acc: 97.66%\n",
            "Epoch 15, Batch 50/511, Loss: 0.0271, Acc: 97.61%\n",
            "Epoch 15, Batch 100/511, Loss: 0.0765, Acc: 97.60%\n",
            "Epoch 15, Batch 150/511, Loss: 0.0311, Acc: 97.68%\n",
            "Epoch 15, Batch 200/511, Loss: 0.0219, Acc: 97.70%\n",
            "Epoch 15, Batch 250/511, Loss: 0.0142, Acc: 97.75%\n",
            "Epoch 15, Batch 300/511, Loss: 0.0170, Acc: 97.74%\n",
            "Epoch 15, Batch 350/511, Loss: 0.0488, Acc: 97.73%\n",
            "Epoch 15, Batch 400/511, Loss: 0.0144, Acc: 97.71%\n",
            "Epoch 15, Batch 450/511, Loss: 0.0362, Acc: 97.70%\n",
            "Epoch 15, Batch 500/511, Loss: 0.1492, Acc: 97.68%\n",
            "Epoch 15/50:\n",
            "  Train Loss: 0.1106, Train Acc: 97.68%\n",
            "  Val Loss: 0.1410, Val Acc: 97.99%\n",
            "  LR: 0.000500\n",
            "  ğŸ’¾ New best model saved! Val Acc: 97.99%\n",
            "Epoch 16, Batch 0/511, Loss: 0.0244, Acc: 98.44%\n",
            "Epoch 16, Batch 50/511, Loss: 1.8900, Acc: 98.18%\n",
            "Epoch 16, Batch 100/511, Loss: 0.0311, Acc: 97.80%\n",
            "Epoch 16, Batch 150/511, Loss: 0.0100, Acc: 97.89%\n",
            "Epoch 16, Batch 200/511, Loss: 0.0101, Acc: 97.89%\n",
            "Epoch 16, Batch 250/511, Loss: 0.0327, Acc: 97.87%\n",
            "Epoch 16, Batch 300/511, Loss: 0.0162, Acc: 97.84%\n",
            "Epoch 16, Batch 350/511, Loss: 0.0173, Acc: 97.82%\n",
            "Epoch 16, Batch 400/511, Loss: 0.0347, Acc: 97.81%\n",
            "Epoch 16, Batch 450/511, Loss: 0.0887, Acc: 97.81%\n",
            "Epoch 16, Batch 500/511, Loss: 0.5673, Acc: 97.76%\n",
            "Epoch 16/50:\n",
            "  Train Loss: 0.1046, Train Acc: 97.75%\n",
            "  Val Loss: 0.1176, Val Acc: 97.42%\n",
            "  LR: 0.000500\n",
            "Epoch 17, Batch 0/511, Loss: 0.0437, Acc: 96.09%\n",
            "Epoch 17, Batch 50/511, Loss: 0.0227, Acc: 97.87%\n",
            "Epoch 17, Batch 100/511, Loss: 0.0437, Acc: 97.90%\n",
            "Epoch 17, Batch 150/511, Loss: 0.0266, Acc: 97.95%\n",
            "Epoch 17, Batch 200/511, Loss: 0.1014, Acc: 97.94%\n",
            "Epoch 17, Batch 250/511, Loss: 0.1503, Acc: 97.78%\n",
            "Epoch 17, Batch 300/511, Loss: 0.0198, Acc: 97.84%\n",
            "Epoch 17, Batch 350/511, Loss: 0.0252, Acc: 97.90%\n",
            "Epoch 17, Batch 400/511, Loss: 0.0271, Acc: 97.87%\n",
            "Epoch 17, Batch 450/511, Loss: 0.1239, Acc: 97.83%\n",
            "Epoch 17, Batch 500/511, Loss: 0.0707, Acc: 97.83%\n",
            "Epoch 17/50:\n",
            "  Train Loss: 0.0880, Train Acc: 97.84%\n",
            "  Val Loss: 0.2921, Val Acc: 97.56%\n",
            "  LR: 0.000500\n",
            "Epoch 18, Batch 0/511, Loss: 0.0384, Acc: 99.22%\n",
            "Epoch 18, Batch 50/511, Loss: 0.0173, Acc: 98.25%\n",
            "Epoch 18, Batch 100/511, Loss: 0.0201, Acc: 98.39%\n",
            "Epoch 18, Batch 150/511, Loss: 0.0189, Acc: 98.35%\n",
            "Epoch 18, Batch 200/511, Loss: 0.0094, Acc: 98.26%\n",
            "Epoch 18, Batch 250/511, Loss: 0.1550, Acc: 98.28%\n",
            "Epoch 18, Batch 300/511, Loss: 0.0518, Acc: 98.12%\n",
            "Epoch 18, Batch 350/511, Loss: 0.1616, Acc: 98.09%\n",
            "Epoch 18, Batch 400/511, Loss: 0.0645, Acc: 98.09%\n",
            "Epoch 18, Batch 450/511, Loss: 0.0698, Acc: 98.04%\n",
            "Epoch 18, Batch 500/511, Loss: 0.0969, Acc: 98.03%\n",
            "Epoch 18/50:\n",
            "  Train Loss: 0.1077, Train Acc: 98.03%\n",
            "  Val Loss: 0.1527, Val Acc: 97.87%\n",
            "  LR: 0.000500\n",
            "Epoch 19, Batch 0/511, Loss: 0.0205, Acc: 98.44%\n",
            "Epoch 19, Batch 50/511, Loss: 0.8832, Acc: 98.44%\n",
            "Epoch 19, Batch 100/511, Loss: 0.0159, Acc: 98.17%\n",
            "Epoch 19, Batch 150/511, Loss: 0.1495, Acc: 98.19%\n",
            "Epoch 19, Batch 200/511, Loss: 0.0727, Acc: 98.12%\n",
            "Epoch 19, Batch 250/511, Loss: 0.0319, Acc: 98.08%\n",
            "Epoch 19, Batch 300/511, Loss: 0.0220, Acc: 98.11%\n",
            "Epoch 19, Batch 350/511, Loss: 0.0196, Acc: 97.99%\n",
            "Epoch 19, Batch 400/511, Loss: 0.0184, Acc: 97.90%\n",
            "Epoch 19, Batch 450/511, Loss: 0.0725, Acc: 97.92%\n",
            "Epoch 19, Batch 500/511, Loss: 0.0537, Acc: 97.88%\n",
            "Epoch 19/50:\n",
            "  Train Loss: 0.0942, Train Acc: 97.88%\n",
            "  Val Loss: 0.1338, Val Acc: 98.04%\n",
            "  LR: 0.000500\n",
            "  ğŸ’¾ New best model saved! Val Acc: 98.04%\n",
            "Epoch 20, Batch 0/511, Loss: 0.0058, Acc: 99.22%\n",
            "Epoch 20, Batch 50/511, Loss: 0.2162, Acc: 98.24%\n",
            "Epoch 20, Batch 100/511, Loss: 0.0059, Acc: 98.17%\n",
            "Epoch 20, Batch 150/511, Loss: 0.0153, Acc: 98.07%\n",
            "Epoch 20, Batch 200/511, Loss: 0.0065, Acc: 98.02%\n",
            "Epoch 20, Batch 250/511, Loss: 0.0592, Acc: 97.97%\n",
            "Epoch 20, Batch 300/511, Loss: 0.0229, Acc: 97.93%\n",
            "Epoch 20, Batch 350/511, Loss: 0.0102, Acc: 97.91%\n",
            "Epoch 20, Batch 400/511, Loss: 1.0274, Acc: 97.95%\n",
            "Epoch 20, Batch 450/511, Loss: 0.0227, Acc: 98.00%\n",
            "Epoch 20, Batch 500/511, Loss: 0.1158, Acc: 98.00%\n",
            "Epoch 20/50:\n",
            "  Train Loss: 0.0915, Train Acc: 98.00%\n",
            "  Val Loss: 0.2216, Val Acc: 98.77%\n",
            "  LR: 0.000500\n",
            "  ğŸ’¾ New best model saved! Val Acc: 98.77%\n",
            "Epoch 21, Batch 0/511, Loss: 0.0496, Acc: 96.88%\n",
            "Epoch 21, Batch 50/511, Loss: 0.0769, Acc: 98.18%\n",
            "Epoch 21, Batch 100/511, Loss: 0.0489, Acc: 98.15%\n",
            "Epoch 21, Batch 150/511, Loss: 0.0646, Acc: 98.19%\n",
            "Epoch 21, Batch 200/511, Loss: 0.0213, Acc: 98.16%\n",
            "Epoch 21, Batch 250/511, Loss: 0.0212, Acc: 98.23%\n",
            "Epoch 21, Batch 300/511, Loss: 0.0051, Acc: 98.23%\n",
            "Epoch 21, Batch 350/511, Loss: 1.6397, Acc: 98.27%\n",
            "Epoch 21, Batch 400/511, Loss: 0.0089, Acc: 98.28%\n",
            "Epoch 21, Batch 450/511, Loss: 0.0069, Acc: 98.24%\n",
            "Epoch 21, Batch 500/511, Loss: 0.0895, Acc: 98.16%\n",
            "Epoch 21/50:\n",
            "  Train Loss: 0.0858, Train Acc: 98.15%\n",
            "  Val Loss: 0.1578, Val Acc: 98.29%\n",
            "  LR: 0.000500\n",
            "Epoch 22, Batch 0/511, Loss: 0.0221, Acc: 97.66%\n",
            "Epoch 22, Batch 50/511, Loss: 0.0547, Acc: 98.21%\n",
            "Epoch 22, Batch 100/511, Loss: 0.1047, Acc: 98.17%\n",
            "Epoch 22, Batch 150/511, Loss: 0.0160, Acc: 98.20%\n",
            "Epoch 22, Batch 200/511, Loss: 0.0091, Acc: 98.19%\n",
            "Epoch 22, Batch 250/511, Loss: 0.8768, Acc: 98.16%\n",
            "Epoch 22, Batch 300/511, Loss: 0.0176, Acc: 98.14%\n",
            "Epoch 22, Batch 350/511, Loss: 0.0125, Acc: 98.15%\n",
            "Epoch 22, Batch 400/511, Loss: 0.0123, Acc: 98.13%\n",
            "Epoch 22, Batch 450/511, Loss: 0.0516, Acc: 98.15%\n",
            "Epoch 22, Batch 500/511, Loss: 0.0726, Acc: 98.08%\n",
            "Epoch 22/50:\n",
            "  Train Loss: 0.0767, Train Acc: 98.09%\n",
            "  Val Loss: 0.1491, Val Acc: 98.45%\n",
            "  LR: 0.000250\n",
            "Epoch 23, Batch 0/511, Loss: 0.0121, Acc: 98.44%\n",
            "Epoch 23, Batch 50/511, Loss: 0.0685, Acc: 98.04%\n",
            "Epoch 23, Batch 100/511, Loss: 0.0235, Acc: 98.13%\n",
            "Epoch 23, Batch 150/511, Loss: 0.0074, Acc: 98.19%\n",
            "Epoch 23, Batch 200/511, Loss: 0.0164, Acc: 98.18%\n",
            "Epoch 23, Batch 250/511, Loss: 0.0080, Acc: 98.22%\n",
            "Epoch 23, Batch 300/511, Loss: 0.0671, Acc: 98.26%\n",
            "Epoch 23, Batch 350/511, Loss: 0.6079, Acc: 98.26%\n",
            "Epoch 23, Batch 400/511, Loss: 0.0235, Acc: 98.30%\n",
            "Epoch 23, Batch 450/511, Loss: 0.0170, Acc: 98.35%\n",
            "Epoch 23, Batch 500/511, Loss: 0.6841, Acc: 98.37%\n",
            "Epoch 23/50:\n",
            "  Train Loss: 0.0801, Train Acc: 98.37%\n",
            "  Val Loss: 0.1675, Val Acc: 98.54%\n",
            "  LR: 0.000250\n",
            "Epoch 24, Batch 0/511, Loss: 0.0410, Acc: 96.88%\n",
            "Epoch 24, Batch 50/511, Loss: 0.0055, Acc: 98.56%\n",
            "Epoch 24, Batch 100/511, Loss: 0.0382, Acc: 98.38%\n",
            "Epoch 24, Batch 150/511, Loss: 0.0184, Acc: 98.39%\n",
            "Epoch 24, Batch 200/511, Loss: 0.0013, Acc: 98.46%\n",
            "Epoch 24, Batch 250/511, Loss: 0.1766, Acc: 98.47%\n",
            "Epoch 24, Batch 300/511, Loss: 0.0596, Acc: 98.45%\n",
            "Epoch 24, Batch 350/511, Loss: 0.0456, Acc: 98.48%\n",
            "Epoch 24, Batch 400/511, Loss: 0.0194, Acc: 98.52%\n",
            "Epoch 24, Batch 450/511, Loss: 0.0087, Acc: 98.50%\n",
            "Epoch 24, Batch 500/511, Loss: 0.0456, Acc: 98.51%\n",
            "Epoch 24/50:\n",
            "  Train Loss: 0.0708, Train Acc: 98.52%\n",
            "  Val Loss: 0.1538, Val Acc: 98.35%\n",
            "  LR: 0.000250\n",
            "Epoch 25, Batch 0/511, Loss: 0.0145, Acc: 99.22%\n",
            "Epoch 25, Batch 50/511, Loss: 0.0666, Acc: 98.74%\n",
            "Epoch 25, Batch 100/511, Loss: 0.0121, Acc: 98.70%\n",
            "Epoch 25, Batch 150/511, Loss: 0.0176, Acc: 98.61%\n",
            "Epoch 25, Batch 200/511, Loss: 0.0150, Acc: 98.68%\n",
            "Epoch 25, Batch 250/511, Loss: 0.0298, Acc: 98.66%\n",
            "Epoch 25, Batch 300/511, Loss: 0.0117, Acc: 98.63%\n",
            "Epoch 25, Batch 350/511, Loss: 0.2451, Acc: 98.63%\n",
            "Epoch 25, Batch 400/511, Loss: 0.0081, Acc: 98.64%\n",
            "Epoch 25, Batch 450/511, Loss: 0.0082, Acc: 98.64%\n",
            "Epoch 25, Batch 500/511, Loss: 0.0099, Acc: 98.57%\n",
            "Epoch 25/50:\n",
            "  Train Loss: 0.0715, Train Acc: 98.56%\n",
            "  Val Loss: 0.1816, Val Acc: 98.60%\n",
            "  LR: 0.000250\n",
            "Epoch 26, Batch 0/511, Loss: 0.0204, Acc: 97.66%\n",
            "Epoch 26, Batch 50/511, Loss: 0.3039, Acc: 98.68%\n",
            "Epoch 26, Batch 100/511, Loss: 0.0122, Acc: 98.67%\n",
            "Epoch 26, Batch 150/511, Loss: 0.0307, Acc: 98.61%\n",
            "Epoch 26, Batch 200/511, Loss: 0.0303, Acc: 98.56%\n",
            "Epoch 26, Batch 250/511, Loss: 0.0257, Acc: 98.53%\n",
            "Epoch 26, Batch 300/511, Loss: 0.0123, Acc: 98.52%\n",
            "Epoch 26, Batch 350/511, Loss: 0.0261, Acc: 98.52%\n",
            "Epoch 26, Batch 400/511, Loss: 0.0418, Acc: 98.51%\n",
            "Epoch 26, Batch 450/511, Loss: 0.0026, Acc: 98.53%\n",
            "Epoch 26, Batch 500/511, Loss: 0.0343, Acc: 98.51%\n",
            "Epoch 26/50:\n",
            "  Train Loss: 0.0541, Train Acc: 98.52%\n",
            "  Val Loss: 0.2013, Val Acc: 98.60%\n",
            "  LR: 0.000250\n",
            "Epoch 27, Batch 0/511, Loss: 0.0403, Acc: 95.31%\n",
            "Epoch 27, Batch 50/511, Loss: 0.0050, Acc: 99.11%\n",
            "Epoch 27, Batch 100/511, Loss: 0.0588, Acc: 98.88%\n",
            "Epoch 27, Batch 150/511, Loss: 0.0222, Acc: 98.72%\n",
            "Epoch 27, Batch 200/511, Loss: 0.0158, Acc: 98.59%\n",
            "Epoch 27, Batch 250/511, Loss: 0.0052, Acc: 98.53%\n",
            "Epoch 27, Batch 300/511, Loss: 0.0747, Acc: 98.57%\n",
            "Epoch 27, Batch 350/511, Loss: 0.0166, Acc: 98.52%\n",
            "Epoch 27, Batch 400/511, Loss: 0.2781, Acc: 98.53%\n",
            "Epoch 27, Batch 450/511, Loss: 0.7114, Acc: 98.53%\n",
            "Epoch 27, Batch 500/511, Loss: 0.0148, Acc: 98.51%\n",
            "Epoch 27/50:\n",
            "  Train Loss: 0.0690, Train Acc: 98.51%\n",
            "  Val Loss: 0.1541, Val Acc: 97.85%\n",
            "  LR: 0.000250\n",
            "Epoch 28, Batch 0/511, Loss: 0.2132, Acc: 96.09%\n",
            "Epoch 28, Batch 50/511, Loss: 0.0250, Acc: 98.61%\n",
            "Epoch 28, Batch 100/511, Loss: 0.0147, Acc: 98.55%\n",
            "Epoch 28, Batch 150/511, Loss: 0.0033, Acc: 98.68%\n",
            "Epoch 28, Batch 200/511, Loss: 0.0158, Acc: 98.63%\n",
            "Epoch 28, Batch 250/511, Loss: 0.6020, Acc: 98.55%\n",
            "Epoch 28, Batch 300/511, Loss: 0.0286, Acc: 98.50%\n",
            "Epoch 28, Batch 350/511, Loss: 0.0159, Acc: 98.51%\n",
            "Epoch 28, Batch 400/511, Loss: 0.0144, Acc: 98.58%\n",
            "Epoch 28, Batch 450/511, Loss: 0.0765, Acc: 98.58%\n",
            "Epoch 28, Batch 500/511, Loss: 0.0532, Acc: 98.61%\n",
            "Epoch 28/50:\n",
            "  Train Loss: 0.0605, Train Acc: 98.61%\n",
            "  Val Loss: 0.2447, Val Acc: 98.89%\n",
            "  LR: 0.000125\n",
            "  ğŸ’¾ New best model saved! Val Acc: 98.89%\n",
            "Epoch 29, Batch 0/511, Loss: 0.0439, Acc: 97.66%\n",
            "Epoch 29, Batch 50/511, Loss: 0.0033, Acc: 98.88%\n",
            "Epoch 29, Batch 100/511, Loss: 0.2708, Acc: 98.76%\n",
            "Epoch 29, Batch 150/511, Loss: 0.0220, Acc: 98.88%\n",
            "Epoch 29, Batch 200/511, Loss: 2.1950, Acc: 98.81%\n",
            "Epoch 29, Batch 250/511, Loss: 0.0056, Acc: 98.74%\n",
            "Epoch 29, Batch 300/511, Loss: 0.0135, Acc: 98.70%\n",
            "Epoch 29, Batch 350/511, Loss: 0.0247, Acc: 98.68%\n",
            "Epoch 29, Batch 400/511, Loss: 0.0133, Acc: 98.70%\n",
            "Epoch 29, Batch 450/511, Loss: 0.0041, Acc: 98.71%\n",
            "Epoch 29, Batch 500/511, Loss: 0.0939, Acc: 98.70%\n",
            "Epoch 29/50:\n",
            "  Train Loss: 0.0622, Train Acc: 98.70%\n",
            "  Val Loss: 0.1879, Val Acc: 98.53%\n",
            "  LR: 0.000125\n",
            "Epoch 30, Batch 0/511, Loss: 0.0050, Acc: 99.22%\n",
            "Epoch 30, Batch 50/511, Loss: 0.1313, Acc: 98.47%\n",
            "Epoch 30, Batch 100/511, Loss: 1.6382, Acc: 98.48%\n",
            "Epoch 30, Batch 150/511, Loss: 0.0154, Acc: 98.44%\n",
            "Epoch 30, Batch 200/511, Loss: 0.0108, Acc: 98.49%\n",
            "Epoch 30, Batch 250/511, Loss: 0.0621, Acc: 98.57%\n",
            "Epoch 30, Batch 300/511, Loss: 0.0262, Acc: 98.56%\n",
            "Epoch 30, Batch 350/511, Loss: 0.0110, Acc: 98.56%\n",
            "Epoch 30, Batch 400/511, Loss: 0.0353, Acc: 98.61%\n",
            "Epoch 30, Batch 450/511, Loss: 0.0073, Acc: 98.62%\n",
            "Epoch 30, Batch 500/511, Loss: 0.0361, Acc: 98.64%\n",
            "Epoch 30/50:\n",
            "  Train Loss: 0.0698, Train Acc: 98.64%\n",
            "  Val Loss: 0.1827, Val Acc: 98.71%\n",
            "  LR: 0.000125\n",
            "Epoch 31, Batch 0/511, Loss: 0.0086, Acc: 98.44%\n",
            "Epoch 31, Batch 50/511, Loss: 0.0030, Acc: 98.94%\n",
            "Epoch 31, Batch 100/511, Loss: 0.0140, Acc: 98.83%\n",
            "Epoch 31, Batch 150/511, Loss: 0.0121, Acc: 98.81%\n",
            "Epoch 31, Batch 200/511, Loss: 0.0025, Acc: 98.76%\n",
            "Epoch 31, Batch 250/511, Loss: 0.0110, Acc: 98.75%\n",
            "Epoch 31, Batch 300/511, Loss: 0.0040, Acc: 98.75%\n",
            "Epoch 31, Batch 350/511, Loss: 0.0098, Acc: 98.73%\n",
            "Epoch 31, Batch 400/511, Loss: 0.0031, Acc: 98.74%\n",
            "Epoch 31, Batch 450/511, Loss: 0.0084, Acc: 98.70%\n",
            "Epoch 31, Batch 500/511, Loss: 0.0037, Acc: 98.72%\n",
            "Epoch 31/50:\n",
            "  Train Loss: 0.0488, Train Acc: 98.72%\n",
            "  Val Loss: 0.2549, Val Acc: 98.68%\n",
            "  LR: 0.000125\n",
            "Epoch 32, Batch 0/511, Loss: 0.5600, Acc: 99.22%\n",
            "Epoch 32, Batch 50/511, Loss: 0.0288, Acc: 98.68%\n",
            "Epoch 32, Batch 100/511, Loss: 0.0256, Acc: 98.77%\n",
            "Epoch 32, Batch 150/511, Loss: 0.0143, Acc: 98.65%\n",
            "Epoch 32, Batch 200/511, Loss: 0.0031, Acc: 98.66%\n",
            "Epoch 32, Batch 250/511, Loss: 0.4379, Acc: 98.61%\n",
            "Epoch 32, Batch 300/511, Loss: 0.0059, Acc: 98.63%\n",
            "Epoch 32, Batch 350/511, Loss: 0.0297, Acc: 98.65%\n",
            "Epoch 32, Batch 400/511, Loss: 0.0063, Acc: 98.65%\n",
            "Epoch 32, Batch 450/511, Loss: 0.0074, Acc: 98.67%\n",
            "Epoch 32, Batch 500/511, Loss: 0.0094, Acc: 98.67%\n",
            "Epoch 32/50:\n",
            "  Train Loss: 0.0665, Train Acc: 98.67%\n",
            "  Val Loss: 0.2010, Val Acc: 98.73%\n",
            "  LR: 0.000125\n",
            "Epoch 33, Batch 0/511, Loss: 0.0185, Acc: 98.44%\n",
            "Epoch 33, Batch 50/511, Loss: 0.0551, Acc: 98.79%\n",
            "Epoch 33, Batch 100/511, Loss: 0.0314, Acc: 98.73%\n",
            "Epoch 33, Batch 150/511, Loss: 0.0072, Acc: 98.72%\n",
            "Epoch 33, Batch 200/511, Loss: 0.0215, Acc: 98.61%\n",
            "Epoch 33, Batch 250/511, Loss: 0.0054, Acc: 98.67%\n",
            "Epoch 33, Batch 300/511, Loss: 0.0191, Acc: 98.70%\n",
            "Epoch 33, Batch 350/511, Loss: 0.0008, Acc: 98.71%\n",
            "Epoch 33, Batch 400/511, Loss: 0.0318, Acc: 98.72%\n",
            "Epoch 33, Batch 450/511, Loss: 0.0102, Acc: 98.71%\n",
            "Epoch 33, Batch 500/511, Loss: 0.0197, Acc: 98.70%\n",
            "Epoch 33/50:\n",
            "  Train Loss: 0.0564, Train Acc: 98.71%\n",
            "  Val Loss: 0.2021, Val Acc: 98.73%\n",
            "  LR: 0.000125\n",
            "Epoch 34, Batch 0/511, Loss: 0.3971, Acc: 96.88%\n",
            "Epoch 34, Batch 50/511, Loss: 0.0078, Acc: 98.64%\n",
            "Epoch 34, Batch 100/511, Loss: 0.0375, Acc: 98.71%\n",
            "Epoch 34, Batch 150/511, Loss: 0.0045, Acc: 98.75%\n",
            "Epoch 34, Batch 200/511, Loss: 0.0366, Acc: 98.78%\n",
            "Epoch 34, Batch 250/511, Loss: 0.0054, Acc: 98.75%\n",
            "Epoch 34, Batch 300/511, Loss: 0.0954, Acc: 98.78%\n",
            "Epoch 34, Batch 350/511, Loss: 0.0757, Acc: 98.73%\n",
            "Epoch 34, Batch 400/511, Loss: 0.0046, Acc: 98.76%\n",
            "Epoch 34, Batch 450/511, Loss: 0.0028, Acc: 98.75%\n",
            "Epoch 34, Batch 500/511, Loss: 0.0145, Acc: 98.75%\n",
            "Epoch 34/50:\n",
            "  Train Loss: 0.0518, Train Acc: 98.75%\n",
            "  Val Loss: 0.1967, Val Acc: 98.58%\n",
            "  LR: 0.000063\n",
            "Epoch 35, Batch 0/511, Loss: 0.0083, Acc: 99.22%\n",
            "Epoch 35, Batch 50/511, Loss: 0.0067, Acc: 98.91%\n",
            "Epoch 35, Batch 100/511, Loss: 0.0033, Acc: 98.88%\n",
            "Epoch 35, Batch 150/511, Loss: 0.0121, Acc: 98.90%\n",
            "Epoch 35, Batch 200/511, Loss: 0.1376, Acc: 98.87%\n",
            "Epoch 35, Batch 250/511, Loss: 0.0194, Acc: 98.79%\n",
            "Epoch 35, Batch 300/511, Loss: 0.0144, Acc: 98.79%\n",
            "Epoch 35, Batch 350/511, Loss: 0.0068, Acc: 98.80%\n",
            "Epoch 35, Batch 400/511, Loss: 0.0012, Acc: 98.79%\n",
            "Epoch 35, Batch 450/511, Loss: 0.1083, Acc: 98.80%\n",
            "Epoch 35, Batch 500/511, Loss: 0.0202, Acc: 98.79%\n",
            "Epoch 35/50:\n",
            "  Train Loss: 0.0512, Train Acc: 98.79%\n",
            "  Val Loss: 0.2079, Val Acc: 98.75%\n",
            "  LR: 0.000063\n",
            "Epoch 36, Batch 0/511, Loss: 0.0252, Acc: 100.00%\n",
            "Epoch 36, Batch 50/511, Loss: 0.0186, Acc: 98.81%\n",
            "Epoch 36, Batch 100/511, Loss: 0.0259, Acc: 98.86%\n",
            "Epoch 36, Batch 150/511, Loss: 0.1250, Acc: 98.82%\n",
            "Epoch 36, Batch 200/511, Loss: 0.5499, Acc: 98.85%\n",
            "Epoch 36, Batch 250/511, Loss: 0.0083, Acc: 98.88%\n",
            "Epoch 36, Batch 300/511, Loss: 0.0065, Acc: 98.88%\n",
            "Epoch 36, Batch 350/511, Loss: 0.0099, Acc: 98.87%\n",
            "Epoch 36, Batch 400/511, Loss: 0.0185, Acc: 98.85%\n",
            "Epoch 36, Batch 450/511, Loss: 0.0156, Acc: 98.86%\n",
            "Epoch 36, Batch 500/511, Loss: 0.0104, Acc: 98.84%\n",
            "Epoch 36/50:\n",
            "  Train Loss: 0.0476, Train Acc: 98.84%\n",
            "  Val Loss: 0.2137, Val Acc: 98.72%\n",
            "  LR: 0.000063\n",
            "Epoch 37, Batch 0/511, Loss: 0.0069, Acc: 99.22%\n",
            "Epoch 37, Batch 50/511, Loss: 0.0481, Acc: 98.74%\n",
            "Epoch 37, Batch 100/511, Loss: 0.0494, Acc: 98.84%\n",
            "Epoch 37, Batch 150/511, Loss: 0.0353, Acc: 98.86%\n",
            "Epoch 37, Batch 200/511, Loss: 0.0014, Acc: 98.86%\n",
            "Epoch 37, Batch 250/511, Loss: 0.0075, Acc: 98.87%\n",
            "Epoch 37, Batch 300/511, Loss: 0.0177, Acc: 98.87%\n",
            "Epoch 37, Batch 350/511, Loss: 0.0761, Acc: 98.84%\n",
            "Epoch 37, Batch 400/511, Loss: 0.0042, Acc: 98.84%\n",
            "Epoch 37, Batch 450/511, Loss: 0.0040, Acc: 98.86%\n",
            "Epoch 37, Batch 500/511, Loss: 0.0013, Acc: 98.86%\n",
            "Epoch 37/50:\n",
            "  Train Loss: 0.0396, Train Acc: 98.86%\n",
            "  Val Loss: 0.2206, Val Acc: 98.90%\n",
            "  LR: 0.000063\n",
            "  ğŸ’¾ New best model saved! Val Acc: 98.90%\n",
            "Epoch 38, Batch 0/511, Loss: 0.0075, Acc: 100.00%\n",
            "Epoch 38, Batch 50/511, Loss: 0.0013, Acc: 99.00%\n",
            "Epoch 38, Batch 100/511, Loss: 0.0396, Acc: 98.96%\n",
            "Epoch 38, Batch 150/511, Loss: 0.0055, Acc: 98.94%\n",
            "Epoch 38, Batch 200/511, Loss: 0.0096, Acc: 98.94%\n",
            "Epoch 38, Batch 250/511, Loss: 0.0099, Acc: 98.93%\n",
            "Epoch 38, Batch 300/511, Loss: 0.0019, Acc: 98.91%\n",
            "Epoch 38, Batch 350/511, Loss: 0.0196, Acc: 98.88%\n",
            "Epoch 38, Batch 400/511, Loss: 0.1097, Acc: 98.86%\n",
            "Epoch 38, Batch 450/511, Loss: 0.0054, Acc: 98.85%\n",
            "Epoch 38, Batch 500/511, Loss: 0.0194, Acc: 98.87%\n",
            "Epoch 38/50:\n",
            "  Train Loss: 0.0559, Train Acc: 98.88%\n",
            "  Val Loss: 0.2317, Val Acc: 98.81%\n",
            "  LR: 0.000063\n",
            "Epoch 39, Batch 0/511, Loss: 0.0096, Acc: 99.22%\n",
            "Epoch 39, Batch 50/511, Loss: 0.0090, Acc: 98.97%\n",
            "Epoch 39, Batch 100/511, Loss: 0.0078, Acc: 98.94%\n",
            "Epoch 39, Batch 150/511, Loss: 0.2882, Acc: 98.90%\n",
            "Epoch 39, Batch 200/511, Loss: 0.0054, Acc: 98.89%\n",
            "Epoch 39, Batch 250/511, Loss: 0.0172, Acc: 98.90%\n",
            "Epoch 39, Batch 300/511, Loss: 0.0006, Acc: 98.90%\n",
            "Epoch 39, Batch 350/511, Loss: 0.0116, Acc: 98.90%\n",
            "Epoch 39, Batch 400/511, Loss: 0.0053, Acc: 98.90%\n",
            "Epoch 39, Batch 450/511, Loss: 0.0131, Acc: 98.90%\n",
            "Epoch 39, Batch 500/511, Loss: 0.0013, Acc: 98.92%\n",
            "Epoch 39/50:\n",
            "  Train Loss: 0.0464, Train Acc: 98.91%\n",
            "  Val Loss: 0.2598, Val Acc: 98.90%\n",
            "  LR: 0.000063\n",
            "  ğŸ’¾ New best model saved! Val Acc: 98.90%\n",
            "Epoch 40, Batch 0/511, Loss: 0.0567, Acc: 96.09%\n",
            "Epoch 40, Batch 50/511, Loss: 0.0025, Acc: 98.87%\n",
            "Epoch 40, Batch 100/511, Loss: 0.0082, Acc: 98.96%\n",
            "Epoch 40, Batch 150/511, Loss: 0.0230, Acc: 99.04%\n",
            "Epoch 40, Batch 200/511, Loss: 0.0272, Acc: 98.98%\n",
            "Epoch 40, Batch 250/511, Loss: 0.1074, Acc: 98.97%\n",
            "Epoch 40, Batch 300/511, Loss: 0.0085, Acc: 98.96%\n",
            "Epoch 40, Batch 350/511, Loss: 0.0614, Acc: 98.96%\n",
            "Epoch 40, Batch 400/511, Loss: 0.0099, Acc: 98.92%\n",
            "Epoch 40, Batch 450/511, Loss: 0.5860, Acc: 98.91%\n",
            "Epoch 40, Batch 500/511, Loss: 0.0121, Acc: 98.90%\n",
            "Epoch 40/50:\n",
            "  Train Loss: 0.0452, Train Acc: 98.90%\n",
            "  Val Loss: 0.2182, Val Acc: 98.83%\n",
            "  LR: 0.000031\n",
            "Epoch 41, Batch 0/511, Loss: 0.0029, Acc: 100.00%\n",
            "Epoch 41, Batch 50/511, Loss: 0.4912, Acc: 99.08%\n",
            "Epoch 41, Batch 100/511, Loss: 0.0038, Acc: 99.07%\n",
            "Epoch 41, Batch 150/511, Loss: 0.0169, Acc: 98.99%\n",
            "Epoch 41, Batch 200/511, Loss: 0.0425, Acc: 99.01%\n",
            "Epoch 41, Batch 250/511, Loss: 0.0036, Acc: 99.00%\n",
            "Epoch 41, Batch 300/511, Loss: 0.0088, Acc: 98.97%\n",
            "Epoch 41, Batch 350/511, Loss: 0.0039, Acc: 98.96%\n",
            "Epoch 41, Batch 400/511, Loss: 0.0081, Acc: 98.92%\n",
            "Epoch 41, Batch 450/511, Loss: 0.0052, Acc: 98.93%\n",
            "Epoch 41, Batch 500/511, Loss: 0.0334, Acc: 98.93%\n",
            "Epoch 41/50:\n",
            "  Train Loss: 0.0535, Train Acc: 98.94%\n",
            "  Val Loss: 0.2337, Val Acc: 98.83%\n",
            "  LR: 0.000031\n",
            "Epoch 42, Batch 0/511, Loss: 0.0129, Acc: 98.44%\n",
            "Epoch 42, Batch 50/511, Loss: 0.0119, Acc: 98.94%\n",
            "Epoch 42, Batch 100/511, Loss: 0.0001, Acc: 98.97%\n",
            "Epoch 42, Batch 150/511, Loss: 0.0025, Acc: 99.01%\n",
            "Epoch 42, Batch 200/511, Loss: 0.0041, Acc: 98.99%\n",
            "Epoch 42, Batch 250/511, Loss: 0.0140, Acc: 99.01%\n",
            "Epoch 42, Batch 300/511, Loss: 0.0163, Acc: 99.02%\n",
            "Epoch 42, Batch 350/511, Loss: 0.0371, Acc: 99.02%\n",
            "Epoch 42, Batch 400/511, Loss: 0.2800, Acc: 99.01%\n",
            "Epoch 42, Batch 450/511, Loss: 0.0502, Acc: 99.00%\n",
            "Epoch 42, Batch 500/511, Loss: 0.0171, Acc: 99.01%\n",
            "Epoch 42/50:\n",
            "  Train Loss: 0.0396, Train Acc: 99.01%\n",
            "  Val Loss: 0.2415, Val Acc: 98.88%\n",
            "  LR: 0.000031\n",
            "Epoch 43, Batch 0/511, Loss: 0.0082, Acc: 98.44%\n",
            "Epoch 43, Batch 50/511, Loss: 0.4485, Acc: 98.87%\n",
            "Epoch 43, Batch 100/511, Loss: 0.0049, Acc: 98.85%\n",
            "Epoch 43, Batch 150/511, Loss: 0.0205, Acc: 98.83%\n",
            "Epoch 43, Batch 200/511, Loss: 0.0043, Acc: 98.83%\n",
            "Epoch 43, Batch 250/511, Loss: 0.0173, Acc: 98.85%\n",
            "Epoch 43, Batch 300/511, Loss: 0.1429, Acc: 98.86%\n",
            "Epoch 43, Batch 350/511, Loss: 0.0497, Acc: 98.87%\n",
            "Epoch 43, Batch 400/511, Loss: 0.0018, Acc: 98.88%\n",
            "Epoch 43, Batch 450/511, Loss: 0.0141, Acc: 98.91%\n",
            "Epoch 43, Batch 500/511, Loss: 0.0266, Acc: 98.93%\n",
            "Epoch 43/50:\n",
            "  Train Loss: 0.0566, Train Acc: 98.94%\n",
            "  Val Loss: 0.2312, Val Acc: 98.88%\n",
            "  LR: 0.000031\n",
            "Epoch 44, Batch 0/511, Loss: 0.0082, Acc: 99.22%\n",
            "Epoch 44, Batch 50/511, Loss: 0.0090, Acc: 98.96%\n",
            "Epoch 44, Batch 100/511, Loss: 0.0137, Acc: 98.99%\n",
            "Epoch 44, Batch 150/511, Loss: 0.0536, Acc: 99.05%\n",
            "Epoch 44, Batch 200/511, Loss: 0.0422, Acc: 99.01%\n",
            "Epoch 44, Batch 250/511, Loss: 0.0011, Acc: 99.04%\n",
            "Epoch 44, Batch 300/511, Loss: 0.0019, Acc: 99.03%\n",
            "Epoch 44, Batch 350/511, Loss: 0.1815, Acc: 99.02%\n",
            "Epoch 44, Batch 400/511, Loss: 0.0211, Acc: 99.01%\n",
            "Epoch 44, Batch 450/511, Loss: 0.0156, Acc: 99.01%\n",
            "Epoch 44, Batch 500/511, Loss: 0.0093, Acc: 99.02%\n",
            "Epoch 44/50:\n",
            "  Train Loss: 0.0438, Train Acc: 99.00%\n",
            "  Val Loss: 0.2143, Val Acc: 98.81%\n",
            "  LR: 0.000031\n",
            "Epoch 45, Batch 0/511, Loss: 0.0021, Acc: 100.00%\n",
            "Epoch 45, Batch 50/511, Loss: 0.0059, Acc: 98.96%\n",
            "Epoch 45, Batch 100/511, Loss: 0.0041, Acc: 98.92%\n",
            "Epoch 45, Batch 150/511, Loss: 0.0777, Acc: 98.92%\n",
            "Epoch 45, Batch 200/511, Loss: 0.0096, Acc: 98.95%\n",
            "Epoch 45, Batch 250/511, Loss: 0.1060, Acc: 98.95%\n",
            "Epoch 45, Batch 300/511, Loss: 0.0226, Acc: 98.98%\n",
            "Epoch 45, Batch 350/511, Loss: 0.0618, Acc: 98.98%\n",
            "Epoch 45, Batch 400/511, Loss: 0.0054, Acc: 98.96%\n",
            "Epoch 45, Batch 450/511, Loss: 0.0716, Acc: 98.95%\n",
            "Epoch 45, Batch 500/511, Loss: 0.0145, Acc: 98.96%\n",
            "Epoch 45/50:\n",
            "  Train Loss: 0.0363, Train Acc: 98.96%\n",
            "  Val Loss: 0.2360, Val Acc: 98.85%\n",
            "  LR: 0.000031\n",
            "Epoch 46, Batch 0/511, Loss: 0.0044, Acc: 98.44%\n",
            "Epoch 46, Batch 50/511, Loss: 0.0042, Acc: 98.87%\n",
            "Epoch 46, Batch 100/511, Loss: 0.0026, Acc: 98.96%\n",
            "Epoch 46, Batch 150/511, Loss: 0.0143, Acc: 99.03%\n",
            "Epoch 46, Batch 200/511, Loss: 0.9896, Acc: 99.03%\n",
            "Epoch 46, Batch 250/511, Loss: 0.0050, Acc: 99.03%\n",
            "Epoch 46, Batch 300/511, Loss: 0.0276, Acc: 99.00%\n",
            "Epoch 46, Batch 350/511, Loss: 0.0035, Acc: 98.99%\n",
            "Epoch 46, Batch 400/511, Loss: 0.0095, Acc: 98.99%\n",
            "Epoch 46, Batch 450/511, Loss: 0.0082, Acc: 98.98%\n",
            "Epoch 46, Batch 500/511, Loss: 0.0076, Acc: 98.98%\n",
            "Epoch 46/50:\n",
            "  Train Loss: 0.0455, Train Acc: 98.97%\n",
            "  Val Loss: 0.2434, Val Acc: 98.85%\n",
            "  LR: 0.000016\n",
            "Epoch 47, Batch 0/511, Loss: 0.1421, Acc: 99.22%\n",
            "Epoch 47, Batch 50/511, Loss: 0.0095, Acc: 99.05%\n",
            "Epoch 47, Batch 100/511, Loss: 0.0523, Acc: 99.03%\n",
            "Epoch 47, Batch 150/511, Loss: 0.0139, Acc: 99.03%\n",
            "Epoch 47, Batch 200/511, Loss: 0.0023, Acc: 99.03%\n",
            "Epoch 47, Batch 250/511, Loss: 0.0078, Acc: 99.01%\n",
            "Epoch 47, Batch 300/511, Loss: 0.0430, Acc: 99.00%\n",
            "Epoch 47, Batch 350/511, Loss: 0.0277, Acc: 98.97%\n",
            "Epoch 47, Batch 400/511, Loss: 0.0023, Acc: 98.95%\n",
            "Epoch 47, Batch 450/511, Loss: 0.0011, Acc: 98.96%\n",
            "Epoch 47, Batch 500/511, Loss: 0.0215, Acc: 98.97%\n",
            "Epoch 47/50:\n",
            "  Train Loss: 0.0415, Train Acc: 98.96%\n",
            "  Val Loss: 0.2347, Val Acc: 98.87%\n",
            "  LR: 0.000016\n",
            "Epoch 48, Batch 0/511, Loss: 0.0704, Acc: 98.44%\n",
            "Epoch 48, Batch 50/511, Loss: 0.0132, Acc: 98.77%\n",
            "Epoch 48, Batch 100/511, Loss: 0.0119, Acc: 98.93%\n",
            "Epoch 48, Batch 150/511, Loss: 0.0110, Acc: 98.96%\n",
            "Epoch 48, Batch 200/511, Loss: 0.0015, Acc: 98.98%\n",
            "Epoch 48, Batch 250/511, Loss: 0.0149, Acc: 98.98%\n",
            "Epoch 48, Batch 300/511, Loss: 0.0055, Acc: 98.97%\n",
            "Epoch 48, Batch 350/511, Loss: 0.0350, Acc: 98.96%\n",
            "Epoch 48, Batch 400/511, Loss: 0.0198, Acc: 98.95%\n",
            "Epoch 48, Batch 450/511, Loss: 0.0204, Acc: 98.96%\n",
            "Epoch 48, Batch 500/511, Loss: 0.0150, Acc: 98.98%\n",
            "Epoch 48/50:\n",
            "  Train Loss: 0.0336, Train Acc: 98.98%\n",
            "  Val Loss: 0.2341, Val Acc: 98.84%\n",
            "  LR: 0.000016\n",
            "Epoch 49, Batch 0/511, Loss: 0.0187, Acc: 97.66%\n",
            "Epoch 49, Batch 50/511, Loss: 0.0298, Acc: 98.68%\n",
            "Epoch 49, Batch 100/511, Loss: 0.0052, Acc: 98.86%\n",
            "Epoch 49, Batch 150/511, Loss: 0.0042, Acc: 98.91%\n",
            "Epoch 49, Batch 200/511, Loss: 0.0190, Acc: 98.95%\n",
            "Epoch 49, Batch 250/511, Loss: 0.0863, Acc: 98.98%\n",
            "Epoch 49, Batch 300/511, Loss: 0.0029, Acc: 98.97%\n",
            "Epoch 49, Batch 350/511, Loss: 0.0086, Acc: 98.96%\n",
            "Epoch 49, Batch 400/511, Loss: 0.0100, Acc: 98.93%\n",
            "Epoch 49, Batch 450/511, Loss: 0.0087, Acc: 98.93%\n",
            "Epoch 49, Batch 500/511, Loss: 0.0122, Acc: 98.92%\n",
            "Epoch 49/50:\n",
            "  Train Loss: 0.0405, Train Acc: 98.93%\n",
            "  Val Loss: 0.2403, Val Acc: 98.85%\n",
            "  LR: 0.000016\n",
            "Early stopping triggered after 49 epochs\n",
            "\n",
            "Training completed! Best validation accuracy: 98.90%\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Parent directory /content/drive/MyDrive/ColabData/ECG does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3092722069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0mfinal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ColabData/ECG/ecg_mitbih_finetuned_improved.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final model saved to: {final_model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             _save(\n\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             super().__init__(\n\u001b[0;32m--> 792\u001b[0;31m                 torch._C.PyTorchFileWriter(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_crc32_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_storage_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/ColabData/ECG does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE6Kec2wBfH8",
        "outputId": "4a205e53-9611-4170-c22c-d64bfc2160ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test set...\n",
            "\n",
            "==================================================\n",
            "COMPREHENSIVE EVALUATION RESULTS\n",
            "==================================================\n",
            "\n",
            "Overall Accuracy: 0.9887\n",
            "Weighted Precision: 0.9891\n",
            "Weighted Recall: 0.9887\n",
            "Weighted F1-Score: 0.9888\n",
            "\n",
            "Macro-averaged Metrics:\n",
            "Macro Precision: 0.9205\n",
            "Macro Recall: 0.9590\n",
            "Macro F1-Score: 0.9384\n",
            "\n",
            "Detailed Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "          Normal     0.9965    0.9921    0.9943     17972\n",
            "Supraventricular     0.8815    0.9203    0.9005       590\n",
            "     Ventricular     0.9730    0.9786    0.9758      1401\n",
            "          Fusion     0.7684    0.9125    0.8343       160\n",
            "         Unknown     0.9830    0.9917    0.9873      1691\n",
            "\n",
            "        accuracy                         0.9887     21814\n",
            "       macro avg     0.9205    0.9590    0.9384     21814\n",
            "    weighted avg     0.9891    0.9887    0.9888     21814\n",
            "\n",
            "\n",
            "Multiclass ROC-AUC Score: 0.9968\n",
            "\n",
            "Per-class AUC scores:\n",
            "  Normal: 0.9985\n",
            "  Supraventricular: 0.9933\n",
            "  Ventricular: 0.9996\n",
            "  Fusion: 0.9933\n",
            "  Unknown: 0.9993\n",
            "\n",
            "Per-class Performance:\n",
            "  Normal          - Precision: 0.9965, Recall: 0.9921, F1: 0.9943, Support: 17972\n",
            "  Supraventricular - Precision: 0.8815, Recall: 0.9203, F1: 0.9005, Support: 590\n",
            "  Ventricular     - Precision: 0.9730, Recall: 0.9786, F1: 0.9758, Support: 1401\n",
            "  Fusion          - Precision: 0.7684, Recall: 0.9125, F1: 0.8343, Support: 160\n",
            "  Unknown         - Precision: 0.9830, Recall: 0.9917, F1: 0.9873, Support: 1691\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Î¦Î¬ÏƒÎ· Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ (Test Set) ---\n",
        "model.eval() # Î˜Î­Ï„Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÏƒÎµ ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚\n",
        "all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "print(\"Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÏ„Î¿ ÏƒÏÎ½Î¿Î»Î¿ ÎµÎ»Î­Î³Ï‡Î¿Ï… (test set)...\")\n",
        "with torch.no_grad(): # Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï ÎºÎ»Î¯ÏƒÎµÏ‰Î½ (gradients)\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÎµÎ¾ÏŒÎ´Î¿Ï… ÏƒÎµ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚ (Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· logits vs log_softmax)\n",
        "        if hasattr(model, 'forward') and 'log_softmax' in str(model.forward):\n",
        "            probs = torch.exp(outputs) # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® log-Ï€Î¹Î¸Î±Î½Î¿Ï„Î®Ï„Ï‰Î½ ÏƒÎµ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚\n",
        "        else:\n",
        "            probs = F.softmax(outputs, dim=1) # Î•Ï†Î±ÏÎ¼Î¿Î³Î® Softmax\n",
        "\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "        # Î£Ï…Î»Î»Î¿Î³Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y_batch.numpy())\n",
        "\n",
        "# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î»Î¹ÏƒÏ„ÏÎ½ ÏƒÎµ numpy arrays Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· Î¼Îµ sklearn\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "# ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½ ÎºÎ»Î¬ÏƒÎµÏ‰Î½ Î³Î¹Î± Ï„Î¹Ï‚ Î±Î½Î±Ï†Î¿ÏÎ­Ï‚\n",
        "class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "\n",
        "# --- 2. Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Î£Î¥ÎÎŸÎ›Î™ÎšÎ‘ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘ Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î—Î£\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚ (Overall & Weighted)\n",
        "print(f\"\\nÎ£Ï…Î½Î¿Î»Î¹ÎºÎ® Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± (Overall Accuracy): {accuracy_score(all_labels, all_preds):.4f}\")\n",
        "print(f\"Î£Ï„Î±Î¸Î¼Î¹ÏƒÎ¼Î­Î½Î· Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± (Weighted Precision): {precision_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
        "print(f\"Î£Ï„Î±Î¸Î¼Î¹ÏƒÎ¼Î­Î½Î· Î‘Î½Î¬ÎºÎ»Î·ÏƒÎ· (Weighted Recall): {recall_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
        "print(f\"Î£Ï„Î±Î¸Î¼Î¹ÏƒÎ¼Î­Î½Î¿ F1-Score (Weighted F1-Score): {f1_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
        "\n",
        "# ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Macro-Average (ÎºÎ±Ï„Î¬Î»Î»Î·Î»ÎµÏ‚ Î³Î¹Î± Î±Î½Î¹ÏƒÏŒÏÏÎ¿Ï€Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±)\n",
        "print(f\"\\nÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Macro-averaged:\")\n",
        "print(f\"Macro Precision: {precision_score(all_labels, all_preds, average='macro'):.4f}\")\n",
        "print(f\"Macro Recall: {recall_score(all_labels, all_preds, average='macro'):.4f}\")\n",
        "print(f\"Macro F1-Score: {f1_score(all_labels, all_preds, average='macro'):.4f}\")\n",
        "\n",
        "# Î Î»Î®ÏÎ·Ï‚ Î‘Î½Î±Ï†Î¿ÏÎ¬ Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ (Classification Report)\n",
        "print(f\"\\nÎ‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ® Î‘Î½Î±Ï†Î¿ÏÎ¬ Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ (Classification Report):\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
        "\n",
        "# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ROC-AUC (One-vs-Rest Î³Î¹Î± multi-class)\n",
        "try:\n",
        "    present_classes = np.unique(all_labels)\n",
        "    if len(present_classes) == 5:\n",
        "        # Binarization Ï„Ï‰Î½ ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ Î³Î¹Î± 'ovr'\n",
        "        y_true_bin = np.eye(5)[all_labels]\n",
        "        auc_score = roc_auc_score(y_true_bin, all_probs, multi_class='ovr')\n",
        "        print(f\"\\nMulticlass ROC-AUC Score (OvR): {auc_score:.4f}\")\n",
        "\n",
        "        print(f\"\\nAUC scores Î±Î½Î¬ ÎºÎ»Î¬ÏƒÎ·:\")\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            if i in present_classes:\n",
        "                fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "                class_auc = auc(fpr, tpr)\n",
        "                print(f\"  {class_name}: {class_auc:.4f}\")\n",
        "    else:\n",
        "        print(f\"Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·: ÎœÏŒÎ½Î¿ {len(present_classes)} ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚ Ï€Î±ÏÎ¿ÏÏƒÎµÏ‚ ÏƒÏ„Î¿ test set, Ï€Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· ROC-AUC\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Î£Ï†Î¬Î»Î¼Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï ROC-AUC: {e}\")\n",
        "\n",
        "# Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î±Î½Î¬ ÎºÎ»Î¬ÏƒÎ· (Precision, Recall, F1)\n",
        "print(f\"\\nÎ‘Ï€ÏŒÎ´Î¿ÏƒÎ· Î±Î½Î¬ ÎšÎ»Î¬ÏƒÎ·:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    if i in present_classes:\n",
        "        class_precision = precision_score(all_labels, all_preds, labels=[i], average=None)\n",
        "        class_recall = recall_score(all_labels, all_preds, labels=[i], average=None)\n",
        "        class_f1 = f1_score(all_labels, all_preds, labels=[i], average=None)\n",
        "        class_support = np.sum(all_labels == i)\n",
        "\n",
        "        if len(class_precision) > 0:\n",
        "            print(f\"  {class_name:15} - Precision: {class_precision[0]:.4f}, \"\n",
        "                  f\"Recall: {class_recall[0]:.4f}, F1: {class_f1[0]:.4f}, \"\n",
        "                  f\"Support: {class_support}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "RWHOQBV-BfH8",
        "outputId": "e5e6b498-dac3-49cc-ad37-c40ca1a32584"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# --- ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·:Confusion Matrix ---\n",
        "\n",
        "# 1. ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ (ÏŒÏ€Ï‰Ï‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ ÏƒÏ„Î¿ MIT-BIH)\n",
        "class_names = ['N', 'S', 'V', 'F', 'Q'] # N=Normal, S=Supraventricular, V=Ventricular, F=Fusion, Q=Unknown\n",
        "\n",
        "# 2. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ± ÏƒÏÎ³Ï‡Ï…ÏƒÎ·Ï‚\n",
        "# all_labels = Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ ÎµÏ„Î¹ÎºÎ­Ï„ÎµÏ‚, all_preds = Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î¼Î¿Î½Ï„Î­Î»Î¿Ï…\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# 3. ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ± (Ï„Î¹Î¼Î­Ï‚ Î±Ï€ÏŒ 0 Î­Ï‰Ï‚ 1)\n",
        "# Î”Î¹Î±Î¹ÏÎ¿ÏÎ¼Îµ ÎºÎ¬Î¸Îµ ÎºÎµÎ»Î¯ Î¼Îµ Ï„Î¿ Î¬Î¸ÏÎ¿Î¹ÏƒÎ¼Î± Ï„Î·Ï‚ Î³ÏÎ±Î¼Î¼Î®Ï‚ Ï„Î¿Ï… (true label)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# 4. Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎ· Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ± (Heatmap)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
        "\n",
        "plt.title(\"(a)Confusion Matrix (ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿Ï‚)\", fontsize=14)\n",
        "plt.xlabel(\"Î ÏÎ¿Î²Î»ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î•Ï„Î¹ÎºÎ­Ï„Î± (Predicted)\", fontsize=12)\n",
        "plt.ylabel(\"Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ® Î•Ï„Î¹ÎºÎ­Ï„Î± (True)\", fontsize=12)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "3rLLMzg2BfH8",
        "outputId": "b307df3f-b321-4f20-ba66-2e8ff75a1b79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·: ÎšÎ±Î¼Ï€ÏÎ»ÎµÏ‚ ROC (One-vs-Rest) ---\n",
        "\n",
        "# 1. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¼Î²Î¬ ÏƒÏ‡ÎµÎ´Î¯Î±ÏƒÎ·Ï‚\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# 2. Î•Ï€Î±Î½Î¬Î»Î·ÏˆÎ· Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎºÎ»Î¬ÏƒÎ· (0 Î­Ï‰Ï‚ 4)\n",
        "for i in range(5):\n",
        "    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ FPR, TPR (Î±Ï€ÏŒ Ï„Î± binarized labels ÎºÎ±Î¹ Ï„Î¹Ï‚ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚)\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎµÎ¼Î²Î±Î´Î¿Ï ÎºÎ¬Ï„Ï‰ Î±Ï€ÏŒ Ï„Î·Î½ ÎºÎ±Î¼Ï€ÏÎ»Î· (AUC)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    # Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎ· Ï„Î·Ï‚ ÎºÎ±Î¼Ï€ÏÎ»Î·Ï‚ Ï„Î·Ï‚ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î·Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚\n",
        "    plt.plot(fpr, tpr, label=f\"ROC ÎšÎ»Î¬ÏƒÎ·Ï‚ {i} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "# 3. Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎ· Î³ÏÎ±Î¼Î¼Î®Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ (Ï„Ï…Ï‡Î±Î¯Î± Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Î¤Ï…Ï‡Î±Î¯Î± Î ÏÏŒÎ²Î»ÎµÏˆÎ·')\n",
        "\n",
        "# 4. Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ (Ï„Î¯Ï„Î»Î¿Î¹, Î¬Î¾Î¿Î½ÎµÏ‚, Ï…Ï€ÏŒÎ¼Î½Î·Î¼Î±)\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"ÎšÎ±Î¼Ï€ÏÎ»ÎµÏ‚ Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÎ¿Ï Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¿Ï (ROC) - OvR\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ MIT-AF (3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚)\n",
        "import os\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import gzip\n",
        "import pickle\n",
        "import neurokit2 as nk\n",
        "from scipy.signal import resample\n",
        "\n",
        "# --- ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Î¸ÎµÏÏÎ½ ---\n",
        "TARGET_SAMPLING_RATE = 125 # Î£Ï„ÏŒÏ‡Î¿Ï‚ ÏƒÏ…Ï‡Î½ÏŒÏ„Î·Ï„Î±Ï‚ Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î±Ï‚ (Hz)\n",
        "MAX_LEN_AF = 30 * TARGET_SAMPLING_RATE  # ÎœÎ­Î³Î¹ÏƒÏ„Î¿ Î¼Î®ÎºÎ¿Ï‚ Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚ (30 Î´ÎµÏ…Ï„.)\n",
        "\n",
        "# Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· 3 ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹ÏÎ½ (Î±Î³Î½Î¿ÎµÎ¯Ï„Î±Î¹ Î· ÎºÎ»Î¬ÏƒÎ· 'J')\n",
        "label_mapping = {\n",
        "    \"N\": 0,\n",
        "    \"AFIB\": 1,\n",
        "    \"AFL\": 2\n",
        "    # Î— ÎºÎ»Î¬ÏƒÎ· J ÎºÎ±Î¹ Î¬Î»Î»ÎµÏ‚ Î±Î³Î½Î¿Î¿ÏÎ½Ï„Î±Î¹\n",
        "}\n",
        "\n",
        "def downsample_signal(signal, original_fs=250, target_fs=125):\n",
        "    \"\"\"Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·: Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± (Î±Ï€ÏŒ 250Hz ÏƒÎµ 125Hz).\"\"\"\n",
        "    if original_fs == target_fs:\n",
        "        return signal\n",
        "    num_samples = int(len(signal) * target_fs / original_fs)\n",
        "    return resample(signal, num_samples)\n",
        "\n",
        "def normalize_signal(signal):\n",
        "    \"\"\"Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·: ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Min-Max [0, 1].\"\"\"\n",
        "    return (signal - np.min(signal)) / (np.max(signal) - np.min(signal) + 1e-8)\n",
        "\n",
        "def detect_r_peaks(signal, fs=125):\n",
        "    \"\"\"Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·: Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· R-peaks (Î¼Îµ NeuroKit2).\"\"\"\n",
        "    _, rpeaks = nk.ecg_peaks(signal, sampling_rate=fs)\n",
        "    return rpeaks[\"ECG_R_Peaks\"]\n",
        "\n",
        "def extract_t_episodes(signal, r_peaks):\n",
        "    \"\"\"Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·: Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ (Ï‡Ï„ÏÏ€Ï‰Î½) Î³ÏÏÏ‰ Î±Ï€ÏŒ Ï„Î± R-peaks.\"\"\"\n",
        "    if len(r_peaks) < 2:\n",
        "        return []\n",
        "    rr_intervals = np.diff(r_peaks)\n",
        "    median_rr = int(np.median(rr_intervals))\n",
        "    episodes = []\n",
        "    for r in r_peaks:\n",
        "        start = max(0, r - median_rr // 2)\n",
        "        end = min(len(signal), r + median_rr // 2)\n",
        "        episodes.append((start, end))\n",
        "    return episodes\n",
        "\n",
        "def build_samplewise_labels(record_len, ann_samples, ann_symbols):\n",
        "    \"\"\"Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± 'Ï€Ï…ÎºÎ½ÏÎ½' ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ (Î¼Î¯Î± ÎµÏ„Î¹ÎºÎ­Ï„Î± Î±Î½Î¬ Î´ÎµÎ¯Î³Î¼Î± ÏƒÎ®Î¼Î±Ï„Î¿Ï‚).\"\"\"\n",
        "    labels = np.array([\"\"] * record_len, dtype=object)\n",
        "    ann_samples = np.array(ann_samples)\n",
        "    ann_symbols = np.array(ann_symbols, dtype=object)\n",
        "    if len(ann_samples) == 0:\n",
        "        return labels\n",
        "    order = np.argsort(ann_samples)\n",
        "    ann_samples = ann_samples[order]\n",
        "    ann_symbols = ann_symbols[order]\n",
        "    for i in range(len(ann_samples)):\n",
        "        start = ann_samples[i]\n",
        "        end = ann_samples[i+1] if i+1 < len(ann_samples) else record_len\n",
        "        if start < 0: start = 0\n",
        "        if end > record_len: end = record_len\n",
        "        labels[start:end] = ann_symbols[i]\n",
        "    return labels\n",
        "\n",
        "def get_label(sym):\n",
        "    \"\"\"Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î·Î½ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ® ÎµÏ„Î¹ÎºÎ­Ï„Î± (0, 1, 2) Î® None Î±Î½ Î´ÎµÎ½ Î±Î½Î®ÎºÎµÎ¹ ÏƒÏ„Î¹Ï‚ 3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚.\"\"\"\n",
        "    if sym is None or str(sym).strip() == \"\":\n",
        "        return None\n",
        "    s = str(sym).strip().upper()\n",
        "    s = s.replace(\"(\", \"\")\n",
        "    # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® ÎµÏ„Î¹ÎºÎ­Ï„Î±Ï‚ Î¼ÏŒÎ½Î¿ Î±Î½ ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ 3-class mapping\n",
        "    if s in label_mapping:\n",
        "        return label_mapping[s]\n",
        "    else:\n",
        "        return None  # Î‘Î³Î½Î¿ÎµÎ¯ 'J' ÎºÎ±Î¹ Î¬Î³Î½Ï‰ÏƒÏ„ÎµÏ‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚\n",
        "\n",
        "def pad_signal(signal, max_len):\n",
        "    \"\"\"Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·: Padding/Truncating Î³Î¹Î± ÏƒÏ„Î±Î¸ÎµÏÏŒ Î¼Î®ÎºÎ¿Ï‚.\"\"\"\n",
        "    if len(signal) < max_len:\n",
        "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
        "    else:\n",
        "        return signal[:max_len]\n",
        "\n",
        "def preprocess_afdb_beats(dataset_dir):\n",
        "    \"\"\"ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·: Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï„Î¿Ï… AFDB dataset (3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚).\"\"\"\n",
        "    all_beats, all_labels = [], []\n",
        "    ignored_count = 0\n",
        "    processed_count = 0\n",
        "    j_class_ignored = 0  # ÎœÎ­Ï„ÏÎ·ÏƒÎ· Ï‡Ï„ÏÏ€Ï‰Î½ 'J' Ï€Î¿Ï… Î±Î³Î½Î¿Î®Î¸Î·ÎºÎ±Î½\n",
        "\n",
        "    for file in os.listdir(dataset_dir):\n",
        "        if file.endswith('.dat'):\n",
        "            recname = os.path.join(dataset_dir, file.replace('.dat', ''))\n",
        "            try:\n",
        "                rec = wfdb.rdrecord(recname)\n",
        "                signal = rec.p_signal[:, 0].astype(np.float32)\n",
        "                fs = rec.fs\n",
        "\n",
        "                # 1. Î¥Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± ÏƒÎ®Î¼Î±Ï„Î¿Ï‚\n",
        "                signal = downsample_signal(signal, original_fs=fs, target_fs=TARGET_SAMPLING_RATE)\n",
        "\n",
        "                # 2. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· annotations (ÎºÎ±Î¹ Ï…Ï€Î¿Î´ÎµÎ¹Î³Î¼Î±Ï„Î¿Î»Î·ÏˆÎ¯Î± Ï„Ï‰Î½ Î¸Î­ÏƒÎµÏ‰Î½)\n",
        "                ann = wfdb.rdann(recname, 'atr')\n",
        "                ann_samples = (np.array(ann.sample) * (TARGET_SAMPLING_RATE / fs)).astype(int)\n",
        "                ann_symbols = ann.aux_note if hasattr(ann, \"aux_note\") else ann.symbol\n",
        "\n",
        "                # 3. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± 'Ï€Ï…ÎºÎ½ÏÎ½' ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½ (Î±Î½Î¬ Î´ÎµÎ¯Î³Î¼Î±)\n",
        "                sample_labels = build_samplewise_labels(len(signal), ann_samples, ann_symbols)\n",
        "\n",
        "                # 4. ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·\n",
        "                signal = normalize_signal(signal)\n",
        "\n",
        "                # 5. Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· R-peaks\n",
        "                r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
        "\n",
        "                # 6. Î•Î¾Î±Î³Ï‰Î³Î® Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ Ï‡Ï„ÏÏ€Ï‰Î½\n",
        "                t_episodes = extract_t_episodes(signal, r_peaks)\n",
        "\n",
        "                for (start, end) in t_episodes:\n",
        "                    # 7. ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÎµÏ„Î¹ÎºÎ­Ï„Î±Ï‚ ÏƒÏ„Î¿ ÎºÎ­Î½Ï„ÏÎ¿ Ï„Î¿Ï… Ï‡Ï„ÏÏ€Î¿Ï…\n",
        "                    center = (start + end) // 2\n",
        "                    original_sym = str(sample_labels[center]).strip().upper().replace(\"(\", \"\")\n",
        "                    label = get_label(sample_labels[center])\n",
        "\n",
        "                    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼ÏŒÎ½Î¿ ÎµÎ¬Î½ Î· ÎµÏ„Î¹ÎºÎ­Ï„Î± ÎµÎ¯Î½Î±Î¹ Î¼Î¯Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ {N, AFIB, AFL}\n",
        "                    if label is not None:\n",
        "                        beat = signal[start:end]\n",
        "                        padded = pad_signal(beat, MAX_LEN_AF)\n",
        "                        all_beats.append(padded)\n",
        "                        all_labels.append(label)\n",
        "                        processed_count += 1\n",
        "                    else:\n",
        "                        # ÎšÎ±Ï„Î±Î¼Î­Ï„ÏÎ·ÏƒÎ· Î±Î³Î½Î¿Î·Î¼Î­Î½Ï‰Î½ Ï‡Ï„ÏÏ€Ï‰Î½ (Ï€.Ï‡. 'J')\n",
        "                        if original_sym == \"J\":\n",
        "                            j_class_ignored += 1\n",
        "                        ignored_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· {recname}, ÏƒÏ†Î¬Î»Î¼Î±: {e}\")\n",
        "\n",
        "    print(f\"Î•Ï€ÎµÎ¾ÎµÏÎ³Î¬ÏƒÏ„Î·ÎºÎ±Î½: {processed_count} Ï‡Ï„ÏÏ€Î¿Î¹\")\n",
        "    print(f\"Î‘Î³Î½Î¿Î®Î¸Î·ÎºÎ±Î½: {ignored_count} Ï‡Ï„ÏÏ€Î¿Î¹ (ÎµÎº Ï„Ï‰Î½ Î¿Ï€Î¿Î¯Ï‰Î½ {j_class_ignored} Î®Ï„Î±Î½ ÎºÎ»Î¬ÏƒÎ·Ï‚ 'J')\")\n",
        "    return np.array(all_beats), np.array(all_labels)\n",
        "\n",
        "# --- ÎšÏÏÎ¹Î± Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ---\n",
        "\n",
        "# Î•Ï†Î±ÏÎ¼Î¿Î³Î® Ï„Î·Ï‚ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚\n",
        "afdb_beats, afdb_labels = preprocess_afdb_beats(\"data/files\")\n",
        "\n",
        "# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ PyTorch Tensors\n",
        "X_afdb = torch.tensor(afdb_beats, dtype=torch.float32)\n",
        "y_afdb = torch.tensor(afdb_labels, dtype=torch.long)\n",
        "\n",
        "# Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· (Î¼Îµ Î½Î­Î¿ ÏŒÎ½Î¿Î¼Î± Î³Î¹Î± Ï„Î¹Ï‚ 3 ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚)\n",
        "with gzip.open(\"afdb_beats_3cat.pkl.gz\", \"wb\") as f:\n",
        "    pickle.dump((X_afdb, y_afdb), f)\n",
        "\n",
        "# Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½\n",
        "print(f\"AFDB Beats Shape: {X_afdb.shape}\")\n",
        "print(f\"Unique Labels: {np.unique(afdb_labels, return_counts=True)}\")\n",
        "print(\"Class mapping: 0=AFIB, 1=AFL, 2=N\")"
      ],
      "metadata": {
        "id": "OKH104VhSJ4n",
        "outputId": "90b88ecb-e93c-43cb-d402-4286f2c4a83c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFDB Beats Shape: torch.Size([1146813, 3750])\n",
            "Unique Labels: (array([0, 1, 2, 3, 4]), array([513691,  12385,    304, 620429,      4]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pickle, gzip\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from NNModel import ECGClassifier # Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ…ÏƒÎºÎµÏ…Î®Ï‚ (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Î§ÏÎ®ÏƒÎ· ÏƒÏ…ÏƒÎºÎµÏ…Î®Ï‚: {device}\")\n",
        "\n",
        "# --------------------\n",
        "# 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (AFDB - 3 ÎšÎ»Î¬ÏƒÎµÎ¹Ï‚)\n",
        "# --------------------\n",
        "print(\"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ AFDB (3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚)...\")\n",
        "with gzip.open(\"afdb_beats_3cat.pkl.gz\", \"rb\") as f:\n",
        "    X_afdb, y_afdb = pickle.load(f)\n",
        "\n",
        "print(f\"Data shape: {X_afdb.shape}\")\n",
        "print(f\"Labels shape: {y_afdb.shape}\")\n",
        "\n",
        "# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÎºÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½\n",
        "unique_labels, counts = np.unique(y_afdb, return_counts=True)\n",
        "class_names = ['N','AFIB','AFL']  # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Î³Î¹Î± 3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚\n",
        "print(\"\\nÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    pct = (count / len(y_afdb)) * 100\n",
        "    print(f\"  ÎšÎ»Î¬ÏƒÎ· {label} ({class_names[label]}): {count} Î´ÎµÎ¯Î³Î¼Î±Ï„Î± ({pct:.2f}%)\")\n",
        "\n",
        "# Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (60-20-20) Î¼Îµ stratify\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_afdb, y_afdb, test_size=0.20, random_state=42, stratify=y_afdb\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "print(\"\\nSplits:\")\n",
        "print(f\"  Train: {X_train.shape[0]}  Val: {X_val.shape[0]}  Test: {X_test.shape[0]}\")\n",
        "\n",
        "# --------------------\n",
        "# 2. Custom Dataset & DataLoaders\n",
        "# --------------------\n",
        "class ECGDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Custom Dataset Î¼Îµ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· data augmentation.\"\"\"\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ Tensors ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # (B,1,L)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self): return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx].clone()\n",
        "        y = self.y[idx]\n",
        "\n",
        "        if self.augment:\n",
        "            # Î¤ÎµÏ‡Î½Î¹ÎºÎ® 1: Î“ÎºÎ±Î¿Ï…ÏƒÎ¹Î±Î½ÏŒÏ‚ Î¸ÏŒÏÏ…Î²Î¿Ï‚\n",
        "            if np.random.rand() < 0.3:\n",
        "                noise = torch.randn_like(x) * 0.01\n",
        "                x += noise\n",
        "            # Î¤ÎµÏ‡Î½Î¹ÎºÎ® 2: Î¤Ï…Ï‡Î±Î¯Î± Ï‡ÏÎ¿Î½Î¹ÎºÎ® Î¼ÎµÏ„Î±Ï„ÏŒÏ€Î¹ÏƒÎ·\n",
        "            if np.random.rand() < 0.3:\n",
        "                shift = np.random.randint(-10, 11)\n",
        "                x = torch.roll(x, shifts=shift, dims=-1)\n",
        "        return x, y\n",
        "\n",
        "# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(ECGDataset(X_train, y_train, augment=True),\n",
        "                                         batch_size=batch_size, shuffle=True,\n",
        "                                         num_workers=2, drop_last=True) # num_workers=2 Î³Î¹Î± Colab\n",
        "val_loader = torch.utils.data.DataLoader(ECGDataset(X_val, y_val, augment=False),\n",
        "                                       batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(ECGDataset(X_test, y_test, augment=False),\n",
        "                                        batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# --------------------\n",
        "# 3. ÎœÎ¿Î½Ï„Î­Î»Î¿ & Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î’Î±ÏÏÎ½ (Transfer Learning)\n",
        "# --------------------\n",
        "num_classes = 3  # Î‘Î»Î»Î±Î³Î® ÏƒÎµ 3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚\n",
        "model = ECGClassifier(num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "# Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Ï‰Î½ Î²Î±ÏÏÎ½\n",
        "try:\n",
        "    with gzip.open(\"pretrained_model_best.pth.gz\", \"rb\") as f:\n",
        "        pretrained_dict = pickle.load(f)\n",
        "\n",
        "    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Ï„Î¿Ï… Ï„ÎµÎ»Î¹ÎºÎ¿Ï ÎµÏ€Î¹Ï€Î­Î´Î¿Ï… (fc2)\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
        "                           if not k.startswith(\"fc2\")}\n",
        "    missing, unexpected = model.load_state_dict(pretrained_dict, strict=False)\n",
        "    print(f\"Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ Ï€ÏÎ¿-ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î²Î¬ÏÎ·. Missing: {len(missing)}  Unexpected: {len(unexpected)}\")\n",
        "\n",
        "    # Î•Ï€Î±Î½Î±-Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… fc2 Î³Î¹Î± 3 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚\n",
        "    model.fc2 = nn.Linear(model.fc2.in_features, num_classes).to(device)\n",
        "    nn.init.kaiming_normal_(model.fc2.weight)\n",
        "    nn.init.constant_(model.fc2.bias, 0)\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·: Î‘Î´Ï…Î½Î±Î¼Î¯Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î²Î±ÏÏÎ½ ({e}). Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏÏ‡Î®.\")\n",
        "\n",
        "# --------------------\n",
        "# 4. Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î‘Ï€ÏÎ»ÎµÎ¹Î±Ï‚ & Optimizer\n",
        "# --------------------\n",
        "# Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î²Î±ÏÏÎ½ ÎºÎ»Î¬ÏƒÎµÏ‰Î½ (class weights)\n",
        "y_train_np = y_train.numpy() if isinstance(y_train, torch.Tensor) else y_train\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train_np), y=y_train_np)\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights) # Loss Î¼Îµ Î²Î¬ÏÎ·\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "\n",
        "# --------------------\n",
        "# 5. Î’ÏÏŒÏ‡Î¿Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Training Loop)\n",
        "# --------------------\n",
        "num_epochs = 5 # Î§Î±Î¼Î·Î»ÏŒÏ‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎºÏÎºÎ»Ï‰Î½\n",
        "best_val_acc = 0.0\n",
        "patience, patience_counter = 2, 0 # Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Early Stopping\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # --- Î¦Î¬ÏƒÎ· Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (Train) ---\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Gradient Clipping\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (preds == y_batch).sum().item()\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # --- Î¦Î¬ÏƒÎ·  (Validate) ---\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val_batch in val_loader:\n",
        "            X_val, y_val_batch = X_val.to(device), y_val_batch.to(device)\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss += criterion(val_outputs, y_val_batch).item()\n",
        "            _, val_preds = val_outputs.max(1)\n",
        "            val_total += y_val_batch.size(0)\n",
        "            val_correct += (val_preds == y_val_batch).sum().item()\n",
        "\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    scheduler.step(avg_val_loss) # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· scheduler\n",
        "\n",
        "    # Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ (Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î¿Î½ ÏŒÏÎ¿ \"ÎšÏÎºÎ»Î¿Ï‚\")\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss {avg_train_loss:.4f} Acc {train_acc:.2f}% | \"\n",
        "          f\"Val Loss {avg_val_loss:.4f} Acc {val_acc:.2f}% | \"\n",
        "          f\"LR {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # --- Early Stopping & Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎšÎ±Î»ÏÏ„ÎµÏÎ¿Ï… ---\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_afdb_3class_model.pth\")\n",
        "        print(\"  ğŸ’¾ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î½Î­Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Early Stopping\")\n",
        "            break\n",
        "\n",
        "# --------------------\n",
        "# 6. Î¤ÎµÎ»Î¹ÎºÎ® Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· (ÏƒÏ„Î¿ Test Set)\n",
        "# --------------------\n",
        "# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î¿Ï… ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…\n",
        "model.load_state_dict(torch.load(\"best_afdb_3class_model.pth\"))\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        preds = model(X_batch).argmax(1)\n",
        "        y_true.extend(y_batch.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "# Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„ÎµÎ»Î¹ÎºÏÎ½ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½\n",
        "print(\"\\n--- Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏƒÏ„Î¿ Test Set ---\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "O8py3PwiJU2a",
        "outputId": "033142d9-5470-452b-e8a7-36ebea45ae94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGClassifier(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (resblock1): ResidualBlock(\n",
            "    (conv1): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "      (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock2): ResidualBlock(\n",
            "    (conv1): Conv1d(64, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=96, out_features=6, bias=True)\n",
            "      (fc2): Linear(in_features=6, out_features=96, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(64, 96, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock3): ResidualBlock(\n",
            "    (conv1): Conv1d(96, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "      (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(96, 128, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock4): ResidualBlock(\n",
            "    (conv1): Conv1d(128, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(160, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=160, out_features=10, bias=True)\n",
            "      (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(128, 160, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (lstm): LSTM(160, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=5, bias=True)\n",
            ")\n",
            "Using device: cuda\n",
            "Loading AFDB data (3 classes)...\n",
            "Data shape: torch.Size([1146505, 3750])\n",
            "Labels shape: torch.Size([1146505])\n",
            "\n",
            "Class distribution:\n",
            "  Class 0 (N): 620429 samples (54.11%)\n",
            "  Class 1 (AFIB): 513691 samples (44.80%)\n",
            "  Class 2 (AFL): 12385 samples (1.08%)\n",
            "\n",
            "Splits:\n",
            "  Train: 687903  Val: 229301  Test: 229301\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3216641403.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # (B,1,L)\n",
            "/tmp/ipython-input-3216641403.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Warning: Could not load pretrained weights ([Errno 2] No such file or directory: 'pretrained_modelss_best.pth.gz'). Training from scratch.\n",
            "Class weights: tensor([ 0.6160,  0.7440, 30.8574], device='cuda:0')\n",
            "Epoch 1/5 | Train Loss 0.5636 Acc 80.80% | Val Loss 1.9411 Acc 63.80% | LR 0.001000\n",
            "  ğŸ’¾ Saved new best model\n",
            "Epoch 2/5 | Train Loss 0.2625 Acc 94.39% | Val Loss 0.3082 Acc 92.82% | LR 0.001000\n",
            "  ğŸ’¾ Saved new best model\n",
            "Epoch 3/5 | Train Loss 0.2228 Acc 95.39% | Val Loss 0.2224 Acc 95.97% | LR 0.001000\n",
            "  ğŸ’¾ Saved new best model\n",
            "Epoch 4/5 | Train Loss 0.1892 Acc 95.92% | Val Loss 0.1680 Acc 96.87% | LR 0.001000\n",
            "  ğŸ’¾ Saved new best model\n",
            "Epoch 5/5 | Train Loss 0.1722 Acc 96.25% | Val Loss 0.2249 Acc 94.99% | LR 0.001000\n",
            "\n",
            "Test Accuracy: 0.9686656403591786\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N     0.9827    0.9631    0.9728    124086\n",
            "        AFIB     0.9542    0.9782    0.9660    102738\n",
            "         AFL     0.8912    0.8502    0.8702      2477\n",
            "\n",
            "    accuracy                         0.9687    229301\n",
            "   macro avg     0.9427    0.9305    0.9364    229301\n",
            "weighted avg     0.9689    0.9687    0.9687    229301\n",
            "\n",
            "Confusion Matrix:\n",
            " [[119513   4563     10]\n",
            " [  1994 100497    247]\n",
            " [   111    260   2106]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# --- ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·: ÎšÎ±Î¼Ï€ÏÎ»ÎµÏ‚ ROC (One-vs-Rest) ---\n",
        "\n",
        "# 1. Î£Ï…Î»Î»Î¿Î³Î® Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ (Ï€Î¹Î¸Î±Î½Î¿Ï„Î®Ï„Ï‰Î½) Î±Ï€ÏŒ Ï„Î¿ test set\n",
        "model.eval()\n",
        "y_true, y_probs = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        # Î•Ï†Î±ÏÎ¼Î¿Î³Î® softmax Î³Î¹Î± Î»Î®ÏˆÎ· Ï€Î¹Î¸Î±Î½Î¿Ï„Î®Ï„Ï‰Î½\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        y_true.extend(y_batch.numpy())\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# 2. Binarization (Î”Ï…Î±Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·) Ï„Ï‰Î½ ÎµÏ„Î¹ÎºÎµÏ„ÏÎ½\n",
        "# Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î³Î¹Î± Ï„Î· ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® One-vs-Rest (OvR) ÏƒÎµ multi-class\n",
        "classes = np.unique(y_true)\n",
        "y_true_bin = label_binarize(y_true, classes=classes)\n",
        "\n",
        "# 3. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ROC/AUC ÎºÎ±Î¹ ÏƒÏ‡ÎµÎ´Î¯Î±ÏƒÎ· Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎºÎ»Î¬ÏƒÎ·\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, c in enumerate(classes):\n",
        "    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ FPR, TPR Î³Î¹Î± Ï„Î·Î½ ÎºÎ»Î¬ÏƒÎ· 'i' Î­Î½Î±Î½Ï„Î¹ ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î¬Î»Î»Ï‰Î½\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"ÎšÎ»Î¬ÏƒÎ· {c} (AUC = {roc_auc:.3f})\")\n",
        "\n",
        "# Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎ· Î³ÏÎ±Î¼Î¼Î®Ï‚ Ï„Ï…Ï‡Î±Î¯Î±Ï‚ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚\n",
        "plt.plot([0,1], [0,1], 'k--', lw=1)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"ÎšÎ±Î¼Ï€ÏÎ»Î· ROC (One-vs-Rest)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 4. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ…Î½Î¿Î»Î¹ÎºÏÎ½ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ AUC (Macro & Weighted)\n",
        "print(\"Macro AUC:\", roc_auc_score(y_true_bin, y_probs, average=\"macro\"))\n",
        "print(\"Weighted AUC:\", roc_auc_score(y_true_bin, y_probs, average=\"weighted\"))"
      ],
      "metadata": {
        "id": "kqSxwYDScBpJ",
        "outputId": "054d424b-e3ae-4470-ed6e-cc60c1282425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro AUC: 0.995406429747324\n",
            "Weighted AUC: 0.9949875242424773\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}