{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m1kemp/ecgDiagnosis/blob/main/ColabCode/FullImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Il-hgAcf6yi",
        "outputId": "d5813c96-2ffe-4451-aeeb-ac5038f0474c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracting mit-af-database.zip ‚Üí data/\n",
            "‚úÖ Done: mit-af-database.zip\n",
            "Extracting mit-arrhythmia-database.zip ‚Üí data/\n",
            "‚úÖ Done: mit-arrhythmia-database.zip\n",
            "Extracting training2017.zip ‚Üí data/\n",
            "‚úÖ Done: training2017.zip\n",
            "\n",
            "üìÅ Contents of data/:\n",
            "  __MACOSX\n",
            "  training2017\n",
            "  mit-bih-arrhythmia-database-1.0.0\n",
            "  files\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths in your Google Drive (adjust if needed)\n",
        "drive_data_dir = Path(\"/content/drive/MyDrive/ECGData/data\")\n",
        "local_data_dir = Path(\"data\")\n",
        "local_data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Zips you want to extract\n",
        "zips = [\n",
        "    \"mit-af-database.zip\",  # Make sure names match exactly\n",
        "    \"mit-arrhythmia-database.zip\",\n",
        "    \"training2017.zip\",\n",
        "]\n",
        "\n",
        "def safe_extract(zip_path: Path, dest_dir: Path):\n",
        "    \"\"\"Safely extract a zip file into dest_dir.\"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        zf.extractall(dest_dir)\n",
        "\n",
        "for zip_name in zips:\n",
        "    zip_path = drive_data_dir / zip_name\n",
        "    if not zip_path.exists():\n",
        "        print(f\"‚ö†Ô∏è File not found in Drive: {zip_path}\")\n",
        "        continue\n",
        "\n",
        "    # Extract directly to data/ without creating extra subdirectory\n",
        "    print(f\"Extracting {zip_path.name} ‚Üí {local_data_dir}/\")\n",
        "    safe_extract(zip_path, local_data_dir)\n",
        "    print(f\"‚úÖ Done: {zip_path.name}\")\n",
        "\n",
        "# Verify extraction\n",
        "print(\"\\nüìÅ Contents of data/:\")\n",
        "for item in local_data_dir.iterdir():\n",
        "    print(f\"  {item.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_OUbktMiJUY",
        "outputId": "b4c91a01-c0fa-433d-f6b7-436c01f2214f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting neurokit2\n",
            "  Downloading neurokit2-0.2.12-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Collecting biosppy\n",
            "  Downloading biosppy-2.2.3-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.1)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.6.1)\n",
            "Requirement already satisfied: PyWavelets>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from neurokit2) (1.9.0)\n",
            "Collecting bidict (from biosppy)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from biosppy) (3.14.0)\n",
            "Collecting shortuuid (from biosppy)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from biosppy) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from biosppy) (1.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from biosppy) (4.12.0.88)\n",
            "Collecting mock (from biosppy)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.8.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neurokit2-0.2.12-py2.py3-none-any.whl (708 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m708.4/708.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biosppy-2.2.3-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.0/158.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: shortuuid, mock, bidict, pandas, wfdb, neurokit2, biosppy\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bidict-0.23.1 biosppy-2.2.3 mock-5.2.0 neurokit2-0.2.12 pandas-2.3.2 shortuuid-1.0.13 wfdb-4.3.0\n",
            "Processing 8528 signals...\n",
            "Processing signal 1/8528\n",
            "Processing signal 101/8528\n",
            "Processing signal 201/8528\n",
            "Processing signal 301/8528\n",
            "Processing signal 401/8528\n",
            "Processing signal 501/8528\n",
            "Processing signal 601/8528\n",
            "Processing signal 701/8528\n",
            "Processing signal 801/8528\n",
            "Processing signal 901/8528\n",
            "Processing signal 1001/8528\n",
            "Processing signal 1101/8528\n",
            "Processing signal 1201/8528\n",
            "Processing signal 1301/8528\n",
            "Processing signal 1401/8528\n",
            "Processing signal 1501/8528\n",
            "Processing signal 1601/8528\n",
            "Processing signal 1701/8528\n",
            "Processing signal 1801/8528\n",
            "Processing signal 1901/8528\n",
            "Processing signal 2001/8528\n",
            "Processing signal 2101/8528\n",
            "Processing signal 2201/8528\n",
            "Processing signal 2301/8528\n",
            "Processing signal 2401/8528\n",
            "Processing signal 2501/8528\n",
            "Processing signal 2601/8528\n",
            "Processing signal 2701/8528\n",
            "Processing signal 2801/8528\n",
            "Processing signal 2901/8528\n",
            "Processing signal 3001/8528\n",
            "Processing signal 3101/8528\n",
            "Processing signal 3201/8528\n",
            "Processing signal 3301/8528\n",
            "Processing signal 3401/8528\n",
            "Processing signal 3501/8528\n",
            "Processing signal 3601/8528\n",
            "Processing signal 3701/8528\n",
            "Processing signal 3801/8528\n",
            "Processing signal 3901/8528\n",
            "Processing signal 4001/8528\n",
            "Processing signal 4101/8528\n",
            "Processing signal 4201/8528\n",
            "Processing signal 4301/8528\n",
            "Processing signal 4401/8528\n",
            "Processing signal 4501/8528\n",
            "Processing signal 4601/8528\n",
            "Processing signal 4701/8528\n",
            "Processing signal 4801/8528\n",
            "Processing signal 4901/8528\n",
            "Processing signal 5001/8528\n",
            "Processing signal 5101/8528\n",
            "Processing signal 5201/8528\n",
            "Processing signal 5301/8528\n",
            "Processing signal 5401/8528\n",
            "Processing signal 5501/8528\n",
            "Processing signal 5601/8528\n",
            "Processing signal 5701/8528\n",
            "Processing signal 5801/8528\n",
            "Processing signal 5901/8528\n",
            "Processing signal 6001/8528\n",
            "Processing signal 6101/8528\n",
            "Processing signal 6201/8528\n",
            "Processing signal 6301/8528\n",
            "Processing signal 6401/8528\n",
            "Processing signal 6501/8528\n",
            "Processing signal 6601/8528\n",
            "Processing signal 6701/8528\n",
            "Processing signal 6801/8528\n",
            "Processing signal 6901/8528\n",
            "Processing signal 7001/8528\n",
            "Processing signal 7101/8528\n",
            "Processing signal 7201/8528\n",
            "Processing signal 7301/8528\n",
            "Processing signal 7401/8528\n",
            "Processing signal 7501/8528\n",
            "Processing signal 7601/8528\n",
            "Processing signal 7701/8528\n",
            "Processing signal 7801/8528\n",
            "Processing signal 7901/8528\n",
            "Processing signal 8001/8528\n",
            "Processing signal 8101/8528\n",
            "Processing signal 8201/8528\n",
            "Processing signal 8301/8528\n",
            "Processing signal 8401/8528\n",
            "Processing signal 8501/8528\n",
            "PhysioNet Data Shape: torch.Size([335068, 1250])\n",
            "Label distribution: [190702  33552 102468   8346]\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install wfdb neurokit2 biosppy torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wfdb\n",
        "import scipy.io\n",
        "import scipy.signal\n",
        "import neurokit2 as nk\n",
        "import torch\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "# Define constants\n",
        "TARGET_SAMPLING_RATE = 125  # Hz\n",
        "MAX_LEN_PHYSIONET = 10 * TARGET_SAMPLING_RATE  # 10 seconds\n",
        "\n",
        "def load_physionet_data(path):\n",
        "    \"\"\"Load PhysioNet 2017 dataset from .mat files and reference.csv.\"\"\"\n",
        "    signals, labels = [], []\n",
        "    ref_df = pd.read_csv(os.path.join(path, \"REFERENCE.csv\"), header=None)\n",
        "    ref_dict = dict(zip(ref_df[0], ref_df[1]))\n",
        "    label_mapping = {\"N\": 0, \"A\": 1, \"O\": 2, \"~\": 3}\n",
        "\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith(\".mat\"):\n",
        "            record_name = file.replace(\".mat\", \"\")\n",
        "            try:\n",
        "                mat_data = scipy.io.loadmat(os.path.join(path, file))\n",
        "                signal = mat_data[\"val\"][0]  # Extract ECG lead\n",
        "                label = ref_dict.get(record_name, None)\n",
        "                if label and label in label_mapping:\n",
        "                    signals.append(signal)\n",
        "                    labels.append(label_mapping[label])\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {record_name}: {e}\")\n",
        "    return signals, labels\n",
        "\n",
        "def downsample_signal(signal, original_fs, target_fs=125):\n",
        "    \"\"\"Downsample ECG signal from original_fs to target_fs.\"\"\"\n",
        "    if original_fs == target_fs:\n",
        "        return signal\n",
        "    num_samples = int(len(signal) * target_fs / original_fs)\n",
        "    return scipy.signal.resample(signal, num_samples)\n",
        "\n",
        "def normalize_signal(signal):\n",
        "    \"\"\"FIXED: Normalize ECG signal with better handling.\"\"\"\n",
        "    signal = np.array(signal, dtype=np.float32)\n",
        "    signal_min, signal_max = np.min(signal), np.max(signal)\n",
        "    signal_range = signal_max - signal_min\n",
        "\n",
        "    if signal_range < 1e-8:  # Prevent division by zero\n",
        "        return np.zeros_like(signal)\n",
        "\n",
        "    return (signal - signal_min) / signal_range\n",
        "\n",
        "def detect_r_peaks(signal, sampling_rate=125):\n",
        "    \"\"\"Detect R-peaks using NeuroKit2 with error handling.\"\"\"\n",
        "    try:\n",
        "        _, r_peaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate)\n",
        "        return np.array(r_peaks[\"ECG_R_Peaks\"])\n",
        "    except:\n",
        "        return np.array([])\n",
        "\n",
        "def extract_t_episodes(signal, r_peaks):\n",
        "    \"\"\"Extract T-episodes centered on R-peaks.\"\"\"\n",
        "    if len(r_peaks) < 2:\n",
        "        return []\n",
        "\n",
        "    rr_intervals = np.diff(r_peaks)\n",
        "    median_rr = int(np.median(rr_intervals))\n",
        "    episodes = []\n",
        "\n",
        "    for r in r_peaks:\n",
        "        start = max(0, r - median_rr // 2)\n",
        "        end = min(len(signal), r + median_rr // 2)\n",
        "        if end - start > 50:  # Minimum length check\n",
        "            episodes.append((start, end))\n",
        "    return episodes\n",
        "\n",
        "def pad_signal(signal, max_len):\n",
        "    \"\"\"Pad signal to max_len with zeros.\"\"\"\n",
        "    if len(signal) < max_len:\n",
        "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
        "    else:\n",
        "        return signal[:max_len]\n",
        "\n",
        "def preprocess_ecg_dataset(dataset_path):\n",
        "    \"\"\"Preprocess ECG dataset from PhysioNet.\"\"\"\n",
        "    signals, labels = load_physionet_data(dataset_path)\n",
        "    original_fs = 300  # PhysioNet signals are sampled at 300 Hz\n",
        "    processed_signals, processed_labels = [], []\n",
        "\n",
        "    print(f\"Processing {len(signals)} signals...\")\n",
        "\n",
        "    for i, (signal, label) in enumerate(zip(signals, labels)):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processing signal {i+1}/{len(signals)}\")\n",
        "\n",
        "        # 1. Downsampling\n",
        "        signal = downsample_signal(signal, original_fs, TARGET_SAMPLING_RATE)\n",
        "\n",
        "        # 2. Normalization\n",
        "        signal = normalize_signal(signal)\n",
        "\n",
        "        # Skip if signal is all zeros (normalization failed)\n",
        "        if np.all(signal == 0):\n",
        "            continue\n",
        "\n",
        "        # 3. R-peak detection\n",
        "        r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
        "\n",
        "        if len(r_peaks) < 2:\n",
        "            continue\n",
        "\n",
        "        # 4. T-episode and beat extraction\n",
        "        t_eps = extract_t_episodes(signal, r_peaks)\n",
        "\n",
        "        for start, end in t_eps:\n",
        "            beat = signal[start:end]\n",
        "            if len(beat) > 0:  # Ensure beat is not empty\n",
        "                processed_signals.append(pad_signal(beat, MAX_LEN_PHYSIONET))\n",
        "                processed_labels.append(label)\n",
        "\n",
        "    return np.array(processed_signals), np.array(processed_labels)\n",
        "\n",
        "# Example Usage\n",
        "physionet_data, physionet_labels = preprocess_ecg_dataset(\"data/training2017\")\n",
        "\n",
        "# Convert to PyTorch Tensors\n",
        "X_physionet = torch.tensor(physionet_data, dtype=torch.float32)\n",
        "y_physionet = torch.tensor(physionet_labels, dtype=torch.long)\n",
        "\n",
        "# Save processed data\n",
        "with gzip.open(\"pretraining_data.pkl.gz\", \"wb\") as f:\n",
        "    pickle.dump((X_physionet, y_physionet), f)\n",
        "\n",
        "print(f\"PhysioNet Data Shape: {X_physionet.shape}\")\n",
        "print(f\"Label distribution: {np.bincount(physionet_labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbM9jefcjxRn",
        "outputId": "187b863c-a411-4bcc-944a-124a97c18c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing NNModel.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile NNModel.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Squeeze-and-Excitation (SE) Module - FIXED\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
        "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, _ = x.shape\n",
        "        se = self.global_avg_pool(x).view(batch, channels)\n",
        "        se = F.relu(self.fc1(se))\n",
        "        se = F.sigmoid(self.fc2(se))  # CHANGED: sigmoid instead of softmax\n",
        "        se = se.view(batch, channels, 1)\n",
        "        return x * se\n",
        "\n",
        "# Residual Block with SE Module - IMPROVED\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=5):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)  # Added BN after conv2\n",
        "        self.se = SEBlock(out_channels)\n",
        "\n",
        "        # FIXED: Add BatchNorm to shortcut\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm1d(out_channels)\n",
        "        ) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))  # Apply BN before SE\n",
        "        out = self.se(out)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        out = self.maxpool(out)  # Move pooling after residual connection\n",
        "        return out\n",
        "\n",
        "# Full Model: CNN + BiLSTM + FC\n",
        "class ECGClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ECGClassifier, self).__init__()\n",
        "\n",
        "        # Initial Convolutional Layers\n",
        "        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "\n",
        "        # Residual Blocks with SE Module\n",
        "        self.resblock1 = ResidualBlock(32, 64)\n",
        "        self.resblock2 = ResidualBlock(64, 96)\n",
        "        self.resblock3 = ResidualBlock(96, 128)\n",
        "        self.resblock4 = ResidualBlock(128, 160)\n",
        "\n",
        "        # BiLSTM Layers\n",
        "        self.lstm = nn.LSTM(160, 64, num_layers=2, bidirectional=True,\n",
        "                           batch_first=True, dropout=0.2)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(128, 64)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Conv1d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm1d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial conv layers\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "\n",
        "        # Residual blocks\n",
        "        x = self.resblock1(x)\n",
        "        x = self.resblock2(x)\n",
        "        x = self.resblock3(x)\n",
        "        x = self.resblock4(x)\n",
        "\n",
        "        # Reshape for LSTM\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # BiLSTM\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.dropout1(x[:, -1, :])  # Take last LSTM output\n",
        "\n",
        "        # FC layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x  # CHANGED: Remove log_softmax, let CrossEntropyLoss handle it\n",
        "\n",
        "model = ECGClassifier(num_classes=5)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX9LZbhFj3DJ",
        "outputId": "6a12b8b8-849e-4688-ef45-21d5aeeab55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECGClassifier(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (resblock1): ResidualBlock(\n",
            "    (conv1): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "      (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock2): ResidualBlock(\n",
            "    (conv1): Conv1d(64, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=96, out_features=6, bias=True)\n",
            "      (fc2): Linear(in_features=6, out_features=96, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(64, 96, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock3): ResidualBlock(\n",
            "    (conv1): Conv1d(96, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "      (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(96, 128, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock4): ResidualBlock(\n",
            "    (conv1): Conv1d(128, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(160, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=160, out_features=10, bias=True)\n",
            "      (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(128, 160, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (lstm): LSTM(160, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=5, bias=True)\n",
            ")\n",
            "Pretraining data: torch.Size([335068, 1250]), Labels: 335068\n",
            "Label distribution: tensor([190702,  33552, 102468,   8346])\n",
            "Epoch 1, Batch 0, Loss: 1.3894\n",
            "Epoch 1, Batch 100, Loss: 1.4775\n",
            "Epoch 1, Batch 200, Loss: 1.0483\n",
            "Epoch 1, Batch 300, Loss: 1.2779\n",
            "Epoch 1, Batch 400, Loss: 1.1158\n",
            "Epoch 1, Batch 500, Loss: 1.2055\n",
            "Epoch 1, Batch 600, Loss: 1.5900\n",
            "Epoch 1, Batch 700, Loss: 1.2578\n",
            "Epoch 1, Batch 800, Loss: 1.0925\n",
            "Epoch 1, Batch 900, Loss: 1.2171\n",
            "Epoch 1, Batch 1000, Loss: 1.2002\n",
            "Epoch 1, Batch 1100, Loss: 0.8319\n",
            "Epoch 1, Batch 1200, Loss: 1.2033\n",
            "Epoch 1, Batch 1300, Loss: 1.3291\n",
            "Epoch 1, Batch 1400, Loss: 1.0843\n",
            "Epoch 1, Batch 1500, Loss: 1.2437\n",
            "Epoch 1, Batch 1600, Loss: 1.3374\n",
            "Epoch 1, Batch 1700, Loss: 1.3280\n",
            "Epoch 1, Batch 1800, Loss: 1.0868\n",
            "Epoch 1, Batch 1900, Loss: 0.9373\n",
            "Epoch 1, Batch 2000, Loss: 1.2162\n",
            "Epoch 1, Batch 2100, Loss: 1.0818\n",
            "Epoch 1, Batch 2200, Loss: 0.9690\n",
            "Epoch 1, Batch 2300, Loss: 1.0840\n",
            "Epoch 1, Batch 2400, Loss: 1.4978\n",
            "Epoch 1, Batch 2500, Loss: 1.3338\n",
            "Epoch 1, Batch 2600, Loss: 1.0678\n",
            "Epoch 1, Batch 2700, Loss: 1.0276\n",
            "Epoch 1, Batch 2800, Loss: 0.8431\n",
            "Epoch 1, Batch 2900, Loss: 1.1242\n",
            "Epoch 1, Batch 3000, Loss: 0.7199\n",
            "Epoch 1, Batch 3100, Loss: 1.0718\n",
            "Epoch 1, Batch 3200, Loss: 1.0809\n",
            "Epoch 1, Batch 3300, Loss: 1.0922\n",
            "Epoch 1, Batch 3400, Loss: 1.1362\n",
            "Epoch 1, Batch 3500, Loss: 1.3834\n",
            "Epoch 1, Batch 3600, Loss: 0.8417\n",
            "Epoch 1, Batch 3700, Loss: 2.2478\n",
            "Epoch 1, Batch 3800, Loss: 1.1363\n",
            "Epoch 1, Batch 3900, Loss: 0.8771\n",
            "Epoch 1, Batch 4000, Loss: 0.8121\n",
            "Epoch 1, Batch 4100, Loss: 1.5112\n",
            "Epoch 1, Batch 4200, Loss: 0.6320\n",
            "Epoch 1, Batch 4300, Loss: 0.9887\n",
            "Epoch 1, Batch 4400, Loss: 1.1745\n",
            "Epoch 1, Batch 4500, Loss: 0.8653\n",
            "Epoch 1, Batch 4600, Loss: 0.9337\n",
            "Epoch 1, Batch 4700, Loss: 0.9661\n",
            "Epoch 1, Batch 4800, Loss: 1.2086\n",
            "Epoch 1, Batch 4900, Loss: 0.8758\n",
            "Epoch 1, Batch 5000, Loss: 1.0176\n",
            "Epoch 1, Batch 5100, Loss: 1.2871\n",
            "Epoch 1, Batch 5200, Loss: 1.0384\n",
            "Epoch 1, Batch 5300, Loss: 0.9506\n",
            "Epoch 1, Batch 5400, Loss: 1.1765\n",
            "Epoch 1, Batch 5500, Loss: 0.8930\n",
            "Epoch 1, Batch 5600, Loss: 0.8984\n",
            "Epoch 1, Batch 5700, Loss: 0.8180\n",
            "Epoch 1, Batch 5800, Loss: 0.8920\n",
            "Epoch 1, Batch 5900, Loss: 0.8533\n",
            "Epoch 1, Batch 6000, Loss: 0.9541\n",
            "Epoch 1, Batch 6100, Loss: 0.8737\n",
            "Epoch 1, Batch 6200, Loss: 0.9639\n",
            "Epoch 1, Batch 6300, Loss: 1.0324\n",
            "Epoch 1, Batch 6400, Loss: 0.7096\n",
            "Epoch 1, Batch 6500, Loss: 1.2907\n",
            "Epoch 1, Batch 6600, Loss: 1.0900\n",
            "Epoch 1, Batch 6700, Loss: 1.0765\n",
            "Epoch 1, Batch 6800, Loss: 1.0472\n",
            "Epoch 1, Batch 6900, Loss: 0.9312\n",
            "Epoch 1, Batch 7000, Loss: 0.7670\n",
            "Epoch 1, Batch 7100, Loss: 1.0064\n",
            "Epoch 1, Batch 7200, Loss: 0.9021\n",
            "Epoch 1, Batch 7300, Loss: 0.9736\n",
            "Epoch 1, Batch 7400, Loss: 0.7862\n",
            "Epoch 1, Batch 7500, Loss: 0.6785\n",
            "Epoch 1, Batch 7600, Loss: 0.9949\n",
            "Epoch 1, Batch 7700, Loss: 0.8624\n",
            "Epoch 1, Batch 7800, Loss: 1.0568\n",
            "Epoch 1, Batch 7900, Loss: 1.7098\n",
            "Epoch 1, Batch 8000, Loss: 0.8944\n",
            "Epoch 1, Batch 8100, Loss: 1.8548\n",
            "Epoch 1, Batch 8200, Loss: 1.1287\n",
            "Epoch 1, Batch 8300, Loss: 1.0540\n",
            "Epoch 1, Batch 8400, Loss: 0.8419\n",
            "Epoch 1, Batch 8500, Loss: 0.8878\n",
            "Epoch 1, Batch 8600, Loss: 0.7128\n",
            "Epoch 1, Batch 8700, Loss: 0.6826\n",
            "Epoch 1, Batch 8800, Loss: 0.8041\n",
            "Epoch 1, Batch 8900, Loss: 0.9325\n",
            "Epoch 1, Batch 9000, Loss: 1.0823\n",
            "Epoch 1, Batch 9100, Loss: 0.9575\n",
            "Epoch 1, Batch 9200, Loss: 0.9654\n",
            "Epoch 1, Batch 9300, Loss: 0.8360\n",
            "Epoch 1, Batch 9400, Loss: 1.3051\n",
            "Epoch 1, Batch 9500, Loss: 1.3113\n",
            "Epoch 1, Batch 9600, Loss: 0.6741\n",
            "Epoch 1, Batch 9700, Loss: 1.1282\n",
            "Epoch 1, Batch 9800, Loss: 1.2638\n",
            "Epoch 1, Batch 9900, Loss: 1.2406\n",
            "Epoch 1, Batch 10000, Loss: 1.1030\n",
            "Epoch 1, Batch 10100, Loss: 1.2060\n",
            "Epoch 1, Batch 10200, Loss: 0.7675\n",
            "Epoch 1, Batch 10300, Loss: 0.9986\n",
            "Epoch 1, Batch 10400, Loss: 1.6738\n",
            "Epoch 1/10, Avg Loss: 1.0885\n",
            "Epoch 2, Batch 0, Loss: 0.8246\n",
            "Epoch 2, Batch 100, Loss: 0.7864\n",
            "Epoch 2, Batch 200, Loss: 0.8437\n",
            "Epoch 2, Batch 300, Loss: 0.9995\n",
            "Epoch 2, Batch 400, Loss: 0.3837\n",
            "Epoch 2, Batch 500, Loss: 0.9536\n",
            "Epoch 2, Batch 600, Loss: 0.9426\n",
            "Epoch 2, Batch 700, Loss: 1.5582\n",
            "Epoch 2, Batch 800, Loss: 1.2447\n",
            "Epoch 2, Batch 900, Loss: 0.7743\n",
            "Epoch 2, Batch 1000, Loss: 0.7339\n",
            "Epoch 2, Batch 1100, Loss: 0.9878\n",
            "Epoch 2, Batch 1200, Loss: 0.7420\n",
            "Epoch 2, Batch 1300, Loss: 0.7660\n",
            "Epoch 2, Batch 1400, Loss: 1.1706\n",
            "Epoch 2, Batch 1500, Loss: 0.8719\n",
            "Epoch 2, Batch 1600, Loss: 1.0505\n",
            "Epoch 2, Batch 1700, Loss: 0.9044\n",
            "Epoch 2, Batch 1800, Loss: 0.9499\n",
            "Epoch 2, Batch 1900, Loss: 0.6765\n",
            "Epoch 2, Batch 2000, Loss: 0.5084\n",
            "Epoch 2, Batch 2100, Loss: 0.5591\n",
            "Epoch 2, Batch 2200, Loss: 0.8694\n",
            "Epoch 2, Batch 2300, Loss: 0.5441\n",
            "Epoch 2, Batch 2400, Loss: 0.8805\n",
            "Epoch 2, Batch 2500, Loss: 0.7126\n",
            "Epoch 2, Batch 2600, Loss: 0.9294\n",
            "Epoch 2, Batch 2700, Loss: 0.7114\n",
            "Epoch 2, Batch 2800, Loss: 0.7850\n",
            "Epoch 2, Batch 2900, Loss: 1.1114\n",
            "Epoch 2, Batch 3000, Loss: 1.1398\n",
            "Epoch 2, Batch 3100, Loss: 0.7188\n",
            "Epoch 2, Batch 3200, Loss: 0.8314\n",
            "Epoch 2, Batch 3300, Loss: 0.8870\n",
            "Epoch 2, Batch 3400, Loss: 1.5277\n",
            "Epoch 2, Batch 3500, Loss: 0.8934\n",
            "Epoch 2, Batch 3600, Loss: 1.0661\n",
            "Epoch 2, Batch 3700, Loss: 0.7938\n",
            "Epoch 2, Batch 3800, Loss: 0.5833\n",
            "Epoch 2, Batch 3900, Loss: 1.1107\n",
            "Epoch 2, Batch 4000, Loss: 1.0107\n",
            "Epoch 2, Batch 4100, Loss: 0.6413\n",
            "Epoch 2, Batch 4200, Loss: 0.9168\n",
            "Epoch 2, Batch 4300, Loss: 1.1694\n",
            "Epoch 2, Batch 4400, Loss: 0.8561\n",
            "Epoch 2, Batch 4500, Loss: 1.1335\n",
            "Epoch 2, Batch 4600, Loss: 1.3141\n",
            "Epoch 2, Batch 4700, Loss: 0.7496\n",
            "Epoch 2, Batch 4800, Loss: 0.8211\n",
            "Epoch 2, Batch 4900, Loss: 0.8150\n",
            "Epoch 2, Batch 5000, Loss: 1.0343\n",
            "Epoch 2, Batch 5100, Loss: 0.7166\n",
            "Epoch 2, Batch 5200, Loss: 0.5472\n",
            "Epoch 2, Batch 5300, Loss: 0.9398\n",
            "Epoch 2, Batch 5400, Loss: 1.1610\n",
            "Epoch 2, Batch 5500, Loss: 1.1528\n",
            "Epoch 2, Batch 5600, Loss: 0.8398\n",
            "Epoch 2, Batch 5700, Loss: 0.9156\n",
            "Epoch 2, Batch 5800, Loss: 0.8727\n",
            "Epoch 2, Batch 5900, Loss: 1.4884\n",
            "Epoch 2, Batch 6000, Loss: 0.6381\n",
            "Epoch 2, Batch 6100, Loss: 1.6968\n",
            "Epoch 2, Batch 6200, Loss: 0.6325\n",
            "Epoch 2, Batch 6300, Loss: 0.8587\n",
            "Epoch 2, Batch 6400, Loss: 0.4008\n",
            "Epoch 2, Batch 6500, Loss: 1.3971\n",
            "Epoch 2, Batch 6600, Loss: 0.8631\n",
            "Epoch 2, Batch 6700, Loss: 0.9683\n",
            "Epoch 2, Batch 6800, Loss: 0.9048\n",
            "Epoch 2, Batch 6900, Loss: 0.9821\n",
            "Epoch 2, Batch 7000, Loss: 1.2941\n",
            "Epoch 2, Batch 7100, Loss: 0.7097\n",
            "Epoch 2, Batch 7200, Loss: 0.5767\n",
            "Epoch 2, Batch 7300, Loss: 0.7594\n",
            "Epoch 2, Batch 7400, Loss: 0.9489\n",
            "Epoch 2, Batch 7500, Loss: 1.1497\n",
            "Epoch 2, Batch 7600, Loss: 0.7166\n",
            "Epoch 2, Batch 7700, Loss: 3.3084\n",
            "Epoch 2, Batch 7800, Loss: 1.1822\n",
            "Epoch 2, Batch 7900, Loss: 1.0420\n",
            "Epoch 2, Batch 8000, Loss: 0.7039\n",
            "Epoch 2, Batch 8100, Loss: 2.7182\n",
            "Epoch 2, Batch 8200, Loss: 0.8457\n",
            "Epoch 2, Batch 8300, Loss: 1.3614\n",
            "Epoch 2, Batch 8400, Loss: 2.2272\n",
            "Epoch 2, Batch 8500, Loss: 0.8028\n",
            "Epoch 2, Batch 8600, Loss: 1.4905\n",
            "Epoch 2, Batch 8700, Loss: 0.8532\n",
            "Epoch 2, Batch 8800, Loss: 1.2406\n",
            "Epoch 2, Batch 8900, Loss: 0.8082\n",
            "Epoch 2, Batch 9000, Loss: 1.9199\n",
            "Epoch 2, Batch 9100, Loss: 0.6849\n",
            "Epoch 2, Batch 9200, Loss: 0.8395\n",
            "Epoch 2, Batch 9300, Loss: 0.9004\n",
            "Epoch 2, Batch 9400, Loss: 1.2367\n",
            "Epoch 2, Batch 9500, Loss: 0.8870\n",
            "Epoch 2, Batch 9600, Loss: 0.6123\n",
            "Epoch 2, Batch 9700, Loss: 0.8854\n",
            "Epoch 2, Batch 9800, Loss: 0.6695\n",
            "Epoch 2, Batch 9900, Loss: 0.6971\n",
            "Epoch 2, Batch 10000, Loss: 0.9302\n",
            "Epoch 2, Batch 10100, Loss: 0.6376\n",
            "Epoch 2, Batch 10200, Loss: 1.2016\n",
            "Epoch 2, Batch 10300, Loss: 0.8878\n",
            "Epoch 2, Batch 10400, Loss: 0.7515\n",
            "Epoch 2/10, Avg Loss: 0.9530\n",
            "Epoch 3, Batch 0, Loss: 0.7489\n",
            "Epoch 3, Batch 100, Loss: 0.8453\n",
            "Epoch 3, Batch 200, Loss: 1.1077\n",
            "Epoch 3, Batch 300, Loss: 0.6285\n",
            "Epoch 3, Batch 400, Loss: 0.7440\n",
            "Epoch 3, Batch 500, Loss: 1.1821\n",
            "Epoch 3, Batch 600, Loss: 0.9069\n",
            "Epoch 3, Batch 700, Loss: 0.5047\n",
            "Epoch 3, Batch 800, Loss: 0.8748\n",
            "Epoch 3, Batch 900, Loss: 0.8021\n",
            "Epoch 3, Batch 1000, Loss: 0.7879\n",
            "Epoch 3, Batch 1100, Loss: 0.7186\n",
            "Epoch 3, Batch 1200, Loss: 0.9732\n",
            "Epoch 3, Batch 1300, Loss: 2.4768\n",
            "Epoch 3, Batch 1400, Loss: 1.7884\n",
            "Epoch 3, Batch 1500, Loss: 0.8153\n",
            "Epoch 3, Batch 1600, Loss: 0.5118\n",
            "Epoch 3, Batch 1700, Loss: 0.9265\n",
            "Epoch 3, Batch 1800, Loss: 0.6762\n",
            "Epoch 3, Batch 1900, Loss: 0.6153\n",
            "Epoch 3, Batch 2000, Loss: 0.8684\n",
            "Epoch 3, Batch 2100, Loss: 0.9775\n",
            "Epoch 3, Batch 2200, Loss: 0.8889\n",
            "Epoch 3, Batch 2300, Loss: 0.7739\n",
            "Epoch 3, Batch 2400, Loss: 0.5550\n",
            "Epoch 3, Batch 2500, Loss: 1.0386\n",
            "Epoch 3, Batch 2600, Loss: 0.9390\n",
            "Epoch 3, Batch 2700, Loss: 0.8866\n",
            "Epoch 3, Batch 2800, Loss: 1.0228\n",
            "Epoch 3, Batch 2900, Loss: 0.7573\n",
            "Epoch 3, Batch 3000, Loss: 1.3775\n",
            "Epoch 3, Batch 3100, Loss: 0.6701\n",
            "Epoch 3, Batch 3200, Loss: 0.7145\n",
            "Epoch 3, Batch 3300, Loss: 0.7012\n",
            "Epoch 3, Batch 3400, Loss: 1.0941\n",
            "Epoch 3, Batch 3500, Loss: 0.9018\n",
            "Epoch 3, Batch 3600, Loss: 0.8879\n",
            "Epoch 3, Batch 3700, Loss: 0.9351\n",
            "Epoch 3, Batch 3800, Loss: 0.8758\n",
            "Epoch 3, Batch 3900, Loss: 0.7181\n",
            "Epoch 3, Batch 4000, Loss: 0.9789\n",
            "Epoch 3, Batch 4100, Loss: 0.8056\n",
            "Epoch 3, Batch 4200, Loss: 0.7862\n",
            "Epoch 3, Batch 4300, Loss: 0.7111\n",
            "Epoch 3, Batch 4400, Loss: 0.5528\n",
            "Epoch 3, Batch 4500, Loss: 0.6304\n",
            "Epoch 3, Batch 4600, Loss: 1.2820\n",
            "Epoch 3, Batch 4700, Loss: 2.2592\n",
            "Epoch 3, Batch 4800, Loss: 2.1349\n",
            "Epoch 3, Batch 4900, Loss: 1.2688\n",
            "Epoch 3, Batch 5000, Loss: 3.3778\n",
            "Epoch 3, Batch 5100, Loss: 1.1873\n",
            "Epoch 3, Batch 5200, Loss: 0.6423\n",
            "Epoch 3, Batch 5300, Loss: 1.4607\n",
            "Epoch 3, Batch 5400, Loss: 0.4076\n",
            "Epoch 3, Batch 5500, Loss: 1.0836\n",
            "Epoch 3, Batch 5600, Loss: 0.8316\n",
            "Epoch 3, Batch 5700, Loss: 1.0870\n",
            "Epoch 3, Batch 5800, Loss: 1.1500\n",
            "Epoch 3, Batch 5900, Loss: 1.1305\n",
            "Epoch 3, Batch 6000, Loss: 0.8586\n",
            "Epoch 3, Batch 6100, Loss: 0.5447\n",
            "Epoch 3, Batch 6200, Loss: 0.6901\n",
            "Epoch 3, Batch 6300, Loss: 0.6864\n",
            "Epoch 3, Batch 6400, Loss: 1.8049\n",
            "Epoch 3, Batch 6500, Loss: 0.8530\n",
            "Epoch 3, Batch 6600, Loss: 0.7090\n",
            "Epoch 3, Batch 6700, Loss: 1.4837\n",
            "Epoch 3, Batch 6800, Loss: 0.6711\n",
            "Epoch 3, Batch 6900, Loss: 1.2026\n",
            "Epoch 3, Batch 7000, Loss: 1.3506\n",
            "Epoch 3, Batch 7100, Loss: 0.9522\n",
            "Epoch 3, Batch 7200, Loss: 0.7768\n",
            "Epoch 3, Batch 7300, Loss: 1.2478\n",
            "Epoch 3, Batch 7400, Loss: 0.7081\n",
            "Epoch 3, Batch 7500, Loss: 0.5178\n",
            "Epoch 3, Batch 7600, Loss: 0.8026\n",
            "Epoch 3, Batch 7700, Loss: 0.6108\n",
            "Epoch 3, Batch 7800, Loss: 0.7303\n",
            "Epoch 3, Batch 7900, Loss: 0.8357\n",
            "Epoch 3, Batch 8000, Loss: 1.7447\n",
            "Epoch 3, Batch 8100, Loss: 0.5725\n",
            "Epoch 3, Batch 8200, Loss: 0.5835\n",
            "Epoch 3, Batch 8300, Loss: 0.8120\n",
            "Epoch 3, Batch 8400, Loss: 0.6434\n",
            "Epoch 3, Batch 8500, Loss: 3.3465\n",
            "Epoch 3, Batch 8600, Loss: 0.4498\n",
            "Epoch 3, Batch 8700, Loss: 0.7340\n",
            "Epoch 3, Batch 8800, Loss: 0.5259\n",
            "Epoch 3, Batch 8900, Loss: 0.8061\n",
            "Epoch 3, Batch 9000, Loss: 1.0176\n",
            "Epoch 3, Batch 9100, Loss: 1.8812\n",
            "Epoch 3, Batch 9200, Loss: 0.5006\n",
            "Epoch 3, Batch 9300, Loss: 0.8279\n",
            "Epoch 3, Batch 9400, Loss: 1.3011\n",
            "Epoch 3, Batch 9500, Loss: 1.0617\n",
            "Epoch 3, Batch 9600, Loss: 0.7900\n",
            "Epoch 3, Batch 9700, Loss: 0.4961\n",
            "Epoch 3, Batch 9800, Loss: 0.9032\n",
            "Epoch 3, Batch 9900, Loss: 0.6029\n",
            "Epoch 3, Batch 10000, Loss: 0.6581\n",
            "Epoch 3, Batch 10100, Loss: 1.2421\n",
            "Epoch 3, Batch 10200, Loss: 0.6553\n",
            "Epoch 3, Batch 10300, Loss: 0.7762\n",
            "Epoch 3, Batch 10400, Loss: 0.4336\n",
            "Epoch 3/10, Avg Loss: 0.8950\n",
            "Epoch 4, Batch 0, Loss: 0.7139\n",
            "Epoch 4, Batch 100, Loss: 0.6393\n",
            "Epoch 4, Batch 200, Loss: 0.6253\n",
            "Epoch 4, Batch 300, Loss: 0.3953\n",
            "Epoch 4, Batch 400, Loss: 0.7528\n",
            "Epoch 4, Batch 500, Loss: 0.6082\n",
            "Epoch 4, Batch 600, Loss: 0.6350\n",
            "Epoch 4, Batch 700, Loss: 0.4448\n",
            "Epoch 4, Batch 800, Loss: 1.1365\n",
            "Epoch 4, Batch 900, Loss: 0.7644\n",
            "Epoch 4, Batch 1000, Loss: 0.6750\n",
            "Epoch 4, Batch 1100, Loss: 0.4540\n",
            "Epoch 4, Batch 1200, Loss: 1.1093\n",
            "Epoch 4, Batch 1300, Loss: 1.3312\n",
            "Epoch 4, Batch 1400, Loss: 0.5619\n",
            "Epoch 4, Batch 1500, Loss: 0.6936\n",
            "Epoch 4, Batch 1600, Loss: 0.6095\n",
            "Epoch 4, Batch 1700, Loss: 1.0910\n",
            "Epoch 4, Batch 1800, Loss: 0.8953\n",
            "Epoch 4, Batch 1900, Loss: 1.2691\n",
            "Epoch 4, Batch 2000, Loss: 0.6678\n",
            "Epoch 4, Batch 2100, Loss: 0.7529\n",
            "Epoch 4, Batch 2200, Loss: 0.6046\n",
            "Epoch 4, Batch 2300, Loss: 1.0343\n",
            "Epoch 4, Batch 2400, Loss: 0.7092\n",
            "Epoch 4, Batch 2500, Loss: 1.0192\n",
            "Epoch 4, Batch 2600, Loss: 0.7235\n",
            "Epoch 4, Batch 2700, Loss: 1.1548\n",
            "Epoch 4, Batch 2800, Loss: 0.5854\n",
            "Epoch 4, Batch 2900, Loss: 1.0934\n",
            "Epoch 4, Batch 3000, Loss: 0.5594\n",
            "Epoch 4, Batch 3100, Loss: 0.9448\n",
            "Epoch 4, Batch 3200, Loss: 0.7805\n",
            "Epoch 4, Batch 3300, Loss: 0.6238\n",
            "Epoch 4, Batch 3400, Loss: 1.2264\n",
            "Epoch 4, Batch 3500, Loss: 0.7152\n",
            "Epoch 4, Batch 3600, Loss: 0.6672\n",
            "Epoch 4, Batch 3700, Loss: 0.8370\n",
            "Epoch 4, Batch 3800, Loss: 1.4032\n",
            "Epoch 4, Batch 3900, Loss: 0.7882\n",
            "Epoch 4, Batch 4000, Loss: 1.1292\n",
            "Epoch 4, Batch 4100, Loss: 0.8585\n",
            "Epoch 4, Batch 4200, Loss: 0.7296\n",
            "Epoch 4, Batch 4300, Loss: 0.8433\n",
            "Epoch 4, Batch 4400, Loss: 0.7107\n",
            "Epoch 4, Batch 4500, Loss: 1.1672\n",
            "Epoch 4, Batch 4600, Loss: 0.8699\n",
            "Epoch 4, Batch 4700, Loss: 0.8234\n",
            "Epoch 4, Batch 4800, Loss: 0.7450\n",
            "Epoch 4, Batch 4900, Loss: 0.5339\n",
            "Epoch 4, Batch 5000, Loss: 0.4973\n",
            "Epoch 4, Batch 5100, Loss: 0.7589\n",
            "Epoch 4, Batch 5200, Loss: 0.8453\n",
            "Epoch 4, Batch 5300, Loss: 0.4835\n",
            "Epoch 4, Batch 5400, Loss: 0.8007\n",
            "Epoch 4, Batch 5500, Loss: 0.7464\n",
            "Epoch 4, Batch 5600, Loss: 1.0752\n",
            "Epoch 4, Batch 5700, Loss: 0.8431\n",
            "Epoch 4, Batch 5800, Loss: 0.8167\n",
            "Epoch 4, Batch 5900, Loss: 0.6902\n",
            "Epoch 4, Batch 6000, Loss: 1.2476\n",
            "Epoch 4, Batch 6100, Loss: 0.5100\n",
            "Epoch 4, Batch 6200, Loss: 0.9660\n",
            "Epoch 4, Batch 6300, Loss: 0.8420\n",
            "Epoch 4, Batch 6400, Loss: 0.6596\n",
            "Epoch 4, Batch 6500, Loss: 0.7960\n",
            "Epoch 4, Batch 6600, Loss: 0.7849\n",
            "Epoch 4, Batch 6700, Loss: 1.2346\n",
            "Epoch 4, Batch 6800, Loss: 0.6552\n",
            "Epoch 4, Batch 6900, Loss: 0.7334\n",
            "Epoch 4, Batch 7000, Loss: 0.5068\n",
            "Epoch 4, Batch 7100, Loss: 0.8577\n",
            "Epoch 4, Batch 7200, Loss: 0.4281\n",
            "Epoch 4, Batch 7300, Loss: 0.6397\n",
            "Epoch 4, Batch 7400, Loss: 1.4705\n",
            "Epoch 4, Batch 7500, Loss: 0.6152\n",
            "Epoch 4, Batch 7600, Loss: 0.7229\n",
            "Epoch 4, Batch 7700, Loss: 0.8756\n",
            "Epoch 4, Batch 7800, Loss: 1.8260\n",
            "Epoch 4, Batch 7900, Loss: 0.7501\n",
            "Epoch 4, Batch 8000, Loss: 0.8482\n",
            "Epoch 4, Batch 8100, Loss: 1.1645\n",
            "Epoch 4, Batch 8200, Loss: 0.5638\n",
            "Epoch 4, Batch 8300, Loss: 0.8294\n",
            "Epoch 4, Batch 8400, Loss: 0.7694\n",
            "Epoch 4, Batch 8500, Loss: 1.2169\n",
            "Epoch 4, Batch 8600, Loss: 0.6735\n",
            "Epoch 4, Batch 8700, Loss: 0.7557\n",
            "Epoch 4, Batch 8800, Loss: 0.7644\n",
            "Epoch 4, Batch 8900, Loss: 0.8736\n",
            "Epoch 4, Batch 9000, Loss: 1.2153\n",
            "Epoch 4, Batch 9100, Loss: 0.5461\n",
            "Epoch 4, Batch 9200, Loss: 0.5823\n",
            "Epoch 4, Batch 9300, Loss: 1.3158\n",
            "Epoch 4, Batch 9400, Loss: 0.9200\n",
            "Epoch 4, Batch 9500, Loss: 0.6550\n",
            "Epoch 4, Batch 9600, Loss: 0.6338\n",
            "Epoch 4, Batch 9700, Loss: 0.5390\n",
            "Epoch 4, Batch 9800, Loss: 0.8208\n",
            "Epoch 4, Batch 9900, Loss: 0.4679\n",
            "Epoch 4, Batch 10000, Loss: 1.0446\n",
            "Epoch 4, Batch 10100, Loss: 0.7977\n",
            "Epoch 4, Batch 10200, Loss: 0.5958\n",
            "Epoch 4, Batch 10300, Loss: 0.6830\n",
            "Epoch 4, Batch 10400, Loss: 0.8952\n",
            "Epoch 4/10, Avg Loss: 0.8440\n",
            "Epoch 5, Batch 0, Loss: 0.8501\n",
            "Epoch 5, Batch 100, Loss: 0.8426\n",
            "Epoch 5, Batch 200, Loss: 0.8282\n",
            "Epoch 5, Batch 300, Loss: 0.7164\n",
            "Epoch 5, Batch 400, Loss: 0.8902\n",
            "Epoch 5, Batch 500, Loss: 0.7105\n",
            "Epoch 5, Batch 600, Loss: 0.9733\n",
            "Epoch 5, Batch 700, Loss: 0.7015\n",
            "Epoch 5, Batch 800, Loss: 0.3718\n",
            "Epoch 5, Batch 900, Loss: 0.4343\n",
            "Epoch 5, Batch 1000, Loss: 0.8364\n",
            "Epoch 5, Batch 1100, Loss: 0.6490\n",
            "Epoch 5, Batch 1200, Loss: 0.8833\n",
            "Epoch 5, Batch 1300, Loss: 1.0037\n",
            "Epoch 5, Batch 1400, Loss: 0.7573\n",
            "Epoch 5, Batch 1500, Loss: 0.8265\n",
            "Epoch 5, Batch 1600, Loss: 0.9609\n",
            "Epoch 5, Batch 1700, Loss: 1.5328\n",
            "Epoch 5, Batch 1800, Loss: 2.3179\n",
            "Epoch 5, Batch 1900, Loss: 0.3061\n",
            "Epoch 5, Batch 2000, Loss: 0.5282\n",
            "Epoch 5, Batch 2100, Loss: 0.6802\n",
            "Epoch 5, Batch 2200, Loss: 0.5311\n",
            "Epoch 5, Batch 2300, Loss: 1.4750\n",
            "Epoch 5, Batch 2400, Loss: 0.4634\n",
            "Epoch 5, Batch 2500, Loss: 0.4353\n",
            "Epoch 5, Batch 2600, Loss: 0.4053\n",
            "Epoch 5, Batch 2700, Loss: 0.5778\n",
            "Epoch 5, Batch 2800, Loss: 0.4152\n",
            "Epoch 5, Batch 2900, Loss: 0.5887\n",
            "Epoch 5, Batch 3000, Loss: 0.6927\n",
            "Epoch 5, Batch 3100, Loss: 0.5178\n",
            "Epoch 5, Batch 3200, Loss: 0.5958\n",
            "Epoch 5, Batch 3300, Loss: 0.8175\n",
            "Epoch 5, Batch 3400, Loss: 0.7551\n",
            "Epoch 5, Batch 3500, Loss: 0.3813\n",
            "Epoch 5, Batch 3600, Loss: 0.8328\n",
            "Epoch 5, Batch 3700, Loss: 0.8684\n",
            "Epoch 5, Batch 3800, Loss: 0.4907\n",
            "Epoch 5, Batch 3900, Loss: 0.8343\n",
            "Epoch 5, Batch 4000, Loss: 0.3241\n",
            "Epoch 5, Batch 4100, Loss: 0.4276\n",
            "Epoch 5, Batch 4200, Loss: 0.4940\n",
            "Epoch 5, Batch 4300, Loss: 1.1702\n",
            "Epoch 5, Batch 4400, Loss: 0.6811\n",
            "Epoch 5, Batch 4500, Loss: 1.2673\n",
            "Epoch 5, Batch 4600, Loss: 1.1561\n",
            "Epoch 5, Batch 4700, Loss: 0.6703\n",
            "Epoch 5, Batch 4800, Loss: 1.6394\n",
            "Epoch 5, Batch 4900, Loss: 0.6338\n",
            "Epoch 5, Batch 5000, Loss: 2.2264\n",
            "Epoch 5, Batch 5100, Loss: 0.4445\n",
            "Epoch 5, Batch 5200, Loss: 0.7166\n",
            "Epoch 5, Batch 5300, Loss: 1.1108\n",
            "Epoch 5, Batch 5400, Loss: 0.4917\n",
            "Epoch 5, Batch 5500, Loss: 1.2945\n",
            "Epoch 5, Batch 5600, Loss: 1.3439\n",
            "Epoch 5, Batch 5700, Loss: 1.0429\n",
            "Epoch 5, Batch 5800, Loss: 0.5714\n",
            "Epoch 5, Batch 5900, Loss: 0.6645\n",
            "Epoch 5, Batch 6000, Loss: 0.7283\n",
            "Epoch 5, Batch 6100, Loss: 0.5582\n",
            "Epoch 5, Batch 6200, Loss: 0.5571\n",
            "Epoch 5, Batch 6300, Loss: 0.8929\n",
            "Epoch 5, Batch 6400, Loss: 0.8683\n",
            "Epoch 5, Batch 6500, Loss: 0.5251\n",
            "Epoch 5, Batch 6600, Loss: 0.5982\n",
            "Epoch 5, Batch 6700, Loss: 0.7508\n",
            "Epoch 5, Batch 6800, Loss: 1.4077\n",
            "Epoch 5, Batch 6900, Loss: 1.0132\n",
            "Epoch 5, Batch 7000, Loss: 0.5659\n",
            "Epoch 5, Batch 7100, Loss: 1.0979\n",
            "Epoch 5, Batch 7200, Loss: 0.7926\n",
            "Epoch 5, Batch 7300, Loss: 0.8427\n",
            "Epoch 5, Batch 7400, Loss: 0.7251\n",
            "Epoch 5, Batch 7500, Loss: 0.6608\n",
            "Epoch 5, Batch 7600, Loss: 0.5751\n",
            "Epoch 5, Batch 7700, Loss: 0.6344\n",
            "Epoch 5, Batch 7800, Loss: 0.6079\n",
            "Epoch 5, Batch 7900, Loss: 0.7021\n",
            "Epoch 5, Batch 8000, Loss: 0.5527\n",
            "Epoch 5, Batch 8100, Loss: 1.1705\n",
            "Epoch 5, Batch 8200, Loss: 0.8007\n",
            "Epoch 5, Batch 8300, Loss: 0.8696\n",
            "Epoch 5, Batch 8400, Loss: 0.6368\n",
            "Epoch 5, Batch 8500, Loss: 0.7070\n",
            "Epoch 5, Batch 8600, Loss: 0.3503\n",
            "Epoch 5, Batch 8700, Loss: 0.4064\n",
            "Epoch 5, Batch 8800, Loss: 0.6564\n",
            "Epoch 5, Batch 8900, Loss: 0.7782\n",
            "Epoch 5, Batch 9000, Loss: 0.5894\n",
            "Epoch 5, Batch 9100, Loss: 0.4477\n",
            "Epoch 5, Batch 9200, Loss: 0.5587\n",
            "Epoch 5, Batch 9300, Loss: 0.6525\n",
            "Epoch 5, Batch 9400, Loss: 0.8978\n",
            "Epoch 5, Batch 9500, Loss: 0.9808\n",
            "Epoch 5, Batch 9600, Loss: 0.5620\n",
            "Epoch 5, Batch 9700, Loss: 0.5651\n",
            "Epoch 5, Batch 9800, Loss: 0.6581\n",
            "Epoch 5, Batch 9900, Loss: 0.4185\n",
            "Epoch 5, Batch 10000, Loss: 1.2087\n",
            "Epoch 5, Batch 10100, Loss: 0.6856\n",
            "Epoch 5, Batch 10200, Loss: 0.4840\n",
            "Epoch 5, Batch 10300, Loss: 0.5435\n",
            "Epoch 5, Batch 10400, Loss: 0.4248\n",
            "Epoch 5/10, Avg Loss: 0.7980\n",
            "Epoch 6, Batch 0, Loss: 0.6804\n",
            "Epoch 6, Batch 100, Loss: 0.5812\n",
            "Epoch 6, Batch 200, Loss: 0.9257\n",
            "Epoch 6, Batch 300, Loss: 0.4909\n",
            "Epoch 6, Batch 400, Loss: 0.7920\n",
            "Epoch 6, Batch 500, Loss: 0.8284\n",
            "Epoch 6, Batch 600, Loss: 0.5811\n",
            "Epoch 6, Batch 700, Loss: 0.3581\n",
            "Epoch 6, Batch 800, Loss: 0.4973\n",
            "Epoch 6, Batch 900, Loss: 0.8026\n",
            "Epoch 6, Batch 1000, Loss: 0.6716\n",
            "Epoch 6, Batch 1100, Loss: 0.2882\n",
            "Epoch 6, Batch 1200, Loss: 0.9658\n",
            "Epoch 6, Batch 1300, Loss: 0.6357\n",
            "Epoch 6, Batch 1400, Loss: 0.7886\n",
            "Epoch 6, Batch 1500, Loss: 0.9725\n",
            "Epoch 6, Batch 1600, Loss: 0.7378\n",
            "Epoch 6, Batch 1700, Loss: 0.4927\n",
            "Epoch 6, Batch 1800, Loss: 0.6436\n",
            "Epoch 6, Batch 1900, Loss: 0.8391\n",
            "Epoch 6, Batch 2000, Loss: 0.4097\n",
            "Epoch 6, Batch 2100, Loss: 0.7799\n",
            "Epoch 6, Batch 2200, Loss: 0.6496\n",
            "Epoch 6, Batch 2300, Loss: 0.7752\n",
            "Epoch 6, Batch 2400, Loss: 0.6135\n",
            "Epoch 6, Batch 2500, Loss: 0.8411\n",
            "Epoch 6, Batch 2600, Loss: 0.5260\n",
            "Epoch 6, Batch 2700, Loss: 0.6987\n",
            "Epoch 6, Batch 2800, Loss: 0.5727\n",
            "Epoch 6, Batch 2900, Loss: 0.5165\n",
            "Epoch 6, Batch 3000, Loss: 0.4805\n",
            "Epoch 6, Batch 3100, Loss: 0.7852\n",
            "Epoch 6, Batch 3200, Loss: 1.2477\n",
            "Epoch 6, Batch 3300, Loss: 0.8849\n",
            "Epoch 6, Batch 3400, Loss: 0.7756\n",
            "Epoch 6, Batch 3500, Loss: 0.5786\n",
            "Epoch 6, Batch 3600, Loss: 0.7290\n",
            "Epoch 6, Batch 3700, Loss: 0.6802\n",
            "Epoch 6, Batch 3800, Loss: 0.4320\n",
            "Epoch 6, Batch 3900, Loss: 0.7394\n",
            "Epoch 6, Batch 4000, Loss: 0.6757\n",
            "Epoch 6, Batch 4100, Loss: 0.5643\n",
            "Epoch 6, Batch 4200, Loss: 2.7368\n",
            "Epoch 6, Batch 4300, Loss: 0.4635\n",
            "Epoch 6, Batch 4400, Loss: 0.9192\n",
            "Epoch 6, Batch 4500, Loss: 0.8771\n",
            "Epoch 6, Batch 4600, Loss: 0.5127\n",
            "Epoch 6, Batch 4700, Loss: 0.7989\n",
            "Epoch 6, Batch 4800, Loss: 0.8275\n",
            "Epoch 6, Batch 4900, Loss: 0.3439\n",
            "Epoch 6, Batch 5000, Loss: 1.4082\n",
            "Epoch 6, Batch 5100, Loss: 1.5848\n",
            "Epoch 6, Batch 5200, Loss: 0.3821\n",
            "Epoch 6, Batch 5300, Loss: 0.9037\n",
            "Epoch 6, Batch 5400, Loss: 0.5017\n",
            "Epoch 6, Batch 5500, Loss: 0.4486\n",
            "Epoch 6, Batch 5600, Loss: 0.6173\n",
            "Epoch 6, Batch 5700, Loss: 0.6462\n",
            "Epoch 6, Batch 5800, Loss: 0.7353\n",
            "Epoch 6, Batch 5900, Loss: 1.2975\n",
            "Epoch 6, Batch 6000, Loss: 0.4988\n",
            "Epoch 6, Batch 6100, Loss: 0.5249\n",
            "Epoch 6, Batch 6200, Loss: 0.5877\n",
            "Epoch 6, Batch 6300, Loss: 0.8776\n",
            "Epoch 6, Batch 6400, Loss: 0.5637\n",
            "Epoch 6, Batch 6500, Loss: 0.5979\n",
            "Epoch 6, Batch 6600, Loss: 0.7982\n",
            "Epoch 6, Batch 6700, Loss: 0.6942\n",
            "Epoch 6, Batch 6800, Loss: 0.7157\n",
            "Epoch 6, Batch 6900, Loss: 0.5984\n",
            "Epoch 6, Batch 7000, Loss: 0.9156\n",
            "Epoch 6, Batch 7100, Loss: 0.9831\n",
            "Epoch 6, Batch 7200, Loss: 0.8076\n",
            "Epoch 6, Batch 7300, Loss: 0.6128\n",
            "Epoch 6, Batch 7400, Loss: 0.5736\n",
            "Epoch 6, Batch 7500, Loss: 0.3976\n",
            "Epoch 6, Batch 7600, Loss: 0.8875\n",
            "Epoch 6, Batch 7700, Loss: 0.4029\n",
            "Epoch 6, Batch 7800, Loss: 1.0820\n",
            "Epoch 6, Batch 7900, Loss: 0.8153\n",
            "Epoch 6, Batch 8000, Loss: 0.9856\n",
            "Epoch 6, Batch 8100, Loss: 0.3415\n",
            "Epoch 6, Batch 8200, Loss: 1.2719\n",
            "Epoch 6, Batch 8300, Loss: 0.6869\n",
            "Epoch 6, Batch 8400, Loss: 0.3262\n",
            "Epoch 6, Batch 8500, Loss: 1.1552\n",
            "Epoch 6, Batch 8600, Loss: 0.7001\n",
            "Epoch 6, Batch 8700, Loss: 1.0539\n",
            "Epoch 6, Batch 8800, Loss: 0.3792\n",
            "Epoch 6, Batch 8900, Loss: 0.5471\n",
            "Epoch 6, Batch 9000, Loss: 2.1122\n",
            "Epoch 6, Batch 9100, Loss: 1.2406\n",
            "Epoch 6, Batch 9200, Loss: 0.9900\n",
            "Epoch 6, Batch 9300, Loss: 0.7091\n",
            "Epoch 6, Batch 9400, Loss: 0.6947\n",
            "Epoch 6, Batch 9500, Loss: 0.6654\n",
            "Epoch 6, Batch 9600, Loss: 0.3220\n",
            "Epoch 6, Batch 9700, Loss: 0.7011\n",
            "Epoch 6, Batch 9800, Loss: 0.6186\n",
            "Epoch 6, Batch 9900, Loss: 1.0189\n",
            "Epoch 6, Batch 10000, Loss: 0.4438\n",
            "Epoch 6, Batch 10100, Loss: 0.8006\n",
            "Epoch 6, Batch 10200, Loss: 0.5624\n",
            "Epoch 6, Batch 10300, Loss: 0.6822\n",
            "Epoch 6, Batch 10400, Loss: 0.3483\n",
            "Epoch 6/10, Avg Loss: 0.7564\n",
            "Epoch 7, Batch 0, Loss: 0.5166\n",
            "Epoch 7, Batch 100, Loss: 0.7074\n",
            "Epoch 7, Batch 200, Loss: 0.7249\n",
            "Epoch 7, Batch 300, Loss: 0.6234\n",
            "Epoch 7, Batch 400, Loss: 0.7622\n",
            "Epoch 7, Batch 500, Loss: 3.2603\n",
            "Epoch 7, Batch 600, Loss: 1.0676\n",
            "Epoch 7, Batch 700, Loss: 0.4790\n",
            "Epoch 7, Batch 800, Loss: 0.6807\n",
            "Epoch 7, Batch 900, Loss: 0.6950\n",
            "Epoch 7, Batch 1000, Loss: 0.2894\n",
            "Epoch 7, Batch 1100, Loss: 0.2763\n",
            "Epoch 7, Batch 1200, Loss: 0.5608\n",
            "Epoch 7, Batch 1300, Loss: 0.4066\n",
            "Epoch 7, Batch 1400, Loss: 0.2664\n",
            "Epoch 7, Batch 1500, Loss: 0.4776\n",
            "Epoch 7, Batch 1600, Loss: 0.6926\n",
            "Epoch 7, Batch 1700, Loss: 0.4794\n",
            "Epoch 7, Batch 1800, Loss: 0.5998\n",
            "Epoch 7, Batch 1900, Loss: 0.7829\n",
            "Epoch 7, Batch 2000, Loss: 0.3805\n",
            "Epoch 7, Batch 2100, Loss: 0.3641\n",
            "Epoch 7, Batch 2200, Loss: 0.9415\n",
            "Epoch 7, Batch 2300, Loss: 0.5684\n",
            "Epoch 7, Batch 2400, Loss: 1.3382\n",
            "Epoch 7, Batch 2500, Loss: 0.5072\n",
            "Epoch 7, Batch 2600, Loss: 0.8732\n",
            "Epoch 7, Batch 2700, Loss: 0.6130\n",
            "Epoch 7, Batch 2800, Loss: 3.0265\n",
            "Epoch 7, Batch 2900, Loss: 0.4958\n",
            "Epoch 7, Batch 3000, Loss: 0.8811\n",
            "Epoch 7, Batch 3100, Loss: 0.6485\n",
            "Epoch 7, Batch 3200, Loss: 0.4405\n",
            "Epoch 7, Batch 3300, Loss: 0.7993\n",
            "Epoch 7, Batch 3400, Loss: 0.4414\n",
            "Epoch 7, Batch 3500, Loss: 0.5858\n",
            "Epoch 7, Batch 3600, Loss: 0.8218\n",
            "Epoch 7, Batch 3700, Loss: 0.4532\n",
            "Epoch 7, Batch 3800, Loss: 0.7082\n",
            "Epoch 7, Batch 3900, Loss: 0.6066\n",
            "Epoch 7, Batch 4000, Loss: 0.9272\n",
            "Epoch 7, Batch 4100, Loss: 0.8220\n",
            "Epoch 7, Batch 4200, Loss: 0.5585\n",
            "Epoch 7, Batch 4300, Loss: 1.0980\n",
            "Epoch 7, Batch 4400, Loss: 0.5950\n",
            "Epoch 7, Batch 4500, Loss: 0.7632\n",
            "Epoch 7, Batch 4600, Loss: 0.8786\n",
            "Epoch 7, Batch 4700, Loss: 0.4897\n",
            "Epoch 7, Batch 4800, Loss: 0.7614\n",
            "Epoch 7, Batch 4900, Loss: 0.4754\n",
            "Epoch 7, Batch 5000, Loss: 0.5229\n",
            "Epoch 7, Batch 5100, Loss: 0.6679\n",
            "Epoch 7, Batch 5200, Loss: 0.6884\n",
            "Epoch 7, Batch 5300, Loss: 0.7039\n",
            "Epoch 7, Batch 5400, Loss: 0.3876\n",
            "Epoch 7, Batch 5500, Loss: 0.5249\n",
            "Epoch 7, Batch 5600, Loss: 0.7932\n",
            "Epoch 7, Batch 5700, Loss: 0.9780\n",
            "Epoch 7, Batch 5800, Loss: 0.4086\n",
            "Epoch 7, Batch 5900, Loss: 0.8982\n",
            "Epoch 7, Batch 6000, Loss: 1.1539\n",
            "Epoch 7, Batch 6100, Loss: 0.6641\n",
            "Epoch 7, Batch 6200, Loss: 0.6869\n",
            "Epoch 7, Batch 6300, Loss: 1.5547\n",
            "Epoch 7, Batch 6400, Loss: 0.3373\n",
            "Epoch 7, Batch 6500, Loss: 0.4520\n",
            "Epoch 7, Batch 6600, Loss: 0.3824\n",
            "Epoch 7, Batch 6700, Loss: 0.4523\n",
            "Epoch 7, Batch 6800, Loss: 0.5368\n",
            "Epoch 7, Batch 6900, Loss: 0.5539\n",
            "Epoch 7, Batch 7000, Loss: 0.2528\n",
            "Epoch 7, Batch 7100, Loss: 1.1507\n",
            "Epoch 7, Batch 7200, Loss: 0.4250\n",
            "Epoch 7, Batch 7300, Loss: 0.7463\n",
            "Epoch 7, Batch 7400, Loss: 0.3131\n",
            "Epoch 7, Batch 7500, Loss: 1.8076\n",
            "Epoch 7, Batch 7600, Loss: 0.3750\n",
            "Epoch 7, Batch 7700, Loss: 0.5136\n",
            "Epoch 7, Batch 7800, Loss: 0.9823\n",
            "Epoch 7, Batch 7900, Loss: 2.6451\n",
            "Epoch 7, Batch 8000, Loss: 0.6099\n",
            "Epoch 7, Batch 8100, Loss: 0.8005\n",
            "Epoch 7, Batch 8200, Loss: 0.8799\n",
            "Epoch 7, Batch 8300, Loss: 0.5208\n",
            "Epoch 7, Batch 8400, Loss: 0.6976\n",
            "Epoch 7, Batch 8500, Loss: 0.6399\n",
            "Epoch 7, Batch 8600, Loss: 0.6128\n",
            "Epoch 7, Batch 8700, Loss: 0.5370\n",
            "Epoch 7, Batch 8800, Loss: 0.4608\n",
            "Epoch 7, Batch 8900, Loss: 0.5327\n",
            "Epoch 7, Batch 9000, Loss: 0.5737\n",
            "Epoch 7, Batch 9100, Loss: 1.3597\n",
            "Epoch 7, Batch 9200, Loss: 0.6850\n",
            "Epoch 7, Batch 9300, Loss: 0.8544\n",
            "Epoch 7, Batch 9400, Loss: 0.6215\n",
            "Epoch 7, Batch 9500, Loss: 0.5630\n",
            "Epoch 7, Batch 9600, Loss: 0.5698\n",
            "Epoch 7, Batch 9700, Loss: 0.5778\n",
            "Epoch 7, Batch 9800, Loss: 0.7241\n",
            "Epoch 7, Batch 9900, Loss: 0.3733\n",
            "Epoch 7, Batch 10000, Loss: 0.3994\n",
            "Epoch 7, Batch 10100, Loss: 0.5395\n",
            "Epoch 7, Batch 10200, Loss: 1.0672\n",
            "Epoch 7, Batch 10300, Loss: 0.5252\n",
            "Epoch 7, Batch 10400, Loss: 0.3554\n",
            "Epoch 7/10, Avg Loss: 0.7159\n",
            "Epoch 8, Batch 0, Loss: 0.4715\n",
            "Epoch 8, Batch 100, Loss: 0.6202\n",
            "Epoch 8, Batch 200, Loss: 1.3963\n",
            "Epoch 8, Batch 300, Loss: 0.5282\n",
            "Epoch 8, Batch 400, Loss: 0.7596\n",
            "Epoch 8, Batch 500, Loss: 0.5358\n",
            "Epoch 8, Batch 600, Loss: 0.5219\n",
            "Epoch 8, Batch 700, Loss: 0.5590\n",
            "Epoch 8, Batch 800, Loss: 0.7121\n",
            "Epoch 8, Batch 900, Loss: 0.3735\n",
            "Epoch 8, Batch 1000, Loss: 0.9496\n",
            "Epoch 8, Batch 1100, Loss: 0.7301\n",
            "Epoch 8, Batch 1200, Loss: 0.6243\n",
            "Epoch 8, Batch 1300, Loss: 0.7426\n",
            "Epoch 8, Batch 1400, Loss: 0.5613\n",
            "Epoch 8, Batch 1500, Loss: 0.7115\n",
            "Epoch 8, Batch 1600, Loss: 0.6117\n",
            "Epoch 8, Batch 1700, Loss: 0.6164\n",
            "Epoch 8, Batch 1800, Loss: 1.9365\n",
            "Epoch 8, Batch 1900, Loss: 0.4041\n",
            "Epoch 8, Batch 2000, Loss: 0.6656\n",
            "Epoch 8, Batch 2100, Loss: 0.6549\n",
            "Epoch 8, Batch 2200, Loss: 0.4251\n",
            "Epoch 8, Batch 2300, Loss: 1.0933\n",
            "Epoch 8, Batch 2400, Loss: 0.3904\n",
            "Epoch 8, Batch 2500, Loss: 0.4822\n",
            "Epoch 8, Batch 2600, Loss: 0.7464\n",
            "Epoch 8, Batch 2700, Loss: 0.3714\n",
            "Epoch 8, Batch 2800, Loss: 0.3722\n",
            "Epoch 8, Batch 2900, Loss: 0.2975\n",
            "Epoch 8, Batch 3000, Loss: 0.8941\n",
            "Epoch 8, Batch 3100, Loss: 0.4305\n",
            "Epoch 8, Batch 3200, Loss: 0.6595\n",
            "Epoch 8, Batch 3300, Loss: 1.4012\n",
            "Epoch 8, Batch 3400, Loss: 0.3112\n",
            "Epoch 8, Batch 3500, Loss: 0.5289\n",
            "Epoch 8, Batch 3600, Loss: 0.6946\n",
            "Epoch 8, Batch 3700, Loss: 0.7911\n",
            "Epoch 8, Batch 3800, Loss: 1.2008\n",
            "Epoch 8, Batch 3900, Loss: 0.5041\n",
            "Epoch 8, Batch 4000, Loss: 0.4402\n",
            "Epoch 8, Batch 4100, Loss: 0.7801\n",
            "Epoch 8, Batch 4200, Loss: 0.6624\n",
            "Epoch 8, Batch 4300, Loss: 0.5406\n",
            "Epoch 8, Batch 4400, Loss: 0.6071\n",
            "Epoch 8, Batch 4500, Loss: 0.3857\n",
            "Epoch 8, Batch 4600, Loss: 0.3221\n",
            "Epoch 8, Batch 4700, Loss: 0.6776\n",
            "Epoch 8, Batch 4800, Loss: 0.4862\n",
            "Epoch 8, Batch 4900, Loss: 0.4079\n",
            "Epoch 8, Batch 5000, Loss: 0.4403\n",
            "Epoch 8, Batch 5100, Loss: 1.0989\n",
            "Epoch 8, Batch 5200, Loss: 0.3586\n",
            "Epoch 8, Batch 5300, Loss: 0.4410\n",
            "Epoch 8, Batch 5400, Loss: 0.4147\n",
            "Epoch 8, Batch 5500, Loss: 0.8009\n",
            "Epoch 8, Batch 5600, Loss: 0.3916\n",
            "Epoch 8, Batch 5700, Loss: 0.3690\n",
            "Epoch 8, Batch 5800, Loss: 0.5321\n",
            "Epoch 8, Batch 5900, Loss: 0.1788\n",
            "Epoch 8, Batch 6000, Loss: 0.5691\n",
            "Epoch 8, Batch 6100, Loss: 1.4411\n",
            "Epoch 8, Batch 6200, Loss: 0.2786\n",
            "Epoch 8, Batch 6300, Loss: 0.6099\n",
            "Epoch 8, Batch 6400, Loss: 0.3924\n",
            "Epoch 8, Batch 6500, Loss: 0.6753\n",
            "Epoch 8, Batch 6600, Loss: 0.7177\n",
            "Epoch 8, Batch 6700, Loss: 1.2813\n",
            "Epoch 8, Batch 6800, Loss: 0.3661\n",
            "Epoch 8, Batch 6900, Loss: 0.3338\n",
            "Epoch 8, Batch 7000, Loss: 0.6822\n",
            "Epoch 8, Batch 7100, Loss: 0.5245\n",
            "Epoch 8, Batch 7200, Loss: 0.4560\n",
            "Epoch 8, Batch 7300, Loss: 0.8697\n",
            "Epoch 8, Batch 7400, Loss: 0.8418\n",
            "Epoch 8, Batch 7500, Loss: 0.8180\n",
            "Epoch 8, Batch 7600, Loss: 0.6479\n",
            "Epoch 8, Batch 7700, Loss: 0.6525\n",
            "Epoch 8, Batch 7800, Loss: 0.3869\n",
            "Epoch 8, Batch 7900, Loss: 0.4904\n",
            "Epoch 8, Batch 8000, Loss: 0.4091\n",
            "Epoch 8, Batch 8100, Loss: 0.6483\n",
            "Epoch 8, Batch 8200, Loss: 0.6817\n",
            "Epoch 8, Batch 8300, Loss: 0.8009\n",
            "Epoch 8, Batch 8400, Loss: 0.4060\n",
            "Epoch 8, Batch 8500, Loss: 0.5283\n",
            "Epoch 8, Batch 8600, Loss: 0.9690\n",
            "Epoch 8, Batch 8700, Loss: 1.1860\n",
            "Epoch 8, Batch 8800, Loss: 0.3555\n",
            "Epoch 8, Batch 8900, Loss: 0.6334\n",
            "Epoch 8, Batch 9000, Loss: 0.8663\n",
            "Epoch 8, Batch 9100, Loss: 0.8531\n",
            "Epoch 8, Batch 9200, Loss: 1.6488\n",
            "Epoch 8, Batch 9300, Loss: 0.6056\n",
            "Epoch 8, Batch 9400, Loss: 0.5092\n",
            "Epoch 8, Batch 9500, Loss: 0.7738\n",
            "Epoch 8, Batch 9600, Loss: 0.7982\n",
            "Epoch 8, Batch 9700, Loss: 0.3721\n",
            "Epoch 8, Batch 9800, Loss: 0.8706\n",
            "Epoch 8, Batch 9900, Loss: 1.0807\n",
            "Epoch 8, Batch 10000, Loss: 0.4966\n",
            "Epoch 8, Batch 10100, Loss: 1.0495\n",
            "Epoch 8, Batch 10200, Loss: 0.5229\n",
            "Epoch 8, Batch 10300, Loss: 0.4644\n",
            "Epoch 8, Batch 10400, Loss: 0.6982\n",
            "Epoch 8/10, Avg Loss: 0.6726\n",
            "Epoch 9, Batch 0, Loss: 0.4284\n",
            "Epoch 9, Batch 100, Loss: 0.4955\n",
            "Epoch 9, Batch 200, Loss: 0.5086\n",
            "Epoch 9, Batch 300, Loss: 0.6295\n",
            "Epoch 9, Batch 400, Loss: 0.4961\n",
            "Epoch 9, Batch 500, Loss: 0.2577\n",
            "Epoch 9, Batch 600, Loss: 0.4528\n",
            "Epoch 9, Batch 700, Loss: 0.4298\n",
            "Epoch 9, Batch 800, Loss: 0.6706\n",
            "Epoch 9, Batch 900, Loss: 0.4585\n",
            "Epoch 9, Batch 1000, Loss: 1.2860\n",
            "Epoch 9, Batch 1100, Loss: 0.3884\n",
            "Epoch 9, Batch 1200, Loss: 0.5421\n",
            "Epoch 9, Batch 1300, Loss: 0.3198\n",
            "Epoch 9, Batch 1400, Loss: 1.2400\n",
            "Epoch 9, Batch 1500, Loss: 0.4190\n",
            "Epoch 9, Batch 1600, Loss: 0.7080\n",
            "Epoch 9, Batch 1700, Loss: 0.4025\n",
            "Epoch 9, Batch 1800, Loss: 0.5252\n",
            "Epoch 9, Batch 1900, Loss: 0.5974\n",
            "Epoch 9, Batch 2000, Loss: 0.4335\n",
            "Epoch 9, Batch 2100, Loss: 0.4244\n",
            "Epoch 9, Batch 2200, Loss: 0.5266\n",
            "Epoch 9, Batch 2300, Loss: 0.5910\n",
            "Epoch 9, Batch 2400, Loss: 0.8494\n",
            "Epoch 9, Batch 2500, Loss: 0.7093\n",
            "Epoch 9, Batch 2600, Loss: 0.2513\n",
            "Epoch 9, Batch 2700, Loss: 0.3276\n",
            "Epoch 9, Batch 2800, Loss: 0.9746\n",
            "Epoch 9, Batch 2900, Loss: 0.5846\n",
            "Epoch 9, Batch 3000, Loss: 0.7238\n",
            "Epoch 9, Batch 3100, Loss: 0.2901\n",
            "Epoch 9, Batch 3200, Loss: 0.8096\n",
            "Epoch 9, Batch 3300, Loss: 0.6779\n",
            "Epoch 9, Batch 3400, Loss: 0.6266\n",
            "Epoch 9, Batch 3500, Loss: 0.6798\n",
            "Epoch 9, Batch 3600, Loss: 0.7771\n",
            "Epoch 9, Batch 3700, Loss: 0.4336\n",
            "Epoch 9, Batch 3800, Loss: 0.8296\n",
            "Epoch 9, Batch 3900, Loss: 0.5143\n",
            "Epoch 9, Batch 4000, Loss: 0.5843\n",
            "Epoch 9, Batch 4100, Loss: 0.4339\n",
            "Epoch 9, Batch 4200, Loss: 0.4569\n",
            "Epoch 9, Batch 4300, Loss: 1.2764\n",
            "Epoch 9, Batch 4400, Loss: 0.7026\n",
            "Epoch 9, Batch 4500, Loss: 0.4064\n",
            "Epoch 9, Batch 4600, Loss: 0.8003\n",
            "Epoch 9, Batch 4700, Loss: 1.0089\n",
            "Epoch 9, Batch 4800, Loss: 0.6146\n",
            "Epoch 9, Batch 4900, Loss: 0.9000\n",
            "Epoch 9, Batch 5000, Loss: 1.7641\n",
            "Epoch 9, Batch 5100, Loss: 1.1071\n",
            "Epoch 9, Batch 5200, Loss: 1.3979\n",
            "Epoch 9, Batch 5300, Loss: 0.3719\n",
            "Epoch 9, Batch 5400, Loss: 0.9098\n",
            "Epoch 9, Batch 5500, Loss: 0.2978\n",
            "Epoch 9, Batch 5600, Loss: 0.5753\n",
            "Epoch 9, Batch 5700, Loss: 1.4682\n",
            "Epoch 9, Batch 5800, Loss: 0.3892\n",
            "Epoch 9, Batch 5900, Loss: 0.3413\n",
            "Epoch 9, Batch 6000, Loss: 0.4459\n",
            "Epoch 9, Batch 6100, Loss: 0.8396\n",
            "Epoch 9, Batch 6200, Loss: 0.6470\n",
            "Epoch 9, Batch 6300, Loss: 0.5238\n",
            "Epoch 9, Batch 6400, Loss: 0.6522\n",
            "Epoch 9, Batch 6500, Loss: 0.6833\n",
            "Epoch 9, Batch 6600, Loss: 0.3304\n",
            "Epoch 9, Batch 6700, Loss: 0.4565\n",
            "Epoch 9, Batch 6800, Loss: 0.7227\n",
            "Epoch 9, Batch 6900, Loss: 0.3766\n",
            "Epoch 9, Batch 7000, Loss: 0.3727\n",
            "Epoch 9, Batch 7100, Loss: 0.3342\n",
            "Epoch 9, Batch 7200, Loss: 0.4149\n",
            "Epoch 9, Batch 7300, Loss: 0.7986\n",
            "Epoch 9, Batch 7400, Loss: 0.9098\n",
            "Epoch 9, Batch 7500, Loss: 0.5878\n",
            "Epoch 9, Batch 7600, Loss: 0.5483\n",
            "Epoch 9, Batch 7700, Loss: 0.3841\n",
            "Epoch 9, Batch 7800, Loss: 0.5426\n",
            "Epoch 9, Batch 7900, Loss: 0.4051\n",
            "Epoch 9, Batch 8000, Loss: 0.3352\n",
            "Epoch 9, Batch 8100, Loss: 0.3295\n",
            "Epoch 9, Batch 8200, Loss: 0.4634\n",
            "Epoch 9, Batch 8300, Loss: 0.5287\n",
            "Epoch 9, Batch 8400, Loss: 0.6731\n",
            "Epoch 9, Batch 8500, Loss: 0.3603\n",
            "Epoch 9, Batch 8600, Loss: 1.1579\n",
            "Epoch 9, Batch 8700, Loss: 0.4575\n",
            "Epoch 9, Batch 8800, Loss: 0.3552\n",
            "Epoch 9, Batch 8900, Loss: 0.4552\n",
            "Epoch 9, Batch 9000, Loss: 0.6206\n",
            "Epoch 9, Batch 9100, Loss: 0.5416\n",
            "Epoch 9, Batch 9200, Loss: 0.5251\n",
            "Epoch 9, Batch 9300, Loss: 0.4056\n",
            "Epoch 9, Batch 9400, Loss: 0.8830\n",
            "Epoch 9, Batch 9500, Loss: 0.6728\n",
            "Epoch 9, Batch 9600, Loss: 0.5623\n",
            "Epoch 9, Batch 9700, Loss: 0.1783\n",
            "Epoch 9, Batch 9800, Loss: 1.7853\n",
            "Epoch 9, Batch 9900, Loss: 0.4304\n",
            "Epoch 9, Batch 10000, Loss: 0.9733\n",
            "Epoch 9, Batch 10100, Loss: 1.4842\n",
            "Epoch 9, Batch 10200, Loss: 0.9179\n",
            "Epoch 9, Batch 10300, Loss: 0.5683\n",
            "Epoch 9, Batch 10400, Loss: 1.1069\n",
            "Epoch 9/10, Avg Loss: 0.6360\n",
            "Epoch 10, Batch 0, Loss: 0.4149\n",
            "Epoch 10, Batch 100, Loss: 0.3989\n",
            "Epoch 10, Batch 200, Loss: 0.1854\n",
            "Epoch 10, Batch 300, Loss: 1.0928\n",
            "Epoch 10, Batch 400, Loss: 1.5794\n",
            "Epoch 10, Batch 500, Loss: 0.3558\n",
            "Epoch 10, Batch 600, Loss: 0.4165\n",
            "Epoch 10, Batch 700, Loss: 2.5403\n",
            "Epoch 10, Batch 800, Loss: 0.6934\n",
            "Epoch 10, Batch 900, Loss: 0.3639\n",
            "Epoch 10, Batch 1000, Loss: 0.4920\n",
            "Epoch 10, Batch 1100, Loss: 0.2661\n",
            "Epoch 10, Batch 1200, Loss: 0.6500\n",
            "Epoch 10, Batch 1300, Loss: 0.4799\n",
            "Epoch 10, Batch 1400, Loss: 0.3088\n",
            "Epoch 10, Batch 1500, Loss: 0.2279\n",
            "Epoch 10, Batch 1600, Loss: 0.2293\n",
            "Epoch 10, Batch 1700, Loss: 0.2336\n",
            "Epoch 10, Batch 1800, Loss: 0.5389\n",
            "Epoch 10, Batch 1900, Loss: 0.3790\n",
            "Epoch 10, Batch 2000, Loss: 0.4430\n",
            "Epoch 10, Batch 2100, Loss: 0.1580\n",
            "Epoch 10, Batch 2200, Loss: 0.4591\n",
            "Epoch 10, Batch 2300, Loss: 0.7035\n",
            "Epoch 10, Batch 2400, Loss: 0.2770\n",
            "Epoch 10, Batch 2500, Loss: 0.5326\n",
            "Epoch 10, Batch 2600, Loss: 0.3263\n",
            "Epoch 10, Batch 2700, Loss: 0.7550\n",
            "Epoch 10, Batch 2800, Loss: 0.3902\n",
            "Epoch 10, Batch 2900, Loss: 0.6629\n",
            "Epoch 10, Batch 3000, Loss: 0.1149\n",
            "Epoch 10, Batch 3100, Loss: 0.6792\n",
            "Epoch 10, Batch 3200, Loss: 0.1859\n",
            "Epoch 10, Batch 3300, Loss: 0.3711\n",
            "Epoch 10, Batch 3400, Loss: 0.4370\n",
            "Epoch 10, Batch 3500, Loss: 0.4185\n",
            "Epoch 10, Batch 3600, Loss: 0.2983\n",
            "Epoch 10, Batch 3700, Loss: 0.4429\n",
            "Epoch 10, Batch 3800, Loss: 0.0929\n",
            "Epoch 10, Batch 3900, Loss: 0.3225\n",
            "Epoch 10, Batch 4000, Loss: 0.5948\n",
            "Epoch 10, Batch 4100, Loss: 0.3324\n",
            "Epoch 10, Batch 4200, Loss: 0.6607\n",
            "Epoch 10, Batch 4300, Loss: 1.3235\n",
            "Epoch 10, Batch 4400, Loss: 0.7229\n",
            "Epoch 10, Batch 4500, Loss: 0.3289\n",
            "Epoch 10, Batch 4600, Loss: 0.9154\n",
            "Epoch 10, Batch 4700, Loss: 0.9327\n",
            "Epoch 10, Batch 4800, Loss: 0.3969\n",
            "Epoch 10, Batch 4900, Loss: 0.8198\n",
            "Epoch 10, Batch 5000, Loss: 0.5304\n",
            "Epoch 10, Batch 5100, Loss: 0.2695\n",
            "Epoch 10, Batch 5200, Loss: 0.5006\n",
            "Epoch 10, Batch 5300, Loss: 0.5617\n",
            "Epoch 10, Batch 5400, Loss: 0.5098\n",
            "Epoch 10, Batch 5500, Loss: 0.4563\n",
            "Epoch 10, Batch 5600, Loss: 0.5497\n",
            "Epoch 10, Batch 5700, Loss: 0.7186\n",
            "Epoch 10, Batch 5800, Loss: 0.7164\n",
            "Epoch 10, Batch 5900, Loss: 0.3289\n",
            "Epoch 10, Batch 6000, Loss: 0.7854\n",
            "Epoch 10, Batch 6100, Loss: 1.9146\n",
            "Epoch 10, Batch 6200, Loss: 0.5306\n",
            "Epoch 10, Batch 6300, Loss: 0.8931\n",
            "Epoch 10, Batch 6400, Loss: 0.7746\n",
            "Epoch 10, Batch 6500, Loss: 0.2895\n",
            "Epoch 10, Batch 6600, Loss: 1.1487\n",
            "Epoch 10, Batch 6700, Loss: 0.4883\n",
            "Epoch 10, Batch 6800, Loss: 0.7042\n",
            "Epoch 10, Batch 6900, Loss: 0.2588\n",
            "Epoch 10, Batch 7000, Loss: 1.6053\n",
            "Epoch 10, Batch 7100, Loss: 0.4941\n",
            "Epoch 10, Batch 7200, Loss: 0.4517\n",
            "Epoch 10, Batch 7300, Loss: 0.5681\n",
            "Epoch 10, Batch 7400, Loss: 0.3686\n",
            "Epoch 10, Batch 7500, Loss: 0.5750\n",
            "Epoch 10, Batch 7600, Loss: 0.6742\n",
            "Epoch 10, Batch 7700, Loss: 0.3387\n",
            "Epoch 10, Batch 7800, Loss: 0.3592\n",
            "Epoch 10, Batch 7900, Loss: 0.2774\n",
            "Epoch 10, Batch 8000, Loss: 0.3780\n",
            "Epoch 10, Batch 8100, Loss: 0.7327\n",
            "Epoch 10, Batch 8200, Loss: 1.6567\n",
            "Epoch 10, Batch 8300, Loss: 0.2288\n",
            "Epoch 10, Batch 8400, Loss: 0.2651\n",
            "Epoch 10, Batch 8500, Loss: 1.3575\n",
            "Epoch 10, Batch 8600, Loss: 0.4166\n",
            "Epoch 10, Batch 8700, Loss: 0.5023\n",
            "Epoch 10, Batch 8800, Loss: 0.1708\n",
            "Epoch 10, Batch 8900, Loss: 0.9732\n",
            "Epoch 10, Batch 9000, Loss: 0.4276\n",
            "Epoch 10, Batch 9100, Loss: 0.7025\n",
            "Epoch 10, Batch 9200, Loss: 0.1799\n",
            "Epoch 10, Batch 9300, Loss: 0.3568\n",
            "Epoch 10, Batch 9400, Loss: 2.0004\n",
            "Epoch 10, Batch 9500, Loss: 1.0331\n",
            "Epoch 10, Batch 9600, Loss: 0.5162\n",
            "Epoch 10, Batch 9700, Loss: 0.5933\n",
            "Epoch 10, Batch 9800, Loss: 0.4010\n",
            "Epoch 10, Batch 9900, Loss: 0.3683\n",
            "Epoch 10, Batch 10000, Loss: 0.5945\n",
            "Epoch 10, Batch 10100, Loss: 0.4514\n",
            "Epoch 10, Batch 10200, Loss: 0.8604\n",
            "Epoch 10, Batch 10300, Loss: 0.3981\n",
            "Epoch 10, Batch 10400, Loss: 0.3957\n",
            "Epoch 10/10, Avg Loss: 0.5964\n",
            "Pretraining Complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from NNModel import ECGClassifier\n",
        "import pickle\n",
        "import gzip\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load Pretraining Data\n",
        "with gzip.open(\"pretraining_data.pkl.gz\", \"rb\") as f:\n",
        "    X_train, y_train = pickle.load(f)\n",
        "\n",
        "print(f\"Pretraining data: {X_train.shape}, Labels: {len(y_train)}\")\n",
        "print(f\"Label distribution: {torch.bincount(y_train)}\")\n",
        "\n",
        "class ECGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.unsqueeze(1) if X.dim() == 2 else X  # Add channel dimension if needed\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create DataLoader with smaller batch size for stability\n",
        "batch_size = 32  # Reduced from 64\n",
        "train_dataset = ECGDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "\n",
        "# Model for pretraining\n",
        "class PretrainECGClassifier(ECGClassifier):\n",
        "    def __init__(self):\n",
        "        super(PretrainECGClassifier, self).__init__(num_classes=4)\n",
        "\n",
        "model = PretrainECGClassifier()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Compute class weights for imbalanced dataset\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                   classes=np.unique(y_train.numpy()),\n",
        "                                   y=y_train.numpy())\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "# Loss and Optimizer with better settings\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "\n",
        "# Pretraining Loop\n",
        "num_epochs = 10  # Increased epochs\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        with gzip.open(\"pretrained_model_best.pth.gz\", \"wb\") as f:\n",
        "            pickle.dump(model.state_dict(), f)\n",
        "\n",
        "print(\"Pretraining Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvv_IKAAwII_",
        "outputId": "859508e7-eb52-4a77-d9db-4eb134cb85d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 48 MIT-BIH files...\n",
            "Processing 100 (1/48)\n",
            "  Extracted 2270 valid episodes from 100\n",
            "Processing 101 (2/48)\n",
            "  Extracted 1868 valid episodes from 101\n",
            "Processing 102 (3/48)\n",
            "  Extracted 2187 valid episodes from 102\n",
            "Processing 103 (4/48)\n",
            "  Extracted 2084 valid episodes from 103\n",
            "Processing 104 (5/48)\n",
            "  Extracted 2203 valid episodes from 104\n",
            "Processing 105 (6/48)\n",
            "  Extracted 2570 valid episodes from 105\n",
            "Processing 106 (7/48)\n",
            "  Extracted 2032 valid episodes from 106\n",
            "Processing 107 (8/48)\n",
            "  Extracted 2136 valid episodes from 107\n",
            "Processing 108 (9/48)\n",
            "  Extracted 1770 valid episodes from 108\n",
            "Processing 109 (10/48)\n",
            "  Extracted 2531 valid episodes from 109\n",
            "Processing 111 (11/48)\n",
            "  Extracted 2124 valid episodes from 111\n",
            "Processing 112 (12/48)\n",
            "  Extracted 2539 valid episodes from 112\n",
            "Processing 113 (13/48)\n",
            "  Extracted 1826 valid episodes from 113\n",
            "Processing 114 (14/48)\n",
            "  Extracted 1882 valid episodes from 114\n",
            "Processing 115 (15/48)\n",
            "  Extracted 1953 valid episodes from 115\n",
            "Processing 116 (16/48)\n",
            "  Extracted 2399 valid episodes from 116\n",
            "Processing 117 (17/48)\n",
            "  Extracted 1535 valid episodes from 117\n",
            "Processing 118 (18/48)\n",
            "  Extracted 2278 valid episodes from 118\n",
            "Processing 119 (19/48)\n",
            "  Extracted 1988 valid episodes from 119\n",
            "Processing 121 (20/48)\n",
            "  Extracted 1863 valid episodes from 121\n",
            "Processing 122 (21/48)\n",
            "  Extracted 2475 valid episodes from 122\n",
            "Processing 123 (22/48)\n",
            "  Extracted 1518 valid episodes from 123\n",
            "Processing 124 (23/48)\n",
            "  Extracted 1623 valid episodes from 124\n",
            "Processing 200 (24/48)\n",
            "  Extracted 2608 valid episodes from 200\n",
            "Processing 201 (25/48)\n",
            "  Extracted 1980 valid episodes from 201\n",
            "Processing 202 (26/48)\n",
            "  Extracted 2136 valid episodes from 202\n",
            "Processing 203 (27/48)\n",
            "  Extracted 2821 valid episodes from 203\n",
            "Processing 205 (28/48)\n",
            "  Extracted 2629 valid episodes from 205\n",
            "Processing 207 (29/48)\n",
            "  Extracted 1236 valid episodes from 207\n",
            "Processing 208 (30/48)\n",
            "  Extracted 2948 valid episodes from 208\n",
            "Processing 209 (31/48)\n",
            "  Extracted 3005 valid episodes from 209\n",
            "Processing 210 (32/48)\n",
            "  Extracted 2605 valid episodes from 210\n",
            "Processing 212 (33/48)\n",
            "  Extracted 2748 valid episodes from 212\n",
            "Processing 213 (34/48)\n",
            "  Extracted 3246 valid episodes from 213\n",
            "Processing 214 (35/48)\n",
            "  Extracted 2260 valid episodes from 214\n",
            "Processing 215 (36/48)\n",
            "  Extracted 3357 valid episodes from 215\n",
            "Processing 217 (37/48)\n",
            "  Extracted 2207 valid episodes from 217\n",
            "Processing 219 (38/48)\n",
            "  Extracted 2154 valid episodes from 219\n",
            "Processing 220 (39/48)\n",
            "  Extracted 2047 valid episodes from 220\n",
            "Processing 221 (40/48)\n",
            "  Extracted 2428 valid episodes from 221\n",
            "Processing 222 (41/48)\n",
            "  Extracted 2491 valid episodes from 222\n",
            "Processing 223 (42/48)\n",
            "  Extracted 2605 valid episodes from 223\n",
            "Processing 228 (43/48)\n",
            "  Extracted 2063 valid episodes from 228\n",
            "Processing 230 (44/48)\n",
            "  Extracted 2255 valid episodes from 230\n",
            "Processing 231 (45/48)\n",
            "  Extracted 1917 valid episodes from 231\n",
            "Processing 232 (46/48)\n",
            "  Extracted 1842 valid episodes from 232\n",
            "Processing 233 (47/48)\n",
            "  Extracted 3072 valid episodes from 233\n",
            "Processing 234 (48/48)\n",
            "  Extracted 2753 valid episodes from 234\n",
            "\n",
            "Completed processing 48/48 files\n",
            "Total beats extracted: 109067\n",
            "\n",
            "MIT-BIH Beats Shape: torch.Size([109067, 3750])\n",
            "Unique Labels and Counts: (array([0, 1, 2, 3, 4]), array([89860,  2952,  7003,   799,  8453]))\n",
            "  Normal: 89860 beats (82.4%)\n",
            "  Supraventricular: 2952 beats (2.7%)\n",
            "  Ventricular: 7003 beats (6.4%)\n",
            "  Fusion: 799 beats (0.7%)\n",
            "  Unknown: 8453 beats (7.8%)\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing for MIT-BIH Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import wfdb\n",
        "import gzip\n",
        "import pickle\n",
        "import neurokit2 as nk\n",
        "from scipy.signal import resample\n",
        "\n",
        "# Constants\n",
        "TARGET_SAMPLING_RATE = 125\n",
        "MAX_LEN_MITBIH = 30 * TARGET_SAMPLING_RATE  # 30 seconds\n",
        "\n",
        "# IMPROVED Beat label mapping - more comprehensive\n",
        "label_mapping = {\n",
        "    # Normal beats\n",
        "    'N': 0, 'L': 0, 'R': 0, 'B': 0, '.': 0,\n",
        "    # Supraventricular ectopic beats\n",
        "    'A': 1, 'a': 1, 'J': 1, 'S': 1, 'e': 1, 'j': 1, 'n': 1,\n",
        "    # Ventricular ectopic beats\n",
        "    'V': 2, 'r': 2, 'E': 2,\n",
        "    # Fusion beats\n",
        "    'F': 3,\n",
        "    # Unknown/Unclassifiable beats\n",
        "    '/': 4, 'Q': 4, 'f': 4, '?': 4\n",
        "}\n",
        "\n",
        "def load_mitbih_record(record_path):\n",
        "    \"\"\"Load MIT-BIH record with error handling.\"\"\"\n",
        "    try:\n",
        "        record = wfdb.rdrecord(record_path)\n",
        "        annotation = wfdb.rdann(record_path, 'atr')\n",
        "        signal = record.p_signal[:, 0]  # use first ECG lead\n",
        "        return signal, annotation.sample, annotation.symbol\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {record_path}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "def downsample_signal(signal, original_fs=360, target_fs=125):\n",
        "    \"\"\"Downsample with validation.\"\"\"\n",
        "    if original_fs == target_fs:\n",
        "        return signal\n",
        "    num_samples = int(len(signal) * target_fs / original_fs)\n",
        "    return resample(signal, num_samples)\n",
        "\n",
        "def normalize_signal(signal):\n",
        "    \"\"\"FIXED: Better normalization with edge case handling.\"\"\"\n",
        "    signal = np.array(signal, dtype=np.float32)\n",
        "    signal_min, signal_max = np.min(signal), np.max(signal)\n",
        "    signal_range = signal_max - signal_min\n",
        "\n",
        "    if signal_range < 1e-8:  # Prevent division by zero\n",
        "        return np.zeros_like(signal)\n",
        "\n",
        "    return (signal - signal_min) / signal_range\n",
        "\n",
        "def detect_r_peaks(signal, fs=125):\n",
        "    \"\"\"Use NeuroKit2 to detect R-peaks with error handling.\"\"\"\n",
        "    try:\n",
        "        _, rpeaks = nk.ecg_peaks(signal, sampling_rate=fs)\n",
        "        return rpeaks[\"ECG_R_Peaks\"]\n",
        "    except:\n",
        "        return np.array([])\n",
        "\n",
        "def extract_t_episodes(signal, r_peaks):\n",
        "    \"\"\"Extract T-episodes with improved logic.\"\"\"\n",
        "    if len(r_peaks) < 2:\n",
        "        return []\n",
        "\n",
        "    rr_intervals = np.diff(r_peaks)\n",
        "    median_rr = int(np.median(rr_intervals))\n",
        "\n",
        "    # Ensure reasonable episode length\n",
        "    min_episode_len = max(50, median_rr // 4)  # At least 50 samples\n",
        "    max_episode_len = min(1000, median_rr * 2)  # At most 1000 samples\n",
        "\n",
        "    episodes = []\n",
        "    for r in r_peaks:\n",
        "        half_len = median_rr // 2\n",
        "        start = max(0, r - half_len)\n",
        "        end = min(len(signal), r + half_len)\n",
        "\n",
        "        # Validate episode length\n",
        "        if (end - start) >= min_episode_len and (end - start) <= max_episode_len:\n",
        "            episodes.append((start, end))\n",
        "\n",
        "    return episodes\n",
        "\n",
        "def assign_labels_to_episodes(episodes, ann_samples, ann_symbols, label_map):\n",
        "    \"\"\"Assign labels to episodes with better matching.\"\"\"\n",
        "    labels = []\n",
        "    ann_samples = np.array(ann_samples)\n",
        "\n",
        "    for start, end in episodes:\n",
        "        center = (start + end) // 2\n",
        "\n",
        "        # Find nearest annotation within reasonable distance\n",
        "        distances = np.abs(ann_samples - center)\n",
        "        nearest_idx = np.argmin(distances)\n",
        "\n",
        "        # Only assign label if annotation is reasonably close (within 1 second)\n",
        "        if distances[nearest_idx] <= 125:  # 125 samples = 1 second at 125Hz\n",
        "            label = ann_symbols[nearest_idx]\n",
        "            if label in label_map:\n",
        "                labels.append(label_map[label])\n",
        "            else:\n",
        "                labels.append(4)  # Unknown class\n",
        "        else:\n",
        "            labels.append(None)  # Skip this episode\n",
        "\n",
        "    return labels\n",
        "\n",
        "def pad_signal(signal, max_len):\n",
        "    \"\"\"Pad or truncate signal to max_len.\"\"\"\n",
        "    if len(signal) < max_len:\n",
        "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
        "    else:\n",
        "        return signal[:max_len]\n",
        "\n",
        "def preprocess_mitbih_dataset(dataset_dir):\n",
        "    \"\"\"Preprocess MIT-BIH dataset with comprehensive error handling.\"\"\"\n",
        "    all_beats, all_labels = [], []\n",
        "    processed_files = 0\n",
        "    total_files = len([f for f in os.listdir(dataset_dir) if f.endswith('.dat')])\n",
        "\n",
        "    print(f\"Processing {total_files} MIT-BIH files...\")\n",
        "\n",
        "    for file in sorted(os.listdir(dataset_dir)):\n",
        "        if file.endswith('.dat'):\n",
        "            record_name = file.replace('.dat', '')\n",
        "            record_path = os.path.join(dataset_dir, record_name)\n",
        "\n",
        "            print(f\"Processing {record_name} ({processed_files+1}/{total_files})\")\n",
        "\n",
        "            # Load record\n",
        "            signal, ann_samples, ann_symbols = load_mitbih_record(record_path)\n",
        "            if signal is None:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Downsample signal\n",
        "                signal = downsample_signal(signal)\n",
        "                ann_samples = (np.array(ann_samples) * (TARGET_SAMPLING_RATE / 360)).astype(int)\n",
        "\n",
        "                # Normalize\n",
        "                signal = normalize_signal(signal)\n",
        "\n",
        "                # Skip if normalization failed\n",
        "                if np.all(signal == 0):\n",
        "                    print(f\"  Skipping {record_name}: normalization failed\")\n",
        "                    continue\n",
        "\n",
        "                # R-peak detection\n",
        "                r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
        "\n",
        "                if len(r_peaks) < 2:\n",
        "                    print(f\"  Skipping {record_name}: insufficient R-peaks detected\")\n",
        "                    continue\n",
        "\n",
        "                # Extract T-episodes\n",
        "                t_episodes = extract_t_episodes(signal, r_peaks)\n",
        "\n",
        "                # Assign labels\n",
        "                labels = assign_labels_to_episodes(t_episodes, ann_samples, ann_symbols, label_mapping)\n",
        "\n",
        "                # Process valid episodes\n",
        "                valid_episodes = 0\n",
        "                for (start, end), label in zip(t_episodes, labels):\n",
        "                    if label is not None:\n",
        "                        beat = signal[start:end]\n",
        "                        if len(beat) > 0:\n",
        "                            padded = pad_signal(beat, MAX_LEN_MITBIH)\n",
        "                            all_beats.append(padded)\n",
        "                            all_labels.append(label)\n",
        "                            valid_episodes += 1\n",
        "\n",
        "                print(f\"  Extracted {valid_episodes} valid episodes from {record_name}\")\n",
        "                processed_files += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error processing {record_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"\\nCompleted processing {processed_files}/{total_files} files\")\n",
        "    print(f\"Total beats extracted: {len(all_beats)}\")\n",
        "\n",
        "    return np.array(all_beats), np.array(all_labels)\n",
        "\n",
        "# Preprocess MIT-BIH\n",
        "mitbih_signals, mitbih_labels = preprocess_mitbih_dataset(\"data/mit-bih-arrhythmia-database-1.0.0\")\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_mitbih = torch.tensor(mitbih_signals, dtype=torch.float32)\n",
        "y_mitbih = torch.tensor(mitbih_labels, dtype=torch.long)\n",
        "\n",
        "# Save\n",
        "with gzip.open(\"mitbih_beats.pkl.gz\", \"wb\") as f:\n",
        "    pickle.dump((X_mitbih, y_mitbih), f)\n",
        "\n",
        "print(f\"\\nMIT-BIH Beats Shape: {X_mitbih.shape}\")\n",
        "print(f\"Unique Labels and Counts: {np.unique(mitbih_labels, return_counts=True)}\")\n",
        "\n",
        "# Show label distribution\n",
        "label_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "unique_labels, counts = np.unique(mitbih_labels, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    if label < len(label_names):\n",
        "        print(f\"  {label_names[label]}: {count} beats ({count/len(mitbih_labels)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbR2IjQu_e2y",
        "outputId": "f940335a-7259-4dff-f9b7-9b6e383280c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚ö†Ô∏è  File not found: /content/drive/MyDrive/ECGData/pretrained_model_best.pth.gz\n",
            "‚ö†Ô∏è  File not found: /content/drive/MyDrive/ECGData/pretraining_data.pkl.gz\n",
            "‚ö†Ô∏è  File not found: /content/drive/MyDrive/ECGData/mitbih_beats.pkl.gz\n",
            "\n",
            "üìÅ Files in /content/:\n",
            "  ‚úÖ pretrained_model_best.pth.gz (14.1 MB)\n",
            "  ‚úÖ pretraining_data.pkl.gz (112.4 MB)\n",
            "  ‚úÖ mitbih_beats.pkl.gz (37.1 MB)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "drive_base = \"/content/drive/MyDrive/ECGData\"\n",
        "files_to_copy = [\n",
        "    \"pretrained_model_best.pth.gz\",\n",
        "    \"pretraining_data.pkl.gz\",\n",
        "    \"mitbih_beats.pkl.gz\"\n",
        "]\n",
        "\n",
        "# Copy files from Drive with error checking\n",
        "for file_name in files_to_copy:\n",
        "    source_path = f\"{drive_base}/{file_name}\"\n",
        "    if os.path.exists(source_path):\n",
        "        !cp \"{source_path}\" /content/\n",
        "        print(f\"‚úÖ Copied {file_name}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  File not found: {source_path}\")\n",
        "\n",
        "# Verify files are copied\n",
        "print(\"\\nüìÅ Files in /content/:\")\n",
        "for file_name in files_to_copy:\n",
        "    if os.path.exists(f\"/content/{file_name}\"):\n",
        "        size_mb = os.path.getsize(f\"/content/{file_name}\") / (1024*1024)\n",
        "        print(f\"  ‚úÖ {file_name} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå {file_name} - Missing!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from NNModel import ECGClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------\n",
        "# 1. Load and Analyze Data\n",
        "# --------------------\n",
        "print(\"Loading MIT-BIH data...\")\n",
        "with gzip.open(\"mitbih_beats.pkl.gz\", \"rb\") as f:\n",
        "    X_mit, y_mit = pickle.load(f)\n",
        "\n",
        "print(f\"Data shape: {X_mit.shape}\")\n",
        "print(f\"Labels shape: {y_mit.shape}\")\n",
        "\n",
        "# Analyze class distribution\n",
        "unique_labels, counts = np.unique(y_mit, return_counts=True)\n",
        "print(f\"\\nClass distribution:\")\n",
        "class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    percentage = (count / len(y_mit)) * 100\n",
        "    print(f\"  Class {label} ({class_names[label]}): {count} samples ({percentage:.2f}%)\")\n",
        "\n",
        "# Train-Validation-Test Split (60/20/20)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_mit, y_mit, test_size=0.2, random_state=42, stratify=y_mit\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val  # 0.25 of 0.8 = 0.2\n",
        ")\n",
        "\n",
        "print(f\"\\nData splits:\")\n",
        "print(f\"  Train: {X_train.shape[0]} samples\")\n",
        "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"  Test: {X_test.shape[0]} samples\")\n",
        "\n",
        "# --------------------\n",
        "# 2. Dataset Class with Data Augmentation\n",
        "# --------------------\n",
        "class ECGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = X.unsqueeze(1) if X.dim() == 2 else X  # Add channel dimension\n",
        "        self.y = y\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx].clone()\n",
        "        y = self.y[idx]\n",
        "\n",
        "        # Simple data augmentation for training\n",
        "        if self.augment:\n",
        "            # Add small amount of noise\n",
        "            if np.random.rand() < 0.3:\n",
        "                noise = torch.randn_like(x) * 0.01\n",
        "                x = x + noise\n",
        "\n",
        "            # Small time shift\n",
        "            if np.random.rand() < 0.3:\n",
        "                shift = np.random.randint(-10, 11)\n",
        "                x = torch.roll(x, shift, dims=-1)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# --------------------\n",
        "# 3. Create DataLoaders\n",
        "# --------------------\n",
        "batch_size = 128  # Reduced for stability\n",
        "train_dataset = ECGDataset(X_train, y_train, augment=True)\n",
        "val_dataset = ECGDataset(X_val, y_val, augment=False)\n",
        "test_dataset = ECGDataset(X_test, y_test, augment=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=2, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# --------------------\n",
        "# 4. Model Initialization with Pretrained Weights\n",
        "# --------------------\n",
        "print(\"\\nInitializing model...\")\n",
        "model = ECGClassifier(num_classes=5)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "# Load pretrained weights (excluding final layer)\n",
        "try:\n",
        "    with gzip.open(\"pretrained_model_best.pth.gz\", \"rb\") as f:\n",
        "        pretrained_dict = pickle.load(f)\n",
        "\n",
        "    # Filter out the final FC layer\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
        "                      if not k.startswith('fc2')}\n",
        "\n",
        "    # Load weights\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(pretrained_dict, strict=False)\n",
        "    print(f\"Loaded pretrained weights. Missing: {len(missing_keys)}, Unexpected: {len(unexpected_keys)}\")\n",
        "\n",
        "    # Reinitialize final layer\n",
        "    model.fc2 = nn.Linear(model.fc2.in_features, 5).to(device)\n",
        "    nn.init.kaiming_normal_(model.fc2.weight)\n",
        "    nn.init.constant_(model.fc2.bias, 0)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not load pretrained weights: {e}\")\n",
        "    print(\"Training from scratch...\")\n",
        "\n",
        "# --------------------\n",
        "# 5. Training Setup with Class Balancing\n",
        "# --------------------\n",
        "# Compute class weights for imbalanced dataset\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                   classes=np.unique(y_train.numpy()),\n",
        "                                   y=y_train.numpy())\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5,\n",
        "                                               factor=0.5)\n",
        "\n",
        "# --------------------\n",
        "# 6. Training Loop with Validation\n",
        "# --------------------\n",
        "num_epochs = 50\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "patience = 10\n",
        "\n",
        "train_losses, val_losses, val_accs = [], [], []\n",
        "\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, \"\n",
        "                  f\"Loss: {loss.item():.4f}, Acc: {100*correct/total:.2f}%\")\n",
        "\n",
        "    train_acc = 100.0 * correct / total\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val_batch in val_loader:\n",
        "            X_val, y_val_batch = X_val.to(device), y_val_batch.to(device)\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss += criterion(val_outputs, y_val_batch).item()\n",
        "\n",
        "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
        "            val_total += y_val_batch.size(0)\n",
        "            val_correct += (val_predicted == y_val_batch).sum().item()\n",
        "\n",
        "    val_acc = 100.0 * val_correct / val_total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # Early stopping and model saving\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(f\"  üíæ New best model saved! Val Acc: {val_acc:.2f}%\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "        break\n",
        "\n",
        "# Load best model for evaluation\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "print(f\"\\nTraining completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "# Save final model to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "final_model_path = \"/content/drive/MyDrive/ColabData/ECG/ecg_mitbih_finetuned_improved.pth\"\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"Final model saved to: {final_model_path}\")"
      ],
      "metadata": {
        "id": "TqnXx8BVaxaG",
        "outputId": "0ec1cd5c-ae2c-4dfb-e97c-f58eb26f463a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MIT-BIH data...\n",
            "Data shape: torch.Size([109067, 3750])\n",
            "Labels shape: torch.Size([109067])\n",
            "\n",
            "Class distribution:\n",
            "  Class 0 (Normal): 89860 samples (82.39%)\n",
            "  Class 1 (Supraventricular): 2952 samples (2.71%)\n",
            "  Class 2 (Ventricular): 7003 samples (6.42%)\n",
            "  Class 3 (Fusion): 799 samples (0.73%)\n",
            "  Class 4 (Unknown): 8453 samples (7.75%)\n",
            "\n",
            "Data splits:\n",
            "  Train: 65439 samples\n",
            "  Validation: 21814 samples\n",
            "  Test: 21814 samples\n",
            "\n",
            "Initializing model...\n",
            "Using device: cuda\n",
            "Loaded pretrained weights. Missing: 2, Unexpected: 0\n",
            "Class weights: tensor([ 0.2427,  7.3859,  3.1147, 27.3232,  2.5809], device='cuda:0')\n",
            "\n",
            "Starting training for 50 epochs...\n",
            "Epoch 1, Batch 0/511, Loss: 2.5241, Acc: 9.38%\n",
            "Epoch 1, Batch 50/511, Loss: 1.5452, Acc: 35.48%\n",
            "Epoch 1, Batch 100/511, Loss: 1.4639, Acc: 31.95%\n",
            "Epoch 1, Batch 150/511, Loss: 1.2908, Acc: 31.93%\n",
            "Epoch 1, Batch 200/511, Loss: 1.1321, Acc: 34.92%\n",
            "Epoch 1, Batch 250/511, Loss: 1.4973, Acc: 38.02%\n",
            "Epoch 1, Batch 300/511, Loss: 0.8495, Acc: 40.85%\n",
            "Epoch 1, Batch 350/511, Loss: 0.9421, Acc: 43.74%\n",
            "Epoch 1, Batch 400/511, Loss: 0.7078, Acc: 47.39%\n",
            "Epoch 1, Batch 450/511, Loss: 0.4659, Acc: 49.82%\n",
            "Epoch 1, Batch 500/511, Loss: 0.6633, Acc: 51.47%\n",
            "Epoch 1/50:\n",
            "  Train Loss: 1.1300, Train Acc: 51.91%\n",
            "  Val Loss: 0.5798, Val Acc: 89.90%\n",
            "  LR: 0.001000\n",
            "  üíæ New best model saved! Val Acc: 89.90%\n",
            "Epoch 2, Batch 0/511, Loss: 0.3690, Acc: 78.12%\n",
            "Epoch 2, Batch 50/511, Loss: 0.5860, Acc: 75.87%\n",
            "Epoch 2, Batch 100/511, Loss: 0.4076, Acc: 75.34%\n",
            "Epoch 2, Batch 150/511, Loss: 0.1450, Acc: 77.11%\n",
            "Epoch 2, Batch 200/511, Loss: 0.2655, Acc: 79.29%\n",
            "Epoch 2, Batch 250/511, Loss: 0.5522, Acc: 80.38%\n",
            "Epoch 2, Batch 300/511, Loss: 0.3420, Acc: 81.55%\n",
            "Epoch 2, Batch 350/511, Loss: 0.5327, Acc: 82.37%\n",
            "Epoch 2, Batch 400/511, Loss: 0.3776, Acc: 83.21%\n",
            "Epoch 2, Batch 450/511, Loss: 0.2928, Acc: 83.70%\n",
            "Epoch 2, Batch 500/511, Loss: 0.3137, Acc: 84.42%\n",
            "Epoch 2/50:\n",
            "  Train Loss: 0.5010, Train Acc: 84.55%\n",
            "  Val Loss: 0.2703, Val Acc: 92.80%\n",
            "  LR: 0.001000\n",
            "  üíæ New best model saved! Val Acc: 92.80%\n",
            "Epoch 3, Batch 0/511, Loss: 0.1045, Acc: 95.31%\n",
            "Epoch 3, Batch 50/511, Loss: 0.1876, Acc: 92.65%\n",
            "Epoch 3, Batch 100/511, Loss: 0.2808, Acc: 92.50%\n",
            "Epoch 3, Batch 150/511, Loss: 0.1539, Acc: 92.70%\n",
            "Epoch 3, Batch 200/511, Loss: 0.2030, Acc: 92.79%\n",
            "Epoch 3, Batch 250/511, Loss: 0.2418, Acc: 92.80%\n",
            "Epoch 3, Batch 300/511, Loss: 0.1259, Acc: 92.59%\n",
            "Epoch 3, Batch 350/511, Loss: 1.6067, Acc: 92.46%\n",
            "Epoch 3, Batch 400/511, Loss: 0.1923, Acc: 92.64%\n",
            "Epoch 3, Batch 450/511, Loss: 0.0470, Acc: 92.72%\n",
            "Epoch 3, Batch 500/511, Loss: 0.1779, Acc: 92.75%\n",
            "Epoch 3/50:\n",
            "  Train Loss: 0.3136, Train Acc: 92.74%\n",
            "  Val Loss: 0.2940, Val Acc: 95.68%\n",
            "  LR: 0.001000\n",
            "  üíæ New best model saved! Val Acc: 95.68%\n",
            "Epoch 4, Batch 0/511, Loss: 0.2025, Acc: 95.31%\n",
            "Epoch 4, Batch 50/511, Loss: 0.1425, Acc: 94.47%\n",
            "Epoch 4, Batch 100/511, Loss: 1.0774, Acc: 94.38%\n",
            "Epoch 4, Batch 150/511, Loss: 0.2001, Acc: 94.15%\n",
            "Epoch 4, Batch 200/511, Loss: 0.0780, Acc: 94.16%\n",
            "Epoch 4, Batch 250/511, Loss: 0.0645, Acc: 94.22%\n",
            "Epoch 4, Batch 300/511, Loss: 0.2522, Acc: 94.17%\n",
            "Epoch 4, Batch 350/511, Loss: 1.9173, Acc: 94.20%\n",
            "Epoch 4, Batch 400/511, Loss: 0.1146, Acc: 94.31%\n",
            "Epoch 4, Batch 450/511, Loss: 0.5217, Acc: 94.36%\n",
            "Epoch 4, Batch 500/511, Loss: 0.0628, Acc: 94.47%\n",
            "Epoch 4/50:\n",
            "  Train Loss: 0.2868, Train Acc: 94.49%\n",
            "  Val Loss: 0.2089, Val Acc: 96.27%\n",
            "  LR: 0.001000\n",
            "  üíæ New best model saved! Val Acc: 96.27%\n",
            "Epoch 5, Batch 0/511, Loss: 0.1125, Acc: 96.88%\n",
            "Epoch 5, Batch 50/511, Loss: 0.2525, Acc: 94.49%\n",
            "Epoch 5, Batch 100/511, Loss: 0.0617, Acc: 94.64%\n",
            "Epoch 5, Batch 150/511, Loss: 0.3526, Acc: 94.79%\n",
            "Epoch 5, Batch 200/511, Loss: 0.2127, Acc: 94.72%\n",
            "Epoch 5, Batch 250/511, Loss: 1.3861, Acc: 94.61%\n",
            "Epoch 5, Batch 300/511, Loss: 0.2857, Acc: 94.79%\n",
            "Epoch 5, Batch 350/511, Loss: 0.0539, Acc: 94.75%\n",
            "Epoch 5, Batch 400/511, Loss: 0.0415, Acc: 94.95%\n",
            "Epoch 5, Batch 450/511, Loss: 0.0808, Acc: 95.00%\n",
            "Epoch 5, Batch 500/511, Loss: 0.0802, Acc: 95.10%\n",
            "Epoch 5/50:\n",
            "  Train Loss: 0.2343, Train Acc: 95.08%\n",
            "  Val Loss: 0.2478, Val Acc: 97.38%\n",
            "  LR: 0.001000\n",
            "  üíæ New best model saved! Val Acc: 97.38%\n",
            "Epoch 6, Batch 0/511, Loss: 1.5042, Acc: 94.53%\n",
            "Epoch 6, Batch 50/511, Loss: 0.1214, Acc: 95.62%\n",
            "Epoch 6, Batch 100/511, Loss: 0.0539, Acc: 96.12%\n",
            "Epoch 6, Batch 150/511, Loss: 0.5326, Acc: 95.63%\n",
            "Epoch 6, Batch 200/511, Loss: 0.1367, Acc: 95.39%\n",
            "Epoch 6, Batch 250/511, Loss: 1.3560, Acc: 95.50%\n",
            "Epoch 6, Batch 300/511, Loss: 0.0816, Acc: 95.46%\n",
            "Epoch 6, Batch 350/511, Loss: 0.0765, Acc: 95.48%\n",
            "Epoch 6, Batch 400/511, Loss: 0.0786, Acc: 95.58%\n",
            "Epoch 6, Batch 450/511, Loss: 0.0357, Acc: 95.68%\n",
            "Epoch 6, Batch 500/511, Loss: 0.0234, Acc: 95.72%\n",
            "Epoch 6/50:\n",
            "  Train Loss: 0.2134, Train Acc: 95.72%\n",
            "  Val Loss: 0.1881, Val Acc: 93.54%\n",
            "  LR: 0.001000\n",
            "Epoch 7, Batch 0/511, Loss: 0.0395, Acc: 95.31%\n",
            "Epoch 7, Batch 50/511, Loss: 0.0435, Acc: 94.30%\n",
            "Epoch 7, Batch 100/511, Loss: 0.0758, Acc: 95.00%\n",
            "Epoch 7, Batch 150/511, Loss: 0.0754, Acc: 95.12%\n",
            "Epoch 7, Batch 200/511, Loss: 0.0596, Acc: 95.41%\n",
            "Epoch 7, Batch 250/511, Loss: 0.0215, Acc: 95.56%\n",
            "Epoch 7, Batch 300/511, Loss: 0.1860, Acc: 95.67%\n",
            "Epoch 7, Batch 350/511, Loss: 0.3747, Acc: 95.65%\n",
            "Epoch 7, Batch 400/511, Loss: 0.2949, Acc: 95.50%\n",
            "Epoch 7, Batch 450/511, Loss: 0.1546, Acc: 95.51%\n",
            "Epoch 7, Batch 500/511, Loss: 0.6116, Acc: 95.53%\n",
            "Epoch 7/50:\n",
            "  Train Loss: 0.1965, Train Acc: 95.52%\n",
            "  Val Loss: 0.2709, Val Acc: 79.92%\n",
            "  LR: 0.001000\n",
            "Epoch 8, Batch 0/511, Loss: 0.0857, Acc: 99.22%\n",
            "Epoch 8, Batch 50/511, Loss: 0.0192, Acc: 96.42%\n",
            "Epoch 8, Batch 100/511, Loss: 0.0369, Acc: 96.53%\n",
            "Epoch 8, Batch 150/511, Loss: 0.0719, Acc: 96.53%\n",
            "Epoch 8, Batch 200/511, Loss: 0.0537, Acc: 96.44%\n",
            "Epoch 8, Batch 250/511, Loss: 0.1506, Acc: 96.30%\n",
            "Epoch 8, Batch 300/511, Loss: 0.0643, Acc: 96.25%\n",
            "Epoch 8, Batch 350/511, Loss: 0.1746, Acc: 96.26%\n",
            "Epoch 8, Batch 400/511, Loss: 0.0276, Acc: 96.24%\n",
            "Epoch 8, Batch 450/511, Loss: 0.1080, Acc: 96.30%\n",
            "Epoch 8, Batch 500/511, Loss: 0.0441, Acc: 96.30%\n",
            "Epoch 8/50:\n",
            "  Train Loss: 0.1725, Train Acc: 96.31%\n",
            "  Val Loss: 0.1575, Val Acc: 96.71%\n",
            "  LR: 0.001000\n",
            "Epoch 9, Batch 0/511, Loss: 0.0245, Acc: 96.88%\n",
            "Epoch 9, Batch 50/511, Loss: 0.0595, Acc: 96.25%\n",
            "Epoch 9, Batch 100/511, Loss: 0.2324, Acc: 96.57%\n",
            "Epoch 9, Batch 150/511, Loss: 0.8265, Acc: 96.69%\n",
            "Epoch 9, Batch 200/511, Loss: 0.0618, Acc: 96.76%\n",
            "Epoch 9, Batch 250/511, Loss: 0.1269, Acc: 96.63%\n",
            "Epoch 9, Batch 300/511, Loss: 0.0591, Acc: 96.58%\n",
            "Epoch 9, Batch 350/511, Loss: 0.1601, Acc: 96.50%\n",
            "Epoch 9, Batch 400/511, Loss: 0.0922, Acc: 96.51%\n",
            "Epoch 9, Batch 450/511, Loss: 0.0201, Acc: 96.47%\n",
            "Epoch 9, Batch 500/511, Loss: 0.0305, Acc: 96.43%\n",
            "Epoch 9/50:\n",
            "  Train Loss: 0.1645, Train Acc: 96.43%\n",
            "  Val Loss: 0.1618, Val Acc: 97.35%\n",
            "  LR: 0.001000\n",
            "Epoch 10, Batch 0/511, Loss: 0.0562, Acc: 94.53%\n",
            "Epoch 10, Batch 50/511, Loss: 0.0410, Acc: 97.33%\n",
            "Epoch 10, Batch 100/511, Loss: 0.4780, Acc: 96.90%\n",
            "Epoch 10, Batch 150/511, Loss: 0.1546, Acc: 96.82%\n",
            "Epoch 10, Batch 200/511, Loss: 0.0261, Acc: 96.65%\n",
            "Epoch 10, Batch 250/511, Loss: 0.0409, Acc: 96.50%\n",
            "Epoch 10, Batch 300/511, Loss: 0.0364, Acc: 96.62%\n",
            "Epoch 10, Batch 350/511, Loss: 0.1859, Acc: 96.57%\n",
            "Epoch 10, Batch 400/511, Loss: 0.0266, Acc: 96.56%\n",
            "Epoch 10, Batch 450/511, Loss: 0.1491, Acc: 96.47%\n",
            "Epoch 10, Batch 500/511, Loss: 0.0424, Acc: 96.45%\n",
            "Epoch 10/50:\n",
            "  Train Loss: 0.1572, Train Acc: 96.44%\n",
            "  Val Loss: 0.1810, Val Acc: 97.96%\n",
            "  LR: 0.001000\n",
            "  üíæ New best model saved! Val Acc: 97.96%\n",
            "Epoch 11, Batch 0/511, Loss: 0.0190, Acc: 97.66%\n",
            "Epoch 11, Batch 50/511, Loss: 0.0410, Acc: 97.21%\n",
            "Epoch 11, Batch 100/511, Loss: 0.0381, Acc: 97.00%\n",
            "Epoch 11, Batch 150/511, Loss: 0.0121, Acc: 96.72%\n",
            "Epoch 11, Batch 200/511, Loss: 0.0699, Acc: 96.84%\n",
            "Epoch 11, Batch 250/511, Loss: 0.1481, Acc: 96.74%\n",
            "Epoch 11, Batch 300/511, Loss: 0.0656, Acc: 96.71%\n",
            "Epoch 11, Batch 350/511, Loss: 0.0455, Acc: 96.69%\n",
            "Epoch 11, Batch 400/511, Loss: 0.0280, Acc: 96.73%\n",
            "Epoch 11, Batch 450/511, Loss: 0.0809, Acc: 96.82%\n",
            "Epoch 11, Batch 500/511, Loss: 0.1387, Acc: 96.73%\n",
            "Epoch 11/50:\n",
            "  Train Loss: 0.1533, Train Acc: 96.71%\n",
            "  Val Loss: 0.2068, Val Acc: 96.97%\n",
            "  LR: 0.001000\n",
            "Epoch 12, Batch 0/511, Loss: 0.6422, Acc: 97.66%\n",
            "Epoch 12, Batch 50/511, Loss: 0.0285, Acc: 95.88%\n",
            "Epoch 12, Batch 100/511, Loss: 0.0305, Acc: 96.18%\n",
            "Epoch 12, Batch 150/511, Loss: 0.0230, Acc: 96.15%\n",
            "Epoch 12, Batch 200/511, Loss: 0.0216, Acc: 96.37%\n",
            "Epoch 12, Batch 250/511, Loss: 0.0773, Acc: 96.30%\n",
            "Epoch 12, Batch 300/511, Loss: 0.0149, Acc: 96.41%\n",
            "Epoch 12, Batch 350/511, Loss: 0.0185, Acc: 96.48%\n",
            "Epoch 12, Batch 400/511, Loss: 0.0624, Acc: 96.47%\n",
            "Epoch 12, Batch 450/511, Loss: 0.0206, Acc: 96.47%\n",
            "Epoch 12, Batch 500/511, Loss: 0.0234, Acc: 96.50%\n",
            "Epoch 12/50:\n",
            "  Train Loss: 0.1487, Train Acc: 96.51%\n",
            "  Val Loss: 0.1662, Val Acc: 96.80%\n",
            "  LR: 0.001000\n",
            "Epoch 13, Batch 0/511, Loss: 0.3787, Acc: 96.88%\n",
            "Epoch 13, Batch 50/511, Loss: 0.0224, Acc: 96.37%\n",
            "Epoch 13, Batch 100/511, Loss: 0.0141, Acc: 96.69%\n",
            "Epoch 13, Batch 150/511, Loss: 0.0181, Acc: 96.62%\n",
            "Epoch 13, Batch 200/511, Loss: 0.0743, Acc: 96.68%\n",
            "Epoch 13, Batch 250/511, Loss: 0.2762, Acc: 96.82%\n",
            "Epoch 13, Batch 300/511, Loss: 0.0059, Acc: 96.89%\n",
            "Epoch 13, Batch 350/511, Loss: 0.3371, Acc: 96.94%\n",
            "Epoch 13, Batch 400/511, Loss: 0.0629, Acc: 97.03%\n",
            "Epoch 13, Batch 450/511, Loss: 0.0303, Acc: 97.10%\n",
            "Epoch 13, Batch 500/511, Loss: 0.0437, Acc: 97.07%\n",
            "Epoch 13/50:\n",
            "  Train Loss: 0.1350, Train Acc: 97.08%\n",
            "  Val Loss: 0.3590, Val Acc: 91.78%\n",
            "  LR: 0.001000\n",
            "Epoch 14, Batch 0/511, Loss: 0.1333, Acc: 96.09%\n",
            "Epoch 14, Batch 50/511, Loss: 0.0170, Acc: 96.71%\n",
            "Epoch 14, Batch 100/511, Loss: 0.0995, Acc: 96.94%\n",
            "Epoch 14, Batch 150/511, Loss: 0.0134, Acc: 97.11%\n",
            "Epoch 14, Batch 200/511, Loss: 0.0903, Acc: 97.03%\n",
            "Epoch 14, Batch 250/511, Loss: 0.4952, Acc: 97.02%\n",
            "Epoch 14, Batch 300/511, Loss: 0.0555, Acc: 96.95%\n",
            "Epoch 14, Batch 350/511, Loss: 0.0701, Acc: 96.85%\n",
            "Epoch 14, Batch 400/511, Loss: 0.0472, Acc: 96.98%\n",
            "Epoch 14, Batch 450/511, Loss: 0.1010, Acc: 97.02%\n",
            "Epoch 14, Batch 500/511, Loss: 0.0619, Acc: 97.03%\n",
            "Epoch 14/50:\n",
            "  Train Loss: 0.1375, Train Acc: 97.04%\n",
            "  Val Loss: 0.1875, Val Acc: 97.85%\n",
            "  LR: 0.000500\n",
            "Epoch 15, Batch 0/511, Loss: 0.0226, Acc: 97.66%\n",
            "Epoch 15, Batch 50/511, Loss: 0.0271, Acc: 97.61%\n",
            "Epoch 15, Batch 100/511, Loss: 0.0765, Acc: 97.60%\n",
            "Epoch 15, Batch 150/511, Loss: 0.0311, Acc: 97.68%\n",
            "Epoch 15, Batch 200/511, Loss: 0.0219, Acc: 97.70%\n",
            "Epoch 15, Batch 250/511, Loss: 0.0142, Acc: 97.75%\n",
            "Epoch 15, Batch 300/511, Loss: 0.0170, Acc: 97.74%\n",
            "Epoch 15, Batch 350/511, Loss: 0.0488, Acc: 97.73%\n",
            "Epoch 15, Batch 400/511, Loss: 0.0144, Acc: 97.71%\n",
            "Epoch 15, Batch 450/511, Loss: 0.0362, Acc: 97.70%\n",
            "Epoch 15, Batch 500/511, Loss: 0.1492, Acc: 97.68%\n",
            "Epoch 15/50:\n",
            "  Train Loss: 0.1106, Train Acc: 97.68%\n",
            "  Val Loss: 0.1410, Val Acc: 97.99%\n",
            "  LR: 0.000500\n",
            "  üíæ New best model saved! Val Acc: 97.99%\n",
            "Epoch 16, Batch 0/511, Loss: 0.0244, Acc: 98.44%\n",
            "Epoch 16, Batch 50/511, Loss: 1.8900, Acc: 98.18%\n",
            "Epoch 16, Batch 100/511, Loss: 0.0311, Acc: 97.80%\n",
            "Epoch 16, Batch 150/511, Loss: 0.0100, Acc: 97.89%\n",
            "Epoch 16, Batch 200/511, Loss: 0.0101, Acc: 97.89%\n",
            "Epoch 16, Batch 250/511, Loss: 0.0327, Acc: 97.87%\n",
            "Epoch 16, Batch 300/511, Loss: 0.0162, Acc: 97.84%\n",
            "Epoch 16, Batch 350/511, Loss: 0.0173, Acc: 97.82%\n",
            "Epoch 16, Batch 400/511, Loss: 0.0347, Acc: 97.81%\n",
            "Epoch 16, Batch 450/511, Loss: 0.0887, Acc: 97.81%\n",
            "Epoch 16, Batch 500/511, Loss: 0.5673, Acc: 97.76%\n",
            "Epoch 16/50:\n",
            "  Train Loss: 0.1046, Train Acc: 97.75%\n",
            "  Val Loss: 0.1176, Val Acc: 97.42%\n",
            "  LR: 0.000500\n",
            "Epoch 17, Batch 0/511, Loss: 0.0437, Acc: 96.09%\n",
            "Epoch 17, Batch 50/511, Loss: 0.0227, Acc: 97.87%\n",
            "Epoch 17, Batch 100/511, Loss: 0.0437, Acc: 97.90%\n",
            "Epoch 17, Batch 150/511, Loss: 0.0266, Acc: 97.95%\n",
            "Epoch 17, Batch 200/511, Loss: 0.1014, Acc: 97.94%\n",
            "Epoch 17, Batch 250/511, Loss: 0.1503, Acc: 97.78%\n",
            "Epoch 17, Batch 300/511, Loss: 0.0198, Acc: 97.84%\n",
            "Epoch 17, Batch 350/511, Loss: 0.0252, Acc: 97.90%\n",
            "Epoch 17, Batch 400/511, Loss: 0.0271, Acc: 97.87%\n",
            "Epoch 17, Batch 450/511, Loss: 0.1239, Acc: 97.83%\n",
            "Epoch 17, Batch 500/511, Loss: 0.0707, Acc: 97.83%\n",
            "Epoch 17/50:\n",
            "  Train Loss: 0.0880, Train Acc: 97.84%\n",
            "  Val Loss: 0.2921, Val Acc: 97.56%\n",
            "  LR: 0.000500\n",
            "Epoch 18, Batch 0/511, Loss: 0.0384, Acc: 99.22%\n",
            "Epoch 18, Batch 50/511, Loss: 0.0173, Acc: 98.25%\n",
            "Epoch 18, Batch 100/511, Loss: 0.0201, Acc: 98.39%\n",
            "Epoch 18, Batch 150/511, Loss: 0.0189, Acc: 98.35%\n",
            "Epoch 18, Batch 200/511, Loss: 0.0094, Acc: 98.26%\n",
            "Epoch 18, Batch 250/511, Loss: 0.1550, Acc: 98.28%\n",
            "Epoch 18, Batch 300/511, Loss: 0.0518, Acc: 98.12%\n",
            "Epoch 18, Batch 350/511, Loss: 0.1616, Acc: 98.09%\n",
            "Epoch 18, Batch 400/511, Loss: 0.0645, Acc: 98.09%\n",
            "Epoch 18, Batch 450/511, Loss: 0.0698, Acc: 98.04%\n",
            "Epoch 18, Batch 500/511, Loss: 0.0969, Acc: 98.03%\n",
            "Epoch 18/50:\n",
            "  Train Loss: 0.1077, Train Acc: 98.03%\n",
            "  Val Loss: 0.1527, Val Acc: 97.87%\n",
            "  LR: 0.000500\n",
            "Epoch 19, Batch 0/511, Loss: 0.0205, Acc: 98.44%\n",
            "Epoch 19, Batch 50/511, Loss: 0.8832, Acc: 98.44%\n",
            "Epoch 19, Batch 100/511, Loss: 0.0159, Acc: 98.17%\n",
            "Epoch 19, Batch 150/511, Loss: 0.1495, Acc: 98.19%\n",
            "Epoch 19, Batch 200/511, Loss: 0.0727, Acc: 98.12%\n",
            "Epoch 19, Batch 250/511, Loss: 0.0319, Acc: 98.08%\n",
            "Epoch 19, Batch 300/511, Loss: 0.0220, Acc: 98.11%\n",
            "Epoch 19, Batch 350/511, Loss: 0.0196, Acc: 97.99%\n",
            "Epoch 19, Batch 400/511, Loss: 0.0184, Acc: 97.90%\n",
            "Epoch 19, Batch 450/511, Loss: 0.0725, Acc: 97.92%\n",
            "Epoch 19, Batch 500/511, Loss: 0.0537, Acc: 97.88%\n",
            "Epoch 19/50:\n",
            "  Train Loss: 0.0942, Train Acc: 97.88%\n",
            "  Val Loss: 0.1338, Val Acc: 98.04%\n",
            "  LR: 0.000500\n",
            "  üíæ New best model saved! Val Acc: 98.04%\n",
            "Epoch 20, Batch 0/511, Loss: 0.0058, Acc: 99.22%\n",
            "Epoch 20, Batch 50/511, Loss: 0.2162, Acc: 98.24%\n",
            "Epoch 20, Batch 100/511, Loss: 0.0059, Acc: 98.17%\n",
            "Epoch 20, Batch 150/511, Loss: 0.0153, Acc: 98.07%\n",
            "Epoch 20, Batch 200/511, Loss: 0.0065, Acc: 98.02%\n",
            "Epoch 20, Batch 250/511, Loss: 0.0592, Acc: 97.97%\n",
            "Epoch 20, Batch 300/511, Loss: 0.0229, Acc: 97.93%\n",
            "Epoch 20, Batch 350/511, Loss: 0.0102, Acc: 97.91%\n",
            "Epoch 20, Batch 400/511, Loss: 1.0274, Acc: 97.95%\n",
            "Epoch 20, Batch 450/511, Loss: 0.0227, Acc: 98.00%\n",
            "Epoch 20, Batch 500/511, Loss: 0.1158, Acc: 98.00%\n",
            "Epoch 20/50:\n",
            "  Train Loss: 0.0915, Train Acc: 98.00%\n",
            "  Val Loss: 0.2216, Val Acc: 98.77%\n",
            "  LR: 0.000500\n",
            "  üíæ New best model saved! Val Acc: 98.77%\n",
            "Epoch 21, Batch 0/511, Loss: 0.0496, Acc: 96.88%\n",
            "Epoch 21, Batch 50/511, Loss: 0.0769, Acc: 98.18%\n",
            "Epoch 21, Batch 100/511, Loss: 0.0489, Acc: 98.15%\n",
            "Epoch 21, Batch 150/511, Loss: 0.0646, Acc: 98.19%\n",
            "Epoch 21, Batch 200/511, Loss: 0.0213, Acc: 98.16%\n",
            "Epoch 21, Batch 250/511, Loss: 0.0212, Acc: 98.23%\n",
            "Epoch 21, Batch 300/511, Loss: 0.0051, Acc: 98.23%\n",
            "Epoch 21, Batch 350/511, Loss: 1.6397, Acc: 98.27%\n",
            "Epoch 21, Batch 400/511, Loss: 0.0089, Acc: 98.28%\n",
            "Epoch 21, Batch 450/511, Loss: 0.0069, Acc: 98.24%\n",
            "Epoch 21, Batch 500/511, Loss: 0.0895, Acc: 98.16%\n",
            "Epoch 21/50:\n",
            "  Train Loss: 0.0858, Train Acc: 98.15%\n",
            "  Val Loss: 0.1578, Val Acc: 98.29%\n",
            "  LR: 0.000500\n",
            "Epoch 22, Batch 0/511, Loss: 0.0221, Acc: 97.66%\n",
            "Epoch 22, Batch 50/511, Loss: 0.0547, Acc: 98.21%\n",
            "Epoch 22, Batch 100/511, Loss: 0.1047, Acc: 98.17%\n",
            "Epoch 22, Batch 150/511, Loss: 0.0160, Acc: 98.20%\n",
            "Epoch 22, Batch 200/511, Loss: 0.0091, Acc: 98.19%\n",
            "Epoch 22, Batch 250/511, Loss: 0.8768, Acc: 98.16%\n",
            "Epoch 22, Batch 300/511, Loss: 0.0176, Acc: 98.14%\n",
            "Epoch 22, Batch 350/511, Loss: 0.0125, Acc: 98.15%\n",
            "Epoch 22, Batch 400/511, Loss: 0.0123, Acc: 98.13%\n",
            "Epoch 22, Batch 450/511, Loss: 0.0516, Acc: 98.15%\n",
            "Epoch 22, Batch 500/511, Loss: 0.0726, Acc: 98.08%\n",
            "Epoch 22/50:\n",
            "  Train Loss: 0.0767, Train Acc: 98.09%\n",
            "  Val Loss: 0.1491, Val Acc: 98.45%\n",
            "  LR: 0.000250\n",
            "Epoch 23, Batch 0/511, Loss: 0.0121, Acc: 98.44%\n",
            "Epoch 23, Batch 50/511, Loss: 0.0685, Acc: 98.04%\n",
            "Epoch 23, Batch 100/511, Loss: 0.0235, Acc: 98.13%\n",
            "Epoch 23, Batch 150/511, Loss: 0.0074, Acc: 98.19%\n",
            "Epoch 23, Batch 200/511, Loss: 0.0164, Acc: 98.18%\n",
            "Epoch 23, Batch 250/511, Loss: 0.0080, Acc: 98.22%\n",
            "Epoch 23, Batch 300/511, Loss: 0.0671, Acc: 98.26%\n",
            "Epoch 23, Batch 350/511, Loss: 0.6079, Acc: 98.26%\n",
            "Epoch 23, Batch 400/511, Loss: 0.0235, Acc: 98.30%\n",
            "Epoch 23, Batch 450/511, Loss: 0.0170, Acc: 98.35%\n",
            "Epoch 23, Batch 500/511, Loss: 0.6841, Acc: 98.37%\n",
            "Epoch 23/50:\n",
            "  Train Loss: 0.0801, Train Acc: 98.37%\n",
            "  Val Loss: 0.1675, Val Acc: 98.54%\n",
            "  LR: 0.000250\n",
            "Epoch 24, Batch 0/511, Loss: 0.0410, Acc: 96.88%\n",
            "Epoch 24, Batch 50/511, Loss: 0.0055, Acc: 98.56%\n",
            "Epoch 24, Batch 100/511, Loss: 0.0382, Acc: 98.38%\n",
            "Epoch 24, Batch 150/511, Loss: 0.0184, Acc: 98.39%\n",
            "Epoch 24, Batch 200/511, Loss: 0.0013, Acc: 98.46%\n",
            "Epoch 24, Batch 250/511, Loss: 0.1766, Acc: 98.47%\n",
            "Epoch 24, Batch 300/511, Loss: 0.0596, Acc: 98.45%\n",
            "Epoch 24, Batch 350/511, Loss: 0.0456, Acc: 98.48%\n",
            "Epoch 24, Batch 400/511, Loss: 0.0194, Acc: 98.52%\n",
            "Epoch 24, Batch 450/511, Loss: 0.0087, Acc: 98.50%\n",
            "Epoch 24, Batch 500/511, Loss: 0.0456, Acc: 98.51%\n",
            "Epoch 24/50:\n",
            "  Train Loss: 0.0708, Train Acc: 98.52%\n",
            "  Val Loss: 0.1538, Val Acc: 98.35%\n",
            "  LR: 0.000250\n",
            "Epoch 25, Batch 0/511, Loss: 0.0145, Acc: 99.22%\n",
            "Epoch 25, Batch 50/511, Loss: 0.0666, Acc: 98.74%\n",
            "Epoch 25, Batch 100/511, Loss: 0.0121, Acc: 98.70%\n",
            "Epoch 25, Batch 150/511, Loss: 0.0176, Acc: 98.61%\n",
            "Epoch 25, Batch 200/511, Loss: 0.0150, Acc: 98.68%\n",
            "Epoch 25, Batch 250/511, Loss: 0.0298, Acc: 98.66%\n",
            "Epoch 25, Batch 300/511, Loss: 0.0117, Acc: 98.63%\n",
            "Epoch 25, Batch 350/511, Loss: 0.2451, Acc: 98.63%\n",
            "Epoch 25, Batch 400/511, Loss: 0.0081, Acc: 98.64%\n",
            "Epoch 25, Batch 450/511, Loss: 0.0082, Acc: 98.64%\n",
            "Epoch 25, Batch 500/511, Loss: 0.0099, Acc: 98.57%\n",
            "Epoch 25/50:\n",
            "  Train Loss: 0.0715, Train Acc: 98.56%\n",
            "  Val Loss: 0.1816, Val Acc: 98.60%\n",
            "  LR: 0.000250\n",
            "Epoch 26, Batch 0/511, Loss: 0.0204, Acc: 97.66%\n",
            "Epoch 26, Batch 50/511, Loss: 0.3039, Acc: 98.68%\n",
            "Epoch 26, Batch 100/511, Loss: 0.0122, Acc: 98.67%\n",
            "Epoch 26, Batch 150/511, Loss: 0.0307, Acc: 98.61%\n",
            "Epoch 26, Batch 200/511, Loss: 0.0303, Acc: 98.56%\n",
            "Epoch 26, Batch 250/511, Loss: 0.0257, Acc: 98.53%\n",
            "Epoch 26, Batch 300/511, Loss: 0.0123, Acc: 98.52%\n",
            "Epoch 26, Batch 350/511, Loss: 0.0261, Acc: 98.52%\n",
            "Epoch 26, Batch 400/511, Loss: 0.0418, Acc: 98.51%\n",
            "Epoch 26, Batch 450/511, Loss: 0.0026, Acc: 98.53%\n",
            "Epoch 26, Batch 500/511, Loss: 0.0343, Acc: 98.51%\n",
            "Epoch 26/50:\n",
            "  Train Loss: 0.0541, Train Acc: 98.52%\n",
            "  Val Loss: 0.2013, Val Acc: 98.60%\n",
            "  LR: 0.000250\n",
            "Epoch 27, Batch 0/511, Loss: 0.0403, Acc: 95.31%\n",
            "Epoch 27, Batch 50/511, Loss: 0.0050, Acc: 99.11%\n",
            "Epoch 27, Batch 100/511, Loss: 0.0588, Acc: 98.88%\n",
            "Epoch 27, Batch 150/511, Loss: 0.0222, Acc: 98.72%\n",
            "Epoch 27, Batch 200/511, Loss: 0.0158, Acc: 98.59%\n",
            "Epoch 27, Batch 250/511, Loss: 0.0052, Acc: 98.53%\n",
            "Epoch 27, Batch 300/511, Loss: 0.0747, Acc: 98.57%\n",
            "Epoch 27, Batch 350/511, Loss: 0.0166, Acc: 98.52%\n",
            "Epoch 27, Batch 400/511, Loss: 0.2781, Acc: 98.53%\n",
            "Epoch 27, Batch 450/511, Loss: 0.7114, Acc: 98.53%\n",
            "Epoch 27, Batch 500/511, Loss: 0.0148, Acc: 98.51%\n",
            "Epoch 27/50:\n",
            "  Train Loss: 0.0690, Train Acc: 98.51%\n",
            "  Val Loss: 0.1541, Val Acc: 97.85%\n",
            "  LR: 0.000250\n",
            "Epoch 28, Batch 0/511, Loss: 0.2132, Acc: 96.09%\n",
            "Epoch 28, Batch 50/511, Loss: 0.0250, Acc: 98.61%\n",
            "Epoch 28, Batch 100/511, Loss: 0.0147, Acc: 98.55%\n",
            "Epoch 28, Batch 150/511, Loss: 0.0033, Acc: 98.68%\n",
            "Epoch 28, Batch 200/511, Loss: 0.0158, Acc: 98.63%\n",
            "Epoch 28, Batch 250/511, Loss: 0.6020, Acc: 98.55%\n",
            "Epoch 28, Batch 300/511, Loss: 0.0286, Acc: 98.50%\n",
            "Epoch 28, Batch 350/511, Loss: 0.0159, Acc: 98.51%\n",
            "Epoch 28, Batch 400/511, Loss: 0.0144, Acc: 98.58%\n",
            "Epoch 28, Batch 450/511, Loss: 0.0765, Acc: 98.58%\n",
            "Epoch 28, Batch 500/511, Loss: 0.0532, Acc: 98.61%\n",
            "Epoch 28/50:\n",
            "  Train Loss: 0.0605, Train Acc: 98.61%\n",
            "  Val Loss: 0.2447, Val Acc: 98.89%\n",
            "  LR: 0.000125\n",
            "  üíæ New best model saved! Val Acc: 98.89%\n",
            "Epoch 29, Batch 0/511, Loss: 0.0439, Acc: 97.66%\n",
            "Epoch 29, Batch 50/511, Loss: 0.0033, Acc: 98.88%\n",
            "Epoch 29, Batch 100/511, Loss: 0.2708, Acc: 98.76%\n",
            "Epoch 29, Batch 150/511, Loss: 0.0220, Acc: 98.88%\n",
            "Epoch 29, Batch 200/511, Loss: 2.1950, Acc: 98.81%\n",
            "Epoch 29, Batch 250/511, Loss: 0.0056, Acc: 98.74%\n",
            "Epoch 29, Batch 300/511, Loss: 0.0135, Acc: 98.70%\n",
            "Epoch 29, Batch 350/511, Loss: 0.0247, Acc: 98.68%\n",
            "Epoch 29, Batch 400/511, Loss: 0.0133, Acc: 98.70%\n",
            "Epoch 29, Batch 450/511, Loss: 0.0041, Acc: 98.71%\n",
            "Epoch 29, Batch 500/511, Loss: 0.0939, Acc: 98.70%\n",
            "Epoch 29/50:\n",
            "  Train Loss: 0.0622, Train Acc: 98.70%\n",
            "  Val Loss: 0.1879, Val Acc: 98.53%\n",
            "  LR: 0.000125\n",
            "Epoch 30, Batch 0/511, Loss: 0.0050, Acc: 99.22%\n",
            "Epoch 30, Batch 50/511, Loss: 0.1313, Acc: 98.47%\n",
            "Epoch 30, Batch 100/511, Loss: 1.6382, Acc: 98.48%\n",
            "Epoch 30, Batch 150/511, Loss: 0.0154, Acc: 98.44%\n",
            "Epoch 30, Batch 200/511, Loss: 0.0108, Acc: 98.49%\n",
            "Epoch 30, Batch 250/511, Loss: 0.0621, Acc: 98.57%\n",
            "Epoch 30, Batch 300/511, Loss: 0.0262, Acc: 98.56%\n",
            "Epoch 30, Batch 350/511, Loss: 0.0110, Acc: 98.56%\n",
            "Epoch 30, Batch 400/511, Loss: 0.0353, Acc: 98.61%\n",
            "Epoch 30, Batch 450/511, Loss: 0.0073, Acc: 98.62%\n",
            "Epoch 30, Batch 500/511, Loss: 0.0361, Acc: 98.64%\n",
            "Epoch 30/50:\n",
            "  Train Loss: 0.0698, Train Acc: 98.64%\n",
            "  Val Loss: 0.1827, Val Acc: 98.71%\n",
            "  LR: 0.000125\n",
            "Epoch 31, Batch 0/511, Loss: 0.0086, Acc: 98.44%\n",
            "Epoch 31, Batch 50/511, Loss: 0.0030, Acc: 98.94%\n",
            "Epoch 31, Batch 100/511, Loss: 0.0140, Acc: 98.83%\n",
            "Epoch 31, Batch 150/511, Loss: 0.0121, Acc: 98.81%\n",
            "Epoch 31, Batch 200/511, Loss: 0.0025, Acc: 98.76%\n",
            "Epoch 31, Batch 250/511, Loss: 0.0110, Acc: 98.75%\n",
            "Epoch 31, Batch 300/511, Loss: 0.0040, Acc: 98.75%\n",
            "Epoch 31, Batch 350/511, Loss: 0.0098, Acc: 98.73%\n",
            "Epoch 31, Batch 400/511, Loss: 0.0031, Acc: 98.74%\n",
            "Epoch 31, Batch 450/511, Loss: 0.0084, Acc: 98.70%\n",
            "Epoch 31, Batch 500/511, Loss: 0.0037, Acc: 98.72%\n",
            "Epoch 31/50:\n",
            "  Train Loss: 0.0488, Train Acc: 98.72%\n",
            "  Val Loss: 0.2549, Val Acc: 98.68%\n",
            "  LR: 0.000125\n",
            "Epoch 32, Batch 0/511, Loss: 0.5600, Acc: 99.22%\n",
            "Epoch 32, Batch 50/511, Loss: 0.0288, Acc: 98.68%\n",
            "Epoch 32, Batch 100/511, Loss: 0.0256, Acc: 98.77%\n",
            "Epoch 32, Batch 150/511, Loss: 0.0143, Acc: 98.65%\n",
            "Epoch 32, Batch 200/511, Loss: 0.0031, Acc: 98.66%\n",
            "Epoch 32, Batch 250/511, Loss: 0.4379, Acc: 98.61%\n",
            "Epoch 32, Batch 300/511, Loss: 0.0059, Acc: 98.63%\n",
            "Epoch 32, Batch 350/511, Loss: 0.0297, Acc: 98.65%\n",
            "Epoch 32, Batch 400/511, Loss: 0.0063, Acc: 98.65%\n",
            "Epoch 32, Batch 450/511, Loss: 0.0074, Acc: 98.67%\n",
            "Epoch 32, Batch 500/511, Loss: 0.0094, Acc: 98.67%\n",
            "Epoch 32/50:\n",
            "  Train Loss: 0.0665, Train Acc: 98.67%\n",
            "  Val Loss: 0.2010, Val Acc: 98.73%\n",
            "  LR: 0.000125\n",
            "Epoch 33, Batch 0/511, Loss: 0.0185, Acc: 98.44%\n",
            "Epoch 33, Batch 50/511, Loss: 0.0551, Acc: 98.79%\n",
            "Epoch 33, Batch 100/511, Loss: 0.0314, Acc: 98.73%\n",
            "Epoch 33, Batch 150/511, Loss: 0.0072, Acc: 98.72%\n",
            "Epoch 33, Batch 200/511, Loss: 0.0215, Acc: 98.61%\n",
            "Epoch 33, Batch 250/511, Loss: 0.0054, Acc: 98.67%\n",
            "Epoch 33, Batch 300/511, Loss: 0.0191, Acc: 98.70%\n",
            "Epoch 33, Batch 350/511, Loss: 0.0008, Acc: 98.71%\n",
            "Epoch 33, Batch 400/511, Loss: 0.0318, Acc: 98.72%\n",
            "Epoch 33, Batch 450/511, Loss: 0.0102, Acc: 98.71%\n",
            "Epoch 33, Batch 500/511, Loss: 0.0197, Acc: 98.70%\n",
            "Epoch 33/50:\n",
            "  Train Loss: 0.0564, Train Acc: 98.71%\n",
            "  Val Loss: 0.2021, Val Acc: 98.73%\n",
            "  LR: 0.000125\n",
            "Epoch 34, Batch 0/511, Loss: 0.3971, Acc: 96.88%\n",
            "Epoch 34, Batch 50/511, Loss: 0.0078, Acc: 98.64%\n",
            "Epoch 34, Batch 100/511, Loss: 0.0375, Acc: 98.71%\n",
            "Epoch 34, Batch 150/511, Loss: 0.0045, Acc: 98.75%\n",
            "Epoch 34, Batch 200/511, Loss: 0.0366, Acc: 98.78%\n",
            "Epoch 34, Batch 250/511, Loss: 0.0054, Acc: 98.75%\n",
            "Epoch 34, Batch 300/511, Loss: 0.0954, Acc: 98.78%\n",
            "Epoch 34, Batch 350/511, Loss: 0.0757, Acc: 98.73%\n",
            "Epoch 34, Batch 400/511, Loss: 0.0046, Acc: 98.76%\n",
            "Epoch 34, Batch 450/511, Loss: 0.0028, Acc: 98.75%\n",
            "Epoch 34, Batch 500/511, Loss: 0.0145, Acc: 98.75%\n",
            "Epoch 34/50:\n",
            "  Train Loss: 0.0518, Train Acc: 98.75%\n",
            "  Val Loss: 0.1967, Val Acc: 98.58%\n",
            "  LR: 0.000063\n",
            "Epoch 35, Batch 0/511, Loss: 0.0083, Acc: 99.22%\n",
            "Epoch 35, Batch 50/511, Loss: 0.0067, Acc: 98.91%\n",
            "Epoch 35, Batch 100/511, Loss: 0.0033, Acc: 98.88%\n",
            "Epoch 35, Batch 150/511, Loss: 0.0121, Acc: 98.90%\n",
            "Epoch 35, Batch 200/511, Loss: 0.1376, Acc: 98.87%\n",
            "Epoch 35, Batch 250/511, Loss: 0.0194, Acc: 98.79%\n",
            "Epoch 35, Batch 300/511, Loss: 0.0144, Acc: 98.79%\n",
            "Epoch 35, Batch 350/511, Loss: 0.0068, Acc: 98.80%\n",
            "Epoch 35, Batch 400/511, Loss: 0.0012, Acc: 98.79%\n",
            "Epoch 35, Batch 450/511, Loss: 0.1083, Acc: 98.80%\n",
            "Epoch 35, Batch 500/511, Loss: 0.0202, Acc: 98.79%\n",
            "Epoch 35/50:\n",
            "  Train Loss: 0.0512, Train Acc: 98.79%\n",
            "  Val Loss: 0.2079, Val Acc: 98.75%\n",
            "  LR: 0.000063\n",
            "Epoch 36, Batch 0/511, Loss: 0.0252, Acc: 100.00%\n",
            "Epoch 36, Batch 50/511, Loss: 0.0186, Acc: 98.81%\n",
            "Epoch 36, Batch 100/511, Loss: 0.0259, Acc: 98.86%\n",
            "Epoch 36, Batch 150/511, Loss: 0.1250, Acc: 98.82%\n",
            "Epoch 36, Batch 200/511, Loss: 0.5499, Acc: 98.85%\n",
            "Epoch 36, Batch 250/511, Loss: 0.0083, Acc: 98.88%\n",
            "Epoch 36, Batch 300/511, Loss: 0.0065, Acc: 98.88%\n",
            "Epoch 36, Batch 350/511, Loss: 0.0099, Acc: 98.87%\n",
            "Epoch 36, Batch 400/511, Loss: 0.0185, Acc: 98.85%\n",
            "Epoch 36, Batch 450/511, Loss: 0.0156, Acc: 98.86%\n",
            "Epoch 36, Batch 500/511, Loss: 0.0104, Acc: 98.84%\n",
            "Epoch 36/50:\n",
            "  Train Loss: 0.0476, Train Acc: 98.84%\n",
            "  Val Loss: 0.2137, Val Acc: 98.72%\n",
            "  LR: 0.000063\n",
            "Epoch 37, Batch 0/511, Loss: 0.0069, Acc: 99.22%\n",
            "Epoch 37, Batch 50/511, Loss: 0.0481, Acc: 98.74%\n",
            "Epoch 37, Batch 100/511, Loss: 0.0494, Acc: 98.84%\n",
            "Epoch 37, Batch 150/511, Loss: 0.0353, Acc: 98.86%\n",
            "Epoch 37, Batch 200/511, Loss: 0.0014, Acc: 98.86%\n",
            "Epoch 37, Batch 250/511, Loss: 0.0075, Acc: 98.87%\n",
            "Epoch 37, Batch 300/511, Loss: 0.0177, Acc: 98.87%\n",
            "Epoch 37, Batch 350/511, Loss: 0.0761, Acc: 98.84%\n",
            "Epoch 37, Batch 400/511, Loss: 0.0042, Acc: 98.84%\n",
            "Epoch 37, Batch 450/511, Loss: 0.0040, Acc: 98.86%\n",
            "Epoch 37, Batch 500/511, Loss: 0.0013, Acc: 98.86%\n",
            "Epoch 37/50:\n",
            "  Train Loss: 0.0396, Train Acc: 98.86%\n",
            "  Val Loss: 0.2206, Val Acc: 98.90%\n",
            "  LR: 0.000063\n",
            "  üíæ New best model saved! Val Acc: 98.90%\n",
            "Epoch 38, Batch 0/511, Loss: 0.0075, Acc: 100.00%\n",
            "Epoch 38, Batch 50/511, Loss: 0.0013, Acc: 99.00%\n",
            "Epoch 38, Batch 100/511, Loss: 0.0396, Acc: 98.96%\n",
            "Epoch 38, Batch 150/511, Loss: 0.0055, Acc: 98.94%\n",
            "Epoch 38, Batch 200/511, Loss: 0.0096, Acc: 98.94%\n",
            "Epoch 38, Batch 250/511, Loss: 0.0099, Acc: 98.93%\n",
            "Epoch 38, Batch 300/511, Loss: 0.0019, Acc: 98.91%\n",
            "Epoch 38, Batch 350/511, Loss: 0.0196, Acc: 98.88%\n",
            "Epoch 38, Batch 400/511, Loss: 0.1097, Acc: 98.86%\n",
            "Epoch 38, Batch 450/511, Loss: 0.0054, Acc: 98.85%\n",
            "Epoch 38, Batch 500/511, Loss: 0.0194, Acc: 98.87%\n",
            "Epoch 38/50:\n",
            "  Train Loss: 0.0559, Train Acc: 98.88%\n",
            "  Val Loss: 0.2317, Val Acc: 98.81%\n",
            "  LR: 0.000063\n",
            "Epoch 39, Batch 0/511, Loss: 0.0096, Acc: 99.22%\n",
            "Epoch 39, Batch 50/511, Loss: 0.0090, Acc: 98.97%\n",
            "Epoch 39, Batch 100/511, Loss: 0.0078, Acc: 98.94%\n",
            "Epoch 39, Batch 150/511, Loss: 0.2882, Acc: 98.90%\n",
            "Epoch 39, Batch 200/511, Loss: 0.0054, Acc: 98.89%\n",
            "Epoch 39, Batch 250/511, Loss: 0.0172, Acc: 98.90%\n",
            "Epoch 39, Batch 300/511, Loss: 0.0006, Acc: 98.90%\n",
            "Epoch 39, Batch 350/511, Loss: 0.0116, Acc: 98.90%\n",
            "Epoch 39, Batch 400/511, Loss: 0.0053, Acc: 98.90%\n",
            "Epoch 39, Batch 450/511, Loss: 0.0131, Acc: 98.90%\n",
            "Epoch 39, Batch 500/511, Loss: 0.0013, Acc: 98.92%\n",
            "Epoch 39/50:\n",
            "  Train Loss: 0.0464, Train Acc: 98.91%\n",
            "  Val Loss: 0.2598, Val Acc: 98.90%\n",
            "  LR: 0.000063\n",
            "  üíæ New best model saved! Val Acc: 98.90%\n",
            "Epoch 40, Batch 0/511, Loss: 0.0567, Acc: 96.09%\n",
            "Epoch 40, Batch 50/511, Loss: 0.0025, Acc: 98.87%\n",
            "Epoch 40, Batch 100/511, Loss: 0.0082, Acc: 98.96%\n",
            "Epoch 40, Batch 150/511, Loss: 0.0230, Acc: 99.04%\n",
            "Epoch 40, Batch 200/511, Loss: 0.0272, Acc: 98.98%\n",
            "Epoch 40, Batch 250/511, Loss: 0.1074, Acc: 98.97%\n",
            "Epoch 40, Batch 300/511, Loss: 0.0085, Acc: 98.96%\n",
            "Epoch 40, Batch 350/511, Loss: 0.0614, Acc: 98.96%\n",
            "Epoch 40, Batch 400/511, Loss: 0.0099, Acc: 98.92%\n",
            "Epoch 40, Batch 450/511, Loss: 0.5860, Acc: 98.91%\n",
            "Epoch 40, Batch 500/511, Loss: 0.0121, Acc: 98.90%\n",
            "Epoch 40/50:\n",
            "  Train Loss: 0.0452, Train Acc: 98.90%\n",
            "  Val Loss: 0.2182, Val Acc: 98.83%\n",
            "  LR: 0.000031\n",
            "Epoch 41, Batch 0/511, Loss: 0.0029, Acc: 100.00%\n",
            "Epoch 41, Batch 50/511, Loss: 0.4912, Acc: 99.08%\n",
            "Epoch 41, Batch 100/511, Loss: 0.0038, Acc: 99.07%\n",
            "Epoch 41, Batch 150/511, Loss: 0.0169, Acc: 98.99%\n",
            "Epoch 41, Batch 200/511, Loss: 0.0425, Acc: 99.01%\n",
            "Epoch 41, Batch 250/511, Loss: 0.0036, Acc: 99.00%\n",
            "Epoch 41, Batch 300/511, Loss: 0.0088, Acc: 98.97%\n",
            "Epoch 41, Batch 350/511, Loss: 0.0039, Acc: 98.96%\n",
            "Epoch 41, Batch 400/511, Loss: 0.0081, Acc: 98.92%\n",
            "Epoch 41, Batch 450/511, Loss: 0.0052, Acc: 98.93%\n",
            "Epoch 41, Batch 500/511, Loss: 0.0334, Acc: 98.93%\n",
            "Epoch 41/50:\n",
            "  Train Loss: 0.0535, Train Acc: 98.94%\n",
            "  Val Loss: 0.2337, Val Acc: 98.83%\n",
            "  LR: 0.000031\n",
            "Epoch 42, Batch 0/511, Loss: 0.0129, Acc: 98.44%\n",
            "Epoch 42, Batch 50/511, Loss: 0.0119, Acc: 98.94%\n",
            "Epoch 42, Batch 100/511, Loss: 0.0001, Acc: 98.97%\n",
            "Epoch 42, Batch 150/511, Loss: 0.0025, Acc: 99.01%\n",
            "Epoch 42, Batch 200/511, Loss: 0.0041, Acc: 98.99%\n",
            "Epoch 42, Batch 250/511, Loss: 0.0140, Acc: 99.01%\n",
            "Epoch 42, Batch 300/511, Loss: 0.0163, Acc: 99.02%\n",
            "Epoch 42, Batch 350/511, Loss: 0.0371, Acc: 99.02%\n",
            "Epoch 42, Batch 400/511, Loss: 0.2800, Acc: 99.01%\n",
            "Epoch 42, Batch 450/511, Loss: 0.0502, Acc: 99.00%\n",
            "Epoch 42, Batch 500/511, Loss: 0.0171, Acc: 99.01%\n",
            "Epoch 42/50:\n",
            "  Train Loss: 0.0396, Train Acc: 99.01%\n",
            "  Val Loss: 0.2415, Val Acc: 98.88%\n",
            "  LR: 0.000031\n",
            "Epoch 43, Batch 0/511, Loss: 0.0082, Acc: 98.44%\n",
            "Epoch 43, Batch 50/511, Loss: 0.4485, Acc: 98.87%\n",
            "Epoch 43, Batch 100/511, Loss: 0.0049, Acc: 98.85%\n",
            "Epoch 43, Batch 150/511, Loss: 0.0205, Acc: 98.83%\n",
            "Epoch 43, Batch 200/511, Loss: 0.0043, Acc: 98.83%\n",
            "Epoch 43, Batch 250/511, Loss: 0.0173, Acc: 98.85%\n",
            "Epoch 43, Batch 300/511, Loss: 0.1429, Acc: 98.86%\n",
            "Epoch 43, Batch 350/511, Loss: 0.0497, Acc: 98.87%\n",
            "Epoch 43, Batch 400/511, Loss: 0.0018, Acc: 98.88%\n",
            "Epoch 43, Batch 450/511, Loss: 0.0141, Acc: 98.91%\n",
            "Epoch 43, Batch 500/511, Loss: 0.0266, Acc: 98.93%\n",
            "Epoch 43/50:\n",
            "  Train Loss: 0.0566, Train Acc: 98.94%\n",
            "  Val Loss: 0.2312, Val Acc: 98.88%\n",
            "  LR: 0.000031\n",
            "Epoch 44, Batch 0/511, Loss: 0.0082, Acc: 99.22%\n",
            "Epoch 44, Batch 50/511, Loss: 0.0090, Acc: 98.96%\n",
            "Epoch 44, Batch 100/511, Loss: 0.0137, Acc: 98.99%\n",
            "Epoch 44, Batch 150/511, Loss: 0.0536, Acc: 99.05%\n",
            "Epoch 44, Batch 200/511, Loss: 0.0422, Acc: 99.01%\n",
            "Epoch 44, Batch 250/511, Loss: 0.0011, Acc: 99.04%\n",
            "Epoch 44, Batch 300/511, Loss: 0.0019, Acc: 99.03%\n",
            "Epoch 44, Batch 350/511, Loss: 0.1815, Acc: 99.02%\n",
            "Epoch 44, Batch 400/511, Loss: 0.0211, Acc: 99.01%\n",
            "Epoch 44, Batch 450/511, Loss: 0.0156, Acc: 99.01%\n",
            "Epoch 44, Batch 500/511, Loss: 0.0093, Acc: 99.02%\n",
            "Epoch 44/50:\n",
            "  Train Loss: 0.0438, Train Acc: 99.00%\n",
            "  Val Loss: 0.2143, Val Acc: 98.81%\n",
            "  LR: 0.000031\n",
            "Epoch 45, Batch 0/511, Loss: 0.0021, Acc: 100.00%\n",
            "Epoch 45, Batch 50/511, Loss: 0.0059, Acc: 98.96%\n",
            "Epoch 45, Batch 100/511, Loss: 0.0041, Acc: 98.92%\n",
            "Epoch 45, Batch 150/511, Loss: 0.0777, Acc: 98.92%\n",
            "Epoch 45, Batch 200/511, Loss: 0.0096, Acc: 98.95%\n",
            "Epoch 45, Batch 250/511, Loss: 0.1060, Acc: 98.95%\n",
            "Epoch 45, Batch 300/511, Loss: 0.0226, Acc: 98.98%\n",
            "Epoch 45, Batch 350/511, Loss: 0.0618, Acc: 98.98%\n",
            "Epoch 45, Batch 400/511, Loss: 0.0054, Acc: 98.96%\n",
            "Epoch 45, Batch 450/511, Loss: 0.0716, Acc: 98.95%\n",
            "Epoch 45, Batch 500/511, Loss: 0.0145, Acc: 98.96%\n",
            "Epoch 45/50:\n",
            "  Train Loss: 0.0363, Train Acc: 98.96%\n",
            "  Val Loss: 0.2360, Val Acc: 98.85%\n",
            "  LR: 0.000031\n",
            "Epoch 46, Batch 0/511, Loss: 0.0044, Acc: 98.44%\n",
            "Epoch 46, Batch 50/511, Loss: 0.0042, Acc: 98.87%\n",
            "Epoch 46, Batch 100/511, Loss: 0.0026, Acc: 98.96%\n",
            "Epoch 46, Batch 150/511, Loss: 0.0143, Acc: 99.03%\n",
            "Epoch 46, Batch 200/511, Loss: 0.9896, Acc: 99.03%\n",
            "Epoch 46, Batch 250/511, Loss: 0.0050, Acc: 99.03%\n",
            "Epoch 46, Batch 300/511, Loss: 0.0276, Acc: 99.00%\n",
            "Epoch 46, Batch 350/511, Loss: 0.0035, Acc: 98.99%\n",
            "Epoch 46, Batch 400/511, Loss: 0.0095, Acc: 98.99%\n",
            "Epoch 46, Batch 450/511, Loss: 0.0082, Acc: 98.98%\n",
            "Epoch 46, Batch 500/511, Loss: 0.0076, Acc: 98.98%\n",
            "Epoch 46/50:\n",
            "  Train Loss: 0.0455, Train Acc: 98.97%\n",
            "  Val Loss: 0.2434, Val Acc: 98.85%\n",
            "  LR: 0.000016\n",
            "Epoch 47, Batch 0/511, Loss: 0.1421, Acc: 99.22%\n",
            "Epoch 47, Batch 50/511, Loss: 0.0095, Acc: 99.05%\n",
            "Epoch 47, Batch 100/511, Loss: 0.0523, Acc: 99.03%\n",
            "Epoch 47, Batch 150/511, Loss: 0.0139, Acc: 99.03%\n",
            "Epoch 47, Batch 200/511, Loss: 0.0023, Acc: 99.03%\n",
            "Epoch 47, Batch 250/511, Loss: 0.0078, Acc: 99.01%\n",
            "Epoch 47, Batch 300/511, Loss: 0.0430, Acc: 99.00%\n",
            "Epoch 47, Batch 350/511, Loss: 0.0277, Acc: 98.97%\n",
            "Epoch 47, Batch 400/511, Loss: 0.0023, Acc: 98.95%\n",
            "Epoch 47, Batch 450/511, Loss: 0.0011, Acc: 98.96%\n",
            "Epoch 47, Batch 500/511, Loss: 0.0215, Acc: 98.97%\n",
            "Epoch 47/50:\n",
            "  Train Loss: 0.0415, Train Acc: 98.96%\n",
            "  Val Loss: 0.2347, Val Acc: 98.87%\n",
            "  LR: 0.000016\n",
            "Epoch 48, Batch 0/511, Loss: 0.0704, Acc: 98.44%\n",
            "Epoch 48, Batch 50/511, Loss: 0.0132, Acc: 98.77%\n",
            "Epoch 48, Batch 100/511, Loss: 0.0119, Acc: 98.93%\n",
            "Epoch 48, Batch 150/511, Loss: 0.0110, Acc: 98.96%\n",
            "Epoch 48, Batch 200/511, Loss: 0.0015, Acc: 98.98%\n",
            "Epoch 48, Batch 250/511, Loss: 0.0149, Acc: 98.98%\n",
            "Epoch 48, Batch 300/511, Loss: 0.0055, Acc: 98.97%\n",
            "Epoch 48, Batch 350/511, Loss: 0.0350, Acc: 98.96%\n",
            "Epoch 48, Batch 400/511, Loss: 0.0198, Acc: 98.95%\n",
            "Epoch 48, Batch 450/511, Loss: 0.0204, Acc: 98.96%\n",
            "Epoch 48, Batch 500/511, Loss: 0.0150, Acc: 98.98%\n",
            "Epoch 48/50:\n",
            "  Train Loss: 0.0336, Train Acc: 98.98%\n",
            "  Val Loss: 0.2341, Val Acc: 98.84%\n",
            "  LR: 0.000016\n",
            "Epoch 49, Batch 0/511, Loss: 0.0187, Acc: 97.66%\n",
            "Epoch 49, Batch 50/511, Loss: 0.0298, Acc: 98.68%\n",
            "Epoch 49, Batch 100/511, Loss: 0.0052, Acc: 98.86%\n",
            "Epoch 49, Batch 150/511, Loss: 0.0042, Acc: 98.91%\n",
            "Epoch 49, Batch 200/511, Loss: 0.0190, Acc: 98.95%\n",
            "Epoch 49, Batch 250/511, Loss: 0.0863, Acc: 98.98%\n",
            "Epoch 49, Batch 300/511, Loss: 0.0029, Acc: 98.97%\n",
            "Epoch 49, Batch 350/511, Loss: 0.0086, Acc: 98.96%\n",
            "Epoch 49, Batch 400/511, Loss: 0.0100, Acc: 98.93%\n",
            "Epoch 49, Batch 450/511, Loss: 0.0087, Acc: 98.93%\n",
            "Epoch 49, Batch 500/511, Loss: 0.0122, Acc: 98.92%\n",
            "Epoch 49/50:\n",
            "  Train Loss: 0.0405, Train Acc: 98.93%\n",
            "  Val Loss: 0.2403, Val Acc: 98.85%\n",
            "  LR: 0.000016\n",
            "Early stopping triggered after 49 epochs\n",
            "\n",
            "Training completed! Best validation accuracy: 98.90%\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Parent directory /content/drive/MyDrive/ColabData/ECG does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3092722069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0mfinal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ColabData/ECG/ecg_mitbih_finetuned_improved.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final model saved to: {final_model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             _save(\n\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             super().__init__(\n\u001b[0;32m--> 792\u001b[0;31m                 torch._C.PyTorchFileWriter(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_crc32_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_storage_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/ColabData/ECG does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE6Kec2wBfH8",
        "outputId": "4a205e53-9611-4170-c22c-d64bfc2160ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on test set...\n",
            "\n",
            "==================================================\n",
            "COMPREHENSIVE EVALUATION RESULTS\n",
            "==================================================\n",
            "\n",
            "Overall Accuracy: 0.9887\n",
            "Weighted Precision: 0.9891\n",
            "Weighted Recall: 0.9887\n",
            "Weighted F1-Score: 0.9888\n",
            "\n",
            "Macro-averaged Metrics:\n",
            "Macro Precision: 0.9205\n",
            "Macro Recall: 0.9590\n",
            "Macro F1-Score: 0.9384\n",
            "\n",
            "Detailed Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "          Normal     0.9965    0.9921    0.9943     17972\n",
            "Supraventricular     0.8815    0.9203    0.9005       590\n",
            "     Ventricular     0.9730    0.9786    0.9758      1401\n",
            "          Fusion     0.7684    0.9125    0.8343       160\n",
            "         Unknown     0.9830    0.9917    0.9873      1691\n",
            "\n",
            "        accuracy                         0.9887     21814\n",
            "       macro avg     0.9205    0.9590    0.9384     21814\n",
            "    weighted avg     0.9891    0.9887    0.9888     21814\n",
            "\n",
            "\n",
            "Multiclass ROC-AUC Score: 0.9968\n",
            "\n",
            "Per-class AUC scores:\n",
            "  Normal: 0.9985\n",
            "  Supraventricular: 0.9933\n",
            "  Ventricular: 0.9996\n",
            "  Fusion: 0.9933\n",
            "  Unknown: 0.9993\n",
            "\n",
            "Per-class Performance:\n",
            "  Normal          - Precision: 0.9965, Recall: 0.9921, F1: 0.9943, Support: 17972\n",
            "  Supraventricular - Precision: 0.8815, Recall: 0.9203, F1: 0.9005, Support: 590\n",
            "  Ventricular     - Precision: 0.9730, Recall: 0.9786, F1: 0.9758, Support: 1401\n",
            "  Fusion          - Precision: 0.7684, Recall: 0.9125, F1: 0.8343, Support: 160\n",
            "  Unknown         - Precision: 0.9830, Recall: 0.9917, F1: 0.9873, Support: 1691\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Evaluation\n",
        "model.eval()\n",
        "all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "print(\"Evaluating model on test set...\")\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # Convert log_softmax to probabilities if needed\n",
        "        if hasattr(model, 'forward') and 'log_softmax' in str(model.forward):\n",
        "            probs = torch.exp(outputs)  # Convert log-probabilities to probabilities\n",
        "        else:\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y_batch.numpy())\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "# Class names for better reporting\n",
        "class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COMPREHENSIVE EVALUATION RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"\\nOverall Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n",
        "print(f\"Weighted Precision: {precision_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
        "print(f\"Weighted Recall: {recall_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
        "print(f\"Weighted F1-Score: {f1_score(all_labels, all_preds, average='weighted'):.4f}\")\n",
        "\n",
        "print(f\"\\nMacro-averaged Metrics:\")\n",
        "print(f\"Macro Precision: {precision_score(all_labels, all_preds, average='macro'):.4f}\")\n",
        "print(f\"Macro Recall: {recall_score(all_labels, all_preds, average='macro'):.4f}\")\n",
        "print(f\"Macro F1-Score: {f1_score(all_labels, all_preds, average='macro'):.4f}\")\n",
        "\n",
        "print(f\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
        "\n",
        "# ROC-AUC Score (if all classes are present)\n",
        "try:\n",
        "    present_classes = np.unique(all_labels)\n",
        "    if len(present_classes) == 5:\n",
        "        y_true_bin = np.eye(5)[all_labels]\n",
        "        auc_score = roc_auc_score(y_true_bin, all_probs, multi_class='ovr')\n",
        "        print(f\"\\nMulticlass ROC-AUC Score: {auc_score:.4f}\")\n",
        "\n",
        "        print(f\"\\nPer-class AUC scores:\")\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            if i in present_classes:\n",
        "                fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "                class_auc = auc(fpr, tpr)\n",
        "                print(f\"  {class_name}: {class_auc:.4f}\")\n",
        "    else:\n",
        "        print(f\"Note: Only {len(present_classes)} classes present in test set, skipping ROC-AUC\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ROC-AUC calculation error: {e}\")\n",
        "\n",
        "# Per-class metrics\n",
        "print(f\"\\nPer-class Performance:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    if i in present_classes:\n",
        "        class_precision = precision_score(all_labels, all_preds, labels=[i], average=None)\n",
        "        class_recall = recall_score(all_labels, all_preds, labels=[i], average=None)\n",
        "        class_f1 = f1_score(all_labels, all_preds, labels=[i], average=None)\n",
        "        class_support = np.sum(all_labels == i)\n",
        "\n",
        "        if len(class_precision) > 0:\n",
        "            print(f\"  {class_name:15} - Precision: {class_precision[0]:.4f}, \"\n",
        "                  f\"Recall: {class_recall[0]:.4f}, F1: {class_f1[0]:.4f}, \"\n",
        "                  f\"Support: {class_support}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "RWHOQBV-BfH8",
        "outputId": "e5e6b498-dac3-49cc-ad37-c40ca1a32584"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Class labels (adjust if your class labels are different)\n",
        "class_names = ['N', 'S', 'V', 'F', 'Q']\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names, cbar=True)\n",
        "\n",
        "plt.title(\"(a) Confusion matrix of proposed model\", fontsize=14)\n",
        "plt.xlabel(\"Predicted label\", fontsize=12)\n",
        "plt.ylabel(\"True label\", fontsize=12)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "3rLLMzg2BfH8",
        "outputId": "b307df3f-b321-4f20-ba66-2e8ff75a1b79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot ROC Curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(5):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"ROC class {i} (area = {roc_auc:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves of All Classes\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing MIT AF Data\n",
        "import os\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import gzip\n",
        "import pickle\n",
        "import neurokit2 as nk\n",
        "from scipy.signal import resample\n",
        "\n",
        "TARGET_SAMPLING_RATE = 125\n",
        "MAX_LEN_AF = 30 * TARGET_SAMPLING_RATE  # 30 seconds\n",
        "\n",
        "# Mapping for 5 categories\n",
        "label_mapping = {\n",
        "    \"AFIB\": 0,\n",
        "    \"AFL\": 1,\n",
        "    \"J\": 2,\n",
        "    \"N\": 3\n",
        "    # anything else will be 4\n",
        "}\n",
        "\n",
        "def downsample_signal(signal, original_fs=250, target_fs=125):\n",
        "    if original_fs == target_fs:\n",
        "        return signal\n",
        "    num_samples = int(len(signal) * target_fs / original_fs)\n",
        "    return resample(signal, num_samples)\n",
        "\n",
        "def normalize_signal(signal):\n",
        "    return (signal - np.min(signal)) / (np.max(signal) - np.min(signal) + 1e-8)\n",
        "\n",
        "def detect_r_peaks(signal, fs=125):\n",
        "    _, rpeaks = nk.ecg_peaks(signal, sampling_rate=fs)\n",
        "    return rpeaks[\"ECG_R_Peaks\"]\n",
        "\n",
        "def extract_t_episodes(signal, r_peaks):\n",
        "    if len(r_peaks) < 2:\n",
        "        return []\n",
        "    rr_intervals = np.diff(r_peaks)\n",
        "    median_rr = int(np.median(rr_intervals))\n",
        "    episodes = []\n",
        "    for r in r_peaks:\n",
        "        start = max(0, r - median_rr // 2)\n",
        "        end = min(len(signal), r + median_rr // 2)\n",
        "        episodes.append((start, end))\n",
        "    return episodes\n",
        "\n",
        "def build_samplewise_labels(record_len, ann_samples, ann_symbols):\n",
        "    labels = np.array([\"\"] * record_len, dtype=object)\n",
        "    ann_samples = np.array(ann_samples)\n",
        "    ann_symbols = np.array(ann_symbols, dtype=object)\n",
        "    if len(ann_samples) == 0:\n",
        "        return labels\n",
        "    order = np.argsort(ann_samples)\n",
        "    ann_samples = ann_samples[order]\n",
        "    ann_symbols = ann_symbols[order]\n",
        "    for i in range(len(ann_samples)):\n",
        "        start = ann_samples[i]\n",
        "        end = ann_samples[i+1] if i+1 < len(ann_samples) else record_len\n",
        "        if start < 0: start = 0\n",
        "        if end > record_len: end = record_len\n",
        "        labels[start:end] = ann_symbols[i]\n",
        "    return labels\n",
        "\n",
        "def get_label(sym):\n",
        "    if sym is None or str(sym).strip() == \"\":\n",
        "        return 4\n",
        "    s = str(sym).strip().upper()\n",
        "    s = s.replace(\"(\", \"\")  # <-- ŒëœÜŒ±ŒπœÅŒµŒØœÇ œÑŒ∑ŒΩ œÄŒ±œÅŒµŒΩŒ∏Œ≠œÉŒ∑\n",
        "    return label_mapping.get(s, 4)\n",
        "\n",
        "\n",
        "def pad_signal(signal, max_len):\n",
        "    if len(signal) < max_len:\n",
        "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
        "    else:\n",
        "        return signal[:max_len]\n",
        "\n",
        "def preprocess_afdb_beats(dataset_dir):\n",
        "    all_beats, all_labels = [], []\n",
        "    for file in os.listdir(dataset_dir):\n",
        "        if file.endswith('.dat'):\n",
        "            recname = os.path.join(dataset_dir, file.replace('.dat', ''))\n",
        "            try:\n",
        "                rec = wfdb.rdrecord(recname)\n",
        "                signal = rec.p_signal[:, 0].astype(np.float32)\n",
        "                fs = rec.fs\n",
        "                # Downsample\n",
        "                signal = downsample_signal(signal, original_fs=fs, target_fs=TARGET_SAMPLING_RATE)\n",
        "                # Read annotations\n",
        "                ann = wfdb.rdann(recname, 'atr')\n",
        "                ann_samples = (np.array(ann.sample) * (TARGET_SAMPLING_RATE / fs)).astype(int)\n",
        "                ann_symbols = ann.aux_note if hasattr(ann, \"aux_note\") else ann.symbol\n",
        "                # Build per-sample labels\n",
        "                sample_labels = build_samplewise_labels(len(signal), ann_samples, ann_symbols)\n",
        "                # Normalize\n",
        "                signal = normalize_signal(signal)\n",
        "                # R-peak detection\n",
        "                r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
        "                # Extract t-episodes\n",
        "                t_episodes = extract_t_episodes(signal, r_peaks)\n",
        "                for (start, end) in t_episodes:\n",
        "                    center = (start + end) // 2\n",
        "                    label = get_label(sample_labels[center])\n",
        "                    beat = signal[start:end]\n",
        "                    padded = pad_signal(beat, MAX_LEN_AF)\n",
        "                    all_beats.append(padded)\n",
        "                    all_labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {recname}, error: {e}\")\n",
        "    return np.array(all_beats), np.array(all_labels)\n",
        "\n",
        "# ŒïŒ∫œÑŒ≠ŒªŒµœÉŒ∑\n",
        "afdb_beats, afdb_labels = preprocess_afdb_beats(\"data/files\")\n",
        "X_afdb = torch.tensor(afdb_beats, dtype=torch.float32)\n",
        "y_afdb = torch.tensor(afdb_labels, dtype=torch.long)\n",
        "with gzip.open(\"afdb_beats_5cat.pkl.gz\", \"wb\") as f:\n",
        "    pickle.dump((X_afdb, y_afdb), f)\n",
        "print(f\"AFDB Beats Shape: {X_afdb.shape}\")\n",
        "print(f\"Unique Labels: {np.unique(afdb_labels, return_counts=True)}\")"
      ],
      "metadata": {
        "id": "OKH104VhSJ4n",
        "outputId": "90b88ecb-e93c-43cb-d402-4286f2c4a83c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFDB Beats Shape: torch.Size([1146813, 3750])\n",
            "Unique Labels: (array([0, 1, 2, 3, 4]), array([513691,  12385,    304, 620429,      4]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pickle, gzip\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from NNModel import ECGClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------\n",
        "# 1. Load AFDB Dataset\n",
        "# --------------------\n",
        "print(\"Loading AFDB data...\")\n",
        "with gzip.open(\"afdb_beats_5cat.pkl.gz\", \"rb\") as f:\n",
        "    X_afdb, y_afdb = pickle.load(f)\n",
        "\n",
        "print(f\"Data shape: {X_afdb.shape}\")\n",
        "print(f\"Labels shape: {y_afdb.shape}\")\n",
        "\n",
        "# Class distribution\n",
        "unique_labels, counts = np.unique(y_afdb, return_counts=True)\n",
        "class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "print(\"\\nClass distribution:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    pct = (count / len(y_afdb)) * 100\n",
        "    print(f\"  Class {label} ({class_names[label]}): {count} samples ({pct:.2f}%)\")\n",
        "\n",
        "# Train/Val/Test split (60/20/20)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_afdb, y_afdb, test_size=0.2, random_state=42, stratify=y_afdb\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        ")\n",
        "print(\"\\nSplits:\")\n",
        "print(f\"  Train: {X_train.shape[0]}  Val: {X_val.shape[0]}  Test: {X_test.shape[0]}\")\n",
        "\n",
        "# --------------------\n",
        "# 2. Dataset + Augmentation\n",
        "# --------------------\n",
        "class ECGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # (B,1,L)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self): return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx].clone()\n",
        "        y = self.y[idx]\n",
        "\n",
        "        if self.augment:\n",
        "            # Gaussian noise\n",
        "            if np.random.rand() < 0.3:\n",
        "                noise = torch.randn_like(x) * 0.01\n",
        "                x += noise\n",
        "            # Random time shift\n",
        "            if np.random.rand() < 0.3:\n",
        "                shift = np.random.randint(-10, 11)\n",
        "                x = torch.roll(x, shifts=shift, dims=-1)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(ECGDataset(X_train, y_train, augment=True),\n",
        "                                           batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(ECGDataset(X_val, y_val, augment=False),\n",
        "                                         batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(ECGDataset(X_test, y_test, augment=False),\n",
        "                                          batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --------------------\n",
        "# 3. Model + Pretrained Weights\n",
        "# --------------------\n",
        "num_classes = 5\n",
        "model = ECGClassifier(num_classes=num_classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "try:\n",
        "    with gzip.open(\"pretrained_model_best.pth.gz\", \"rb\") as f:\n",
        "        pretrained_dict = pickle.load(f)\n",
        "\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
        "                       if not k.startswith(\"fc2\")}\n",
        "    missing, unexpected = model.load_state_dict(pretrained_dict, strict=False)\n",
        "    print(f\"Pretrained loaded. Missing: {len(missing)}  Unexpected: {len(unexpected)}\")\n",
        "\n",
        "    # Reinit final FC\n",
        "    model.fc2 = nn.Linear(model.fc2.in_features, num_classes).to(device)\n",
        "    nn.init.kaiming_normal_(model.fc2.weight)\n",
        "    nn.init.constant_(model.fc2.bias, 0)\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Warning: Could not load pretrained weights ({e}). Training from scratch.\")\n",
        "\n",
        "# --------------------\n",
        "# 4. Loss + Optimizer + Scheduler\n",
        "# --------------------\n",
        "y_train_np = y_train.numpy() if isinstance(y_train, torch.Tensor) else y_train\n",
        "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train_np), y=y_train_np)\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "\n",
        "# --------------------\n",
        "# 5. Training Loop\n",
        "# --------------------\n",
        "num_epochs = 5\n",
        "best_val_acc = 0.0\n",
        "patience, patience_counter = 2, 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (preds == y_batch).sum().item()\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val_batch in val_loader:\n",
        "            X_val, y_val_batch = X_val.to(device), y_val_batch.to(device)\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss += criterion(val_outputs, y_val_batch).item()\n",
        "            _, val_preds = val_outputs.max(1)\n",
        "            val_total += y_val_batch.size(0)\n",
        "            val_correct += (val_preds == y_val_batch).sum().item()\n",
        "\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss {avg_train_loss:.4f} Acc {train_acc:.2f}% | \"\n",
        "          f\"Val Loss {avg_val_loss:.4f} Acc {val_acc:.2f}% | \"\n",
        "          f\"LR {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_afdb_model.pth\")\n",
        "        print(\"  üíæ Saved new best model\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# --------------------\n",
        "# 6. Final Evaluation\n",
        "# --------------------\n",
        "model.load_state_dict(torch.load(\"best_afdb_model.pth\"))\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        preds = model(X_batch).argmax(1)\n",
        "        y_true.extend(y_batch.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "O8py3PwiJU2a",
        "outputId": "6d85d01c-9170-4315-8bcf-d7b8443a1dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECGClassifier(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (resblock1): ResidualBlock(\n",
            "    (conv1): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
            "      (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock2): ResidualBlock(\n",
            "    (conv1): Conv1d(64, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=96, out_features=6, bias=True)\n",
            "      (fc2): Linear(in_features=6, out_features=96, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(64, 96, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock3): ResidualBlock(\n",
            "    (conv1): Conv1d(96, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
            "      (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(96, 128, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (resblock4): ResidualBlock(\n",
            "    (conv1): Conv1d(128, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv1d(160, 160, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (bn2): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (se): SEBlock(\n",
            "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "      (fc1): Linear(in_features=160, out_features=10, bias=True)\n",
            "      (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv1d(128, 160, kernel_size=(1,), stride=(1,))\n",
            "      (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (lstm): LSTM(160, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.3, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=5, bias=True)\n",
            ")\n",
            "Loading AFDB data...\n",
            "Data shape: torch.Size([1146813, 3750])\n",
            "Labels shape: torch.Size([1146813])\n",
            "\n",
            "Class distribution:\n",
            "  Class 0 (Normal): 513691 samples (44.79%)\n",
            "  Class 1 (Supraventricular): 12385 samples (1.08%)\n",
            "  Class 2 (Ventricular): 304 samples (0.03%)\n",
            "  Class 3 (Fusion): 620429 samples (54.10%)\n",
            "  Class 4 (Unknown): 4 samples (0.00%)\n",
            "\n",
            "Splits:\n",
            "  Train: 688087  Val: 229363  Test: 229363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-49829588.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # (B,1,L)\n",
            "/tmp/ipython-input-49829588.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained loaded. Missing: 2  Unexpected: 0\n",
            "Class weights: tensor([4.4650e-01, 1.8519e+01, 7.5614e+02, 3.6968e-01, 6.8809e+04],\n",
            "       device='cuda:0')\n",
            "Epoch 1/5 | Train Loss 0.5138 Acc 89.30% | Val Loss 0.3548 Acc 95.62% | LR 0.001000\n",
            "  üíæ Saved new best model\n",
            "Epoch 2/5 | Train Loss 0.3322 Acc 95.27% | Val Loss 0.2992 Acc 95.54% | LR 0.001000\n",
            "Epoch 3/5 | Train Loss 0.2641 Acc 95.92% | Val Loss 0.1771 Acc 97.39% | LR 0.001000\n",
            "  üíæ Saved new best model\n",
            "Epoch 4/5 | Train Loss 0.2303 Acc 96.23% | Val Loss 0.1979 Acc 97.93% | LR 0.001000\n",
            "  üíæ Saved new best model\n",
            "Epoch 5/5 | Train Loss 0.2099 Acc 96.44% | Val Loss 0.2004 Acc 98.05% | LR 0.001000\n",
            "  üíæ Saved new best model\n",
            "\n",
            "Test Accuracy: 0.9802496479379847\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "          Normal     0.9746    0.9830    0.9788    102738\n",
            "Supraventricular     0.9205    0.9536    0.9367      2477\n",
            "     Ventricular     0.3629    0.7377    0.4865        61\n",
            "          Fusion     0.9868    0.9786    0.9827    124086\n",
            "         Unknown     0.0000    0.0000    0.0000         1\n",
            "\n",
            "        accuracy                         0.9802    229363\n",
            "       macro avg     0.6490    0.7306    0.6770    229363\n",
            "    weighted avg     0.9805    0.9802    0.9803    229363\n",
            "\n",
            "Confusion Matrix:\n",
            " [[100990    160     10   1578      0]\n",
            " [    83   2362      0     32      0]\n",
            " [     8      0     45      8      0]\n",
            " [  2537     44     69 121436      0]\n",
            " [     0      0      0      1      0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# --------------------\n",
        "# ROC Curve (One-vs-Rest for Multiclass)\n",
        "# --------------------\n",
        "model.eval()\n",
        "y_true, y_probs = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        probs = torch.softmax(outputs, dim=1)  # class probabilities\n",
        "        y_true.extend(y_batch.numpy())\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Binarize labels for One-vs-Rest ROC\n",
        "classes = np.unique(y_true)\n",
        "y_true_bin = label_binarize(y_true, classes=classes)\n",
        "\n",
        "# Compute ROC curve and AUC for each class\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, c in enumerate(classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"Class {c} (AUC = {roc_auc:.3f})\")\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--', lw=1)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve (One-vs-Rest)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Macro & weighted AUC\n",
        "print(\"Macro AUC:\", roc_auc_score(y_true_bin, y_probs, average=\"macro\"))\n",
        "print(\"Weighted AUC:\", roc_auc_score(y_true_bin, y_probs, average=\"weighted\"))"
      ],
      "metadata": {
        "id": "kqSxwYDScBpJ",
        "outputId": "bc348568-e8c3-4f7f-a59f-6545de094a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro AUC: 0.9699268317844592\n",
            "Weighted AUC: 0.9979502067786213\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}