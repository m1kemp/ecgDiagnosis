{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysioNet Data Shape: torch.Size([340517, 1250])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import neurokit2 as nk\n",
    "import biosppy.signals.ecg as ecg\n",
    "import torch\n",
    "\n",
    "# Define constants\n",
    "TARGET_SAMPLING_RATE = 125  # Hz\n",
    "MAX_LEN_PHYSIONET = 10 * TARGET_SAMPLING_RATE  # 10 seconds\n",
    "MAX_LEN_MITBIH = 30 * TARGET_SAMPLING_RATE  # 30 seconds\n",
    "\n",
    "# Load PhysioNet dataset\n",
    "def load_physionet_data(path):\n",
    "    \"\"\"Load PhysioNet 2017 dataset from .mat files and reference.csv.\"\"\"\n",
    "    signals, labels = [], []\n",
    "    ref_df = pd.read_csv(os.path.join(path, \"REFERENCE.csv\"), header=None)\n",
    "    ref_dict = dict(zip(ref_df[0], ref_df[1]))\n",
    "    label_mapping = {\"N\": 0, \"A\": 1, \"O\": 2, \"~\": 3}  # Modify as per dataset classes\n",
    "    \n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".mat\"):\n",
    "            record_name = file.replace(\".mat\", \"\")\n",
    "            mat_data = scipy.io.loadmat(os.path.join(path, file))\n",
    "            signal = mat_data[\"val\"][0]  # Extract ECG lead\n",
    "            label = ref_dict.get(record_name, None)\n",
    "            if label:\n",
    "                signals.append(signal)\n",
    "                physionet_labels = label_mapping[label]\n",
    "                labels.append(physionet_labels)\n",
    "\n",
    "    return signals, labels\n",
    "\n",
    "\n",
    "\n",
    "# Downsampling function\n",
    "def downsample_signal(signal, original_fs, target_fs=125):\n",
    "    \"\"\"Downsample ECG signal from original_fs to target_fs.\"\"\"\n",
    "    num_samples = int(len(signal) * target_fs / original_fs)\n",
    "    return scipy.signal.resample(signal, num_samples)\n",
    "\n",
    "# Normalize function\n",
    "def normalize_signal(signal):\n",
    "    \"\"\"Normalize ECG signal between 0 and 1.\"\"\"\n",
    "    return (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "\n",
    "# R-peak detection\n",
    "def detect_r_peaks(signal, sampling_rate=125):\n",
    "    \"\"\"Detect R-peaks using the Pan-Tompkins algorithm.\"\"\"\n",
    "    _, r_peaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate)\n",
    "    return np.array(r_peaks[\"ECG_R_Peaks\"])\n",
    "\n",
    "# Beat segmentation\n",
    "def extract_beats(signal, r_peaks, window_size=0.5, fs=125):\n",
    "    \"\"\"Extract ECG beats centered around R-peaks.\"\"\"\n",
    "    beat_length = int(window_size * fs)\n",
    "    beats = []\n",
    "    for peak in r_peaks:\n",
    "        start = max(0, peak - beat_length)\n",
    "        end = min(len(signal), peak + beat_length)\n",
    "        beat = signal[start:end]\n",
    "        beats.append(beat)\n",
    "    return beats\n",
    "\n",
    "# Zero-padding\n",
    "def pad_signal(signal, max_len=MAX_LEN_PHYSIONET):\n",
    "    \"\"\"Pad signal to max_len with zeros.\"\"\"\n",
    "    if len(signal) < max_len:\n",
    "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
    "    else:\n",
    "        return signal[:max_len]\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_ecg_dataset(dataset_path):\n",
    "    \"\"\"Preprocess ECG dataset from PhysioNet or MIT-BIH.\"\"\"\n",
    "    signals, labels = load_physionet_data(dataset_path)\n",
    "    original_fs = 300  # PhysioNet signals are sampled at 300 Hz\n",
    "    max_len = MAX_LEN_PHYSIONET\n",
    "    processed_signals,processed_labels = [],[]\n",
    "    for signal,label in zip(signals,labels):\n",
    "        # 1. Downsampling\n",
    "        signal = downsample_signal(signal, original_fs, TARGET_SAMPLING_RATE)\n",
    "        # 2. Normalization\n",
    "        signal = normalize_signal(signal)\n",
    "        # 3. R-peak detection\n",
    "        r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
    "        # 4. Beat extraction\n",
    "        beats = extract_beats(signal, r_peaks)\n",
    "        # 5. Zero-padding each beat\n",
    "        padded_beats = [pad_signal(beat, max_len) for beat in beats]\n",
    "        processed_signals.extend(padded_beats)  # Collect all beats\n",
    "        processed_labels.extend([label] * len(padded_beats))  # Assign the same label to all extracted beats\n",
    "\n",
    "    return np.array(processed_signals), np.array(processed_labels)\n",
    "\n",
    "# Example Usage\n",
    "physionet_data, physionet_labels = preprocess_ecg_dataset(\"data/training2017\")\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_physionet = torch.tensor(physionet_data, dtype=torch.float32)\n",
    "y_physionet = torch.tensor(physionet_labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "print(f\"PhysioNet Data Shape: {X_physionet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIT-BIH dataset\n",
    "def load_mitbih_data(path):\n",
    "    \"\"\"Load MIT-BIH dataset from WFDB format.\"\"\"\n",
    "    signals, labels = [], []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".dat\"):\n",
    "            record_name = file.replace(\".dat\", \"\")\n",
    "            record = wfdb.rdsamp(os.path.join(path, record_name))\n",
    "            annotation = wfdb.rdann(os.path.join(path, record_name), 'atr')\n",
    "            signals.append(record[0][:, 0])  # Extract first ECG lead\n",
    "            labels.append(annotation.sample)\n",
    "    return signals, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
