{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lz/f_d309_d5rl3fqjxt475d5nc0000gn/T/ipykernel_5301/2137697392.py\", line 8, in <module>\n",
      "    import torch\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/mpallasmichael/Desktop/ecgDiagnosis/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysioNet Data Shape: torch.Size([340517, 1250])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import neurokit2 as nk\n",
    "import biosppy.signals.ecg as ecg\n",
    "import torch\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# Define constants\n",
    "TARGET_SAMPLING_RATE = 125  # Hz\n",
    "MAX_LEN_PHYSIONET = 10 * TARGET_SAMPLING_RATE  # 10 seconds\n",
    "MAX_LEN_MITBIH = 30 * TARGET_SAMPLING_RATE  # 30 seconds\n",
    "\n",
    "# Load PhysioNet dataset\n",
    "def load_physionet_data(path):\n",
    "    \"\"\"Load PhysioNet 2017 dataset from .mat files and reference.csv.\"\"\"\n",
    "    signals, labels = [], []\n",
    "    ref_df = pd.read_csv(os.path.join(path, \"REFERENCE.csv\"), header=None)\n",
    "    ref_dict = dict(zip(ref_df[0], ref_df[1]))\n",
    "    label_mapping = {\"N\": 0, \"A\": 1, \"O\": 2, \"~\": 3}  # Modify as per dataset classes\n",
    "    \n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".mat\"):\n",
    "            record_name = file.replace(\".mat\", \"\")\n",
    "            mat_data = scipy.io.loadmat(os.path.join(path, file))\n",
    "            signal = mat_data[\"val\"][0]  # Extract ECG lead\n",
    "            label = ref_dict.get(record_name, None)\n",
    "            if label:\n",
    "                signals.append(signal)\n",
    "                physionet_labels = label_mapping[label]\n",
    "                labels.append(physionet_labels)\n",
    "\n",
    "    return signals, labels\n",
    "\n",
    "\n",
    "\n",
    "# Downsampling function\n",
    "def downsample_signal(signal, original_fs, target_fs=125):\n",
    "    \"\"\"Downsample ECG signal from original_fs to target_fs.\"\"\"\n",
    "    num_samples = int(len(signal) * target_fs / original_fs)\n",
    "    return scipy.signal.resample(signal, num_samples)\n",
    "\n",
    "# Normalize function\n",
    "def normalize_signal(signal):\n",
    "    \"\"\"Normalize ECG signal between 0 and 1.\"\"\"\n",
    "    return (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "\n",
    "# R-peak detection\n",
    "def detect_r_peaks(signal, sampling_rate=125):\n",
    "    \"\"\"Detect R-peaks using the Pan-Tompkins algorithm.\"\"\"\n",
    "    _, r_peaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate)\n",
    "    return np.array(r_peaks[\"ECG_R_Peaks\"])\n",
    "\n",
    "# Beat segmentation\n",
    "def extract_beats(signal, r_peaks, window_size=0.5, fs=125):\n",
    "    \"\"\"Extract ECG beats centered around R-peaks.\"\"\"\n",
    "    beat_length = int(window_size * fs)\n",
    "    beats = []\n",
    "    for peak in r_peaks:\n",
    "        start = max(0, peak - beat_length)\n",
    "        end = min(len(signal), peak + beat_length)\n",
    "        beat = signal[start:end]\n",
    "        beats.append(beat)\n",
    "    return beats\n",
    "\n",
    "# Zero-padding\n",
    "def pad_signal(signal, max_len=MAX_LEN_PHYSIONET):\n",
    "    \"\"\"Pad signal to max_len with zeros.\"\"\"\n",
    "    if len(signal) < max_len:\n",
    "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
    "    else:\n",
    "        return signal[:max_len]\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "def preprocess_ecg_dataset(dataset_path):\n",
    "    \"\"\"Preprocess ECG dataset from PhysioNet or MIT-BIH.\"\"\"\n",
    "    signals, labels = load_physionet_data(dataset_path)\n",
    "    original_fs = 300  # PhysioNet signals are sampled at 300 Hz\n",
    "    max_len = MAX_LEN_PHYSIONET\n",
    "    processed_signals,processed_labels = [],[]\n",
    "    for signal,label in zip(signals,labels):\n",
    "        # 1. Downsampling\n",
    "        signal = downsample_signal(signal, original_fs, TARGET_SAMPLING_RATE)\n",
    "        # 2. Normalization\n",
    "        signal = normalize_signal(signal)\n",
    "        # 3. R-peak detection\n",
    "        r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
    "        # 4. Beat extraction\n",
    "        beats = extract_beats(signal, r_peaks)\n",
    "        # 5. Zero-padding each beat\n",
    "        padded_beats = [pad_signal(beat, max_len) for beat in beats]\n",
    "        processed_signals.extend(padded_beats)  # Collect all beats\n",
    "        processed_labels.extend([label] * len(padded_beats))  # Assign the same label to all extracted beats\n",
    "\n",
    "    return np.array(processed_signals), np.array(processed_labels)\n",
    "\n",
    "# Example Usage\n",
    "physionet_data, physionet_labels = preprocess_ecg_dataset(\"data/training2017\")\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_physionet = torch.tensor(physionet_data, dtype=torch.float32)\n",
    "y_physionet = torch.tensor(physionet_labels, dtype=torch.long)\n",
    "\n",
    "#save the processed data\n",
    "# Save data with gzip compression\n",
    "with gzip.open(\"pretraining_data.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump((X_physionet, y_physionet), f)\n",
    "print(f\"PhysioNet Data Shape: {X_physionet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT-BIH Beats Shape: torch.Size([109966, 250])\n",
      "Unique Labels: (array([0, 1, 2, 3, 4]), array([90631,  2781,  7708,   803,  8043]))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import wfdb\n",
    "import gzip\n",
    "import pickle\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Constants\n",
    "TARGET_SAMPLING_RATE = 125  # Hz\n",
    "MAX_LEN_MITBIH = 2 * TARGET_SAMPLING_RATE  # e.g., 2-second window around each R-peak\n",
    "\n",
    "# Beat label mapping (can expand if needed)\n",
    "label_mapping = {\n",
    "    'N': 0,  # Normal\n",
    "    'L': 0, 'R': 0, 'e': 0, 'j': 0,\n",
    "    'A': 1, 'a': 1, 'J': 1, 'S': 1,\n",
    "    'V': 2, 'E': 2, '!': 2,\n",
    "    'F': 3,\n",
    "    '/': 4, 'f': 4, 'Q': 4, '?': 4  # Unknown/other\n",
    "}\n",
    "\n",
    "def load_mitbih_record(record_path):\n",
    "    \"\"\"Load signal and annotations from MIT-BIH record.\"\"\"\n",
    "    record = wfdb.rdrecord(record_path)\n",
    "    annotation = wfdb.rdann(record_path, 'atr')\n",
    "    signal = record.p_signal[:, 0]  # Use first ECG lead\n",
    "    return signal, annotation.sample, annotation.symbol\n",
    "\n",
    "def downsample_signal(signal, original_fs=360, target_fs=125):\n",
    "    num_samples = int(len(signal) * target_fs / original_fs)\n",
    "    return resample(signal, num_samples)\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    return (signal - np.min(signal)) / (np.max(signal) - np.min(signal) + 1e-6)\n",
    "\n",
    "def pad_signal(signal, max_len):\n",
    "    if len(signal) < max_len:\n",
    "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
    "    else:\n",
    "        return signal[:max_len]\n",
    "\n",
    "def extract_beats_and_labels(signal, r_peaks, ann_symbols, fs=125, window_size=1.0):\n",
    "    \"\"\"Extract beats centered around R-peaks and assign arrhythmia labels.\"\"\"\n",
    "    half_window = int((window_size / 2) * fs)\n",
    "    beats, labels = [], []\n",
    "    for i, peak in enumerate(r_peaks):\n",
    "        if ann_symbols[i] in label_mapping:\n",
    "            start = max(0, peak - half_window)\n",
    "            end = min(len(signal), peak + half_window)\n",
    "            beat = signal[start:end]\n",
    "            padded = pad_signal(beat, max_len=MAX_LEN_MITBIH)\n",
    "            beats.append(padded)\n",
    "            labels.append(label_mapping[ann_symbols[i]])\n",
    "    return beats, labels\n",
    "\n",
    "def preprocess_mitbih_dataset(dataset_dir):\n",
    "    \"\"\"Load all records, extract beats and labels.\"\"\"\n",
    "    all_beats, all_labels = [], []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith('.dat'):\n",
    "            record_name = file.replace('.dat', '')\n",
    "            signal, r_peaks, ann_symbols = load_mitbih_record(os.path.join(dataset_dir, record_name))\n",
    "            # Downsample\n",
    "            signal = downsample_signal(signal, original_fs=360, target_fs=TARGET_SAMPLING_RATE)\n",
    "            r_peaks = (np.array(r_peaks) * (TARGET_SAMPLING_RATE / 360)).astype(int)\n",
    "            # Normalize\n",
    "            signal = normalize_signal(signal)\n",
    "            # Extract\n",
    "            beats, labels = extract_beats_and_labels(signal, r_peaks, ann_symbols, fs=TARGET_SAMPLING_RATE)\n",
    "            all_beats.extend(beats)\n",
    "            all_labels.extend(labels)\n",
    "    return np.array(all_beats), np.array(all_labels)\n",
    "# Preprocess MIT-BIH\n",
    "mitbih_signals, mitbih_labels = preprocess_mitbih_dataset(\"data/mit-bih-arrhythmia-database-1.0.0\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_mitbih = torch.tensor(mitbih_signals, dtype=torch.float32)\n",
    "y_mitbih = torch.tensor(mitbih_labels, dtype=torch.long)\n",
    "\n",
    "# Save\n",
    "with gzip.open(\"mitbih_beats.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump((X_mitbih, y_mitbih), f)\n",
    "\n",
    "print(f\"MIT-BIH Beats Shape: {X_mitbih.shape}\")\n",
    "print(f\"Unique Labels: {np.unique(mitbih_labels, return_counts=True)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
