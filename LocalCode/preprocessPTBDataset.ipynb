{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d996c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTBDB Beats Shape: torch.Size([38084, 250])\n",
      "Unique Labels: (array([0, 1, 2, 3, 4]), array([ 7096,  5540, 21473,   504,  3471]))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import wfdb\n",
    "import gzip\n",
    "import pickle\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Constants\n",
    "TARGET_SAMPLING_RATE = 125\n",
    "MAX_LEN_BEAT = 2 * TARGET_SAMPLING_RATE  # 2 seconds per beat\n",
    "\n",
    "def parse_reason_from_header(header_file):\n",
    "    \"\"\"Extract 'Reason for admission' from header file.\"\"\"\n",
    "    reason = None\n",
    "    with open(header_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"Reason for admission:\" in line:\n",
    "                reason = line.split(\"Reason for admission:\")[-1].strip()\n",
    "                break\n",
    "    if reason is None or reason == \"\":\n",
    "        reason = \"other\"\n",
    "    return reason\n",
    "\n",
    "def map_reason(reason):\n",
    "    \"\"\"Map PTBDB reason into MIT-BIH 5-class style.\"\"\"\n",
    "    reason = reason.lower()\n",
    "\n",
    "    if \"healthy\" in reason:\n",
    "        return 0  # N\n",
    "    elif \"myocardial infarction\" in reason:\n",
    "        return 2  # V\n",
    "    elif \"cardiomyopathy\" in reason or \"myocarditis\" in reason or \"bundle branch\" in reason or \"hypertrophy\" in reason:\n",
    "        return 1  # S\n",
    "    elif \"valvular\" in reason:\n",
    "        return 3  # F\n",
    "    else:\n",
    "        return 4  # Unknown/Q\n",
    "\n",
    "def load_ptbdb_record(record_path):\n",
    "    \"\"\"Load ECG signal (first lead).\"\"\"\n",
    "    record = wfdb.rdrecord(record_path)\n",
    "    signal = record.p_signal[:, 0]\n",
    "    return signal, record.fs\n",
    "\n",
    "def downsample_signal(signal, original_fs, target_fs=125):\n",
    "    \"\"\"Resample signal.\"\"\"\n",
    "    num_samples = int(len(signal) * target_fs / original_fs)\n",
    "    return resample(signal, num_samples)\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    \"\"\"Min-max normalization.\"\"\"\n",
    "    return (signal - np.min(signal)) / (np.max(signal) - np.min(signal) + 1e-6)\n",
    "\n",
    "def detect_r_peaks(signal, fs=125):\n",
    "    \"\"\"Detect R-peaks using NeuroKit2.\"\"\"\n",
    "    _, rpeaks = nk.ecg_peaks(signal, sampling_rate=fs)\n",
    "    return rpeaks[\"ECG_R_Peaks\"]\n",
    "\n",
    "def extract_beats(signal, r_peaks, fs=125):\n",
    "    \"\"\"Extract beats centered on each R-peak (using median RR).\"\"\"\n",
    "    if len(r_peaks) < 2:\n",
    "        return []\n",
    "    rr_intervals = np.diff(r_peaks)\n",
    "    median_rr = int(np.median(rr_intervals))\n",
    "    beats = []\n",
    "    for r in r_peaks:\n",
    "        start = max(0, r - median_rr // 2)\n",
    "        end = min(len(signal), r + median_rr // 2)\n",
    "        beats.append(signal[start:end])\n",
    "    return beats\n",
    "\n",
    "def pad_signal(signal, max_len):\n",
    "    \"\"\"Pad or truncate beats to fixed length.\"\"\"\n",
    "    if len(signal) < max_len:\n",
    "        return np.pad(signal, (0, max_len - len(signal)), 'constant')\n",
    "    else:\n",
    "        return signal[:max_len]\n",
    "\n",
    "def preprocess_ptbdb_beats(dataset_dir):\n",
    "    all_beats, all_labels = [], []\n",
    "\n",
    "    for patient_folder in sorted(os.listdir(dataset_dir)):\n",
    "        patient_path = os.path.join(dataset_dir, patient_folder)\n",
    "\n",
    "        # âœ… Only process folders starting with \"patient\"\n",
    "        if not os.path.isdir(patient_path) or not patient_folder.startswith(\"patient\"):\n",
    "            continue\n",
    "\n",
    "        # take first .dat file in folder\n",
    "        dat_files = [f for f in os.listdir(patient_path) if f.endswith(\".dat\")]\n",
    "        if not dat_files:\n",
    "            continue\n",
    "        first_dat = sorted(dat_files)[0]\n",
    "        record_name = os.path.splitext(first_dat)[0]\n",
    "        record_path = os.path.join(patient_path, record_name)\n",
    "\n",
    "        # parse reason\n",
    "        hea_file = record_path + \".hea\"\n",
    "        reason = parse_reason_from_header(hea_file)\n",
    "        label = map_reason(reason)\n",
    "\n",
    "        # load signal\n",
    "        signal, fs = load_ptbdb_record(record_path)\n",
    "\n",
    "        # downsample + normalize\n",
    "        signal = downsample_signal(signal, fs, TARGET_SAMPLING_RATE)\n",
    "        signal = normalize_signal(signal)\n",
    "\n",
    "        # detect R-peaks\n",
    "        r_peaks = detect_r_peaks(signal, TARGET_SAMPLING_RATE)\n",
    "\n",
    "        # extract beats\n",
    "        beats = extract_beats(signal, r_peaks, TARGET_SAMPLING_RATE)\n",
    "\n",
    "        for beat in beats:\n",
    "            padded = pad_signal(beat, MAX_LEN_BEAT)\n",
    "            all_beats.append(padded)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return np.array(all_beats), np.array(all_labels)\n",
    "\n",
    "# Run preprocessing\n",
    "ptbdb_beats, ptbdb_labels = preprocess_ptbdb_beats(\"data/ptb-diagnostic-ecg-database-1.0.0\")\n",
    "\n",
    "# Convert to tensors\n",
    "X_ptbdb = torch.tensor(ptbdb_beats, dtype=torch.float32)\n",
    "y_ptbdb = torch.tensor(ptbdb_labels, dtype=torch.long)\n",
    "\n",
    "# Save\n",
    "with gzip.open(\"ptbdb_beats.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump((X_ptbdb, y_ptbdb), f)\n",
    "\n",
    "print(f\"PTBDB Beats Shape: {X_ptbdb.shape}\")\n",
    "print(f\"Unique Labels: {np.unique(ptbdb_labels, return_counts=True)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
